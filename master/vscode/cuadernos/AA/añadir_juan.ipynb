{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= False)\n",
    "# param_grid = {'alpha': [0.1, 1, 10, 100]}\n",
    "# ridge = Ridge()\n",
    "# grid_search = GridSearchCV(ridge, param_grid)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= False)\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "# grid_search = GridSearchCV(RandomForestRegressor(), param_grid)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_alpha = grid_search.best_params_\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= False)\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "    'max_depth': [3,4,5,6,7,8],\n",
    "    'n_estimators': [50, 100, 200, 300, 400]\n",
    "}\n",
    "grid_search = GridSearchCV(XGBRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_con_validacion_cruzada_y_test(X, y):\n",
    "  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= False)\n",
    "    \n",
    "    # Inicializa los modelos\n",
    "    modelos = {\n",
    "        \"Ridge\": Ridge(alpha=100),\n",
    "        \"Lasso\": Lasso(alpha=100),\n",
    "        \"XGB\": XGBRegressor(learning_rate= 0.01, max_depth= 4, n_estimators=300),\n",
    "        \"Random Forest\": RandomForestRegressor(n_estimators=300, max_depth=30 ,min_samples_split=10 ,random_state=42)\n",
    "    }\n",
    "    \n",
    " \n",
    "    resultados = {}\n",
    "    for nombre, modelo in modelos.items():\n",
    "        mse_scores = []\n",
    "        r2_scores = []\n",
    "        mae_scores = []\n",
    "        mape_scores = []\n",
    "        \n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            \n",
    "            train_index = train_index.astype('int64')\n",
    "            X_train_fold = X_train.iloc[train_index]\n",
    "            X_val_fold = X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            \n",
    "            modelo.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = modelo.predict(X_val_fold)\n",
    "            \n",
    "            mse_fold = mean_squared_error(y_val_fold, y_pred)\n",
    "            r2_fold = r2_score(y_val_fold, y_pred)\n",
    "            mae_fold = mean_absolute_error(y_val_fold, y_pred)\n",
    "            mape_fold = (mean_absolute_percentage_error(y_val_fold, y_pred)*100)\n",
    "            \n",
    "            mse_scores.append(mse_fold)\n",
    "            r2_scores.append(r2_fold)\n",
    "            mae_scores.append(mae_fold)\n",
    "            mape_scores.append(mape_fold)\n",
    "        \n",
    "\n",
    "        mse_promedio = np.mean(mse_scores)\n",
    "        r2_promedio = np.mean(r2_scores)\n",
    "        mae_promedio = np.mean(mae_scores)\n",
    "        mape_promedio = np.mean(mape_scores)\n",
    "        \n",
    "        # Evalúa el modelo en el conjunto de prueba\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred_test = modelo.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        mae_test =  mean_absolute_error(y_test, y_pred_test)\n",
    "        mape_test =  (mean_absolute_percentage_error(y_test, y_pred_test)*100)\n",
    "        \n",
    "        resultados[nombre] = {\n",
    "            'MSE Promedio': mse_promedio,\n",
    "            'R² Promedio': r2_promedio,\n",
    "            'MAE Promedio': mae_promedio,\n",
    "            'MAPE Promedio': mape_promedio,\n",
    "            'MSE en Test': mse_test,\n",
    "            'R² en Test': r2_test,\n",
    "            'MAE en Test': mae_test,\n",
    "            'MAPE en Test': mape_test\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "\n",
    "resultados = regresion_con_validacion_cruzada_y_test(X, y)\n",
    "\n",
    "\n",
    "for modelo, metricas in resultados.items():\n",
    "    print(f\"Modelo: {modelo}\")\n",
    "    print(f\"MSE Promedio en Validación Cruzada: {metricas['MSE Promedio']}\")\n",
    "    print(f\"R² Promedio en Validación Cruzada: {metricas['R² Promedio']}\")\n",
    "    print(f\"MAE Promedio en Validación Cruzada: {metricas['MAE Promedio']}\")\n",
    "    print(f\"MAPE Promedio en Validación Cruzada: {metricas['MAPE Promedio']}\")    \n",
    "    print(f\"MSE en Test: {metricas['MSE en Test']}\")\n",
    "    print(f\"R² en Test: {metricas['R² en Test']}\")\n",
    "    print(f\"MAE en Test: {metricas['MAE en Test']}\")\n",
    "    print(f\"MAPE en Test: {metricas['MAPE en Test']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
