{"cells":[{"cell_type":"markdown","metadata":{"id":"eU_gqVHcSuHE"},"source":["# <font color='#2B4865'>**Hugging Face ü§ó Transformers Tutorial I**</font>\n","\n","---\n","### Natural Language Processing\n","Date: Dec 21, 2022\n","\n","Author: Lorena Calvo-Bartolom√© (lcalvo@pa.uc3m.es)\n","\n","Version 1.0\n","\n","---\n","This notebook is based on the [Hugging Face course](https://huggingface.co/course/chapter1/1), documentation available at the Hugging Face website and  [CS224n](https://web.stanford.edu/class/cs224n/)'s Hugging Face Transformers Tutorial session by Ben Newman.\n","\n","It constitutes the first out of three tutorial notebooks on the usage of Hugging Face libraries as well as its application for solving a series of NLP tasks.\n","\n","This notebook provides an introduction to the Hugging Face ü§ó Python library. In particular, its **goals** are:\n","\n","*  To establish a common pattern for performing inference with Hugging Face Transformer models\n","*  To revise the specific fine-tuning example on the task of Sentiment Analysis\n","\n","---\n","\n","<font color='#E0144C'>**For this notebook's execution, we highly encourage you to use Google Colaboratory. While for the inference part it is not necessary, you will highly speed up the execution if you make use of a GPU. For doing so, follow the following steps:**</font>\n","\n","<font color='#E0144C'>**1. Connect to hosted runtime**</font>\n","\n","<font color='#E0144C'>**2. Enable GPU setting by clicking Edit -> Notebook Settings -> Select GPU in Hardware Acceleration Tab -> Save**</font>"]},{"cell_type":"markdown","source":["### PR√ÅCTICA 4.2 - PROCESAMIENTO DEL LENGUAJE NATURAL - MASTER EN INTELIGENCIA ARTIFICIAL APLICADA\n","\n","### JOS√â LORENTE L√ìPEZ - DNI: 48842308Z"],"metadata":{"id":"eSmDpTHvbv5R"}},{"cell_type":"markdown","metadata":{"id":"H_ak68EcROir"},"source":["## <font color='#2B4865'>Installing necessary packages, imports and auxiliary functions</font>"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"jNmR0A9v3gG7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b4888df-04b1-4713-ee3e-b4763479b2d4","executionInfo":{"status":"ok","timestamp":1673391561185,"user_tz":-60,"elapsed":2105,"user":{"displayName":"Jos√© Lorente L√≥pez","userId":"17635609222309178675"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing package transformers[sentencepiece]\n","Installing package datasets\n","Installing package gradio\n","Installing package colored\n","Installing package wikipedia\n","Installing package evaluate\n","Package nltk already installed!\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 5, in <module>\n","    from pip._internal.cli.main import main\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 9, in <module>\n","    from pip._internal.cli.autocompletion import autocomplete\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n","    from pip._internal.cli.main_parser import create_main_parser\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main_parser.py\", line 8, in <module>\n","    from pip._internal.cli import cmdoptions\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/cmdoptions.py\", line 23, in <module>\n","    from pip._internal.cli.parser import ConfigOptionParser\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/parser.py\", line 12, in <module>\n","    from pip._internal.configuration import Configuration, ConfigurationError\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/configuration.py\", line 26, in <module>\n","    from pip._internal.utils.logging import getLogger\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 19, in <module>\n","    from pip._vendor.rich.logging import RichHandler\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/logging.py\", line 12, in <module>\n","    from .traceback import Traceback\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/traceback.py\", line 25, in <module>\n","    from .syntax import Syntax\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/syntax.py\", line 8, in <module>\n","    from pip._vendor.pygments.lexer import Lexer\n","  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1407, in find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1379, in _get_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 1506, in find_spec\n","  File \"<frozen importlib._bootstrap_external>\", line 142, in _path_stat\n","KeyboardInterrupt\n","^C\n"]}],"source":["# Importamos las librer√≠as necesarias para el desarrollo de la pr√°ctica\n","\n","# Install necessary packages\n","import importlib, os\n","\n","necessary_packages = ['transformers[sentencepiece]', 'datasets', 'gradio', 'colored', 'wikipedia', 'evaluate', 'nltk', 'rouge_score']\n","def import_missing(packages):\n","  for p in packages:\n","    try:\n","      mod = importlib.import_module(p)\n","      print(f\"Package {p} already installed!\")\n","      packages.remove(p)\n","    except ModuleNotFoundError:\n","      print(f\"Installing package {p}\")\n","      with open(\"requirements.txt\", 'w') as f:\n","        f.write(\"\\n\".join(str(i) for i in packages))\n","  if os.path.isfile(\"requirements.txt\"):\n","    %pip install --quiet -r \"requirements.txt\"\n","\n","import_missing(necessary_packages)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VszD2tguTJcS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a4e6fc20-3c16-4ef6-cdef-7e194c8f0283"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["# Librer√≠as m√°s generales \n","import os\n","import numpy as np\n","import pandas as pd\n","from termcolor import colored\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tqdm\n","import scipy\n","from colored import fore, back, style\n","import gradio as gr\n","import torch\n","import json\n","import random\n","from collections import defaultdict\n","import nltk\n","nltk.download(\"punkt\")\n","\n","# Figures plotted inside the notebook\n","%matplotlib inline \n","# High quality figures\n","%config InlineBackend.figure_format = 'retina' \n","# Figures style\n","plt.style.use('seaborn-whitegrid')\n","sns.set_style(\"darkgrid\")\n","sns.color_palette(\"deep\")\n","# Figues size\n","plt.rcParams['figure.figsize'] = [8, 6]\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.filterwarnings(action='ignore',module='gradio')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lhwq7n9ETRuL"},"outputs":[],"source":["# To wrap long text lines\n","from IPython.display import HTML, display\n","\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)\n","\n","# For fancy table Display\n","%load_ext google.colab.data_table"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2NeGDEO48Bi","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"921fefe3-7d46-4e45-e4b6-2e038b1265eb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["# Auxiliary funcion to print Trasnformer encodings\n","def print_encoding(model_inputs, indent=4):\n","    indent_str = \" \" * indent\n","    print(\"{\")\n","    for k, v in model_inputs.items():\n","        print(indent_str + k + \":\")\n","        print(indent_str + indent_str + str(v))\n","    print(\"}\")"]},{"cell_type":"markdown","metadata":{"id":"BsQkcsv7x89u"},"source":["We are going to save all the files in this notebook generated into Drive. Fill the variable ``path_to_folder`` in the next with your Drive's folder in which you want to save the files."]},{"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"3lpjmqFjewF3","outputId":"40887068-a563-4d79-f7a1-2b6bfc3c5221"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h7wQkXVnvnvu","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"04b68bfc-acbb-4e25-aad6-2de1a839d12b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["path_to_folder = '/content/drive/MyDrive/Cosas/NLP_IA/Cosas_LAB_4/P3'  # UPDATE THIS ACCORDING TO WHERE YOU WANT TO SAVE THE FILES!!!!\n","\n","# Change to assignment directory\n","os.chdir(path_to_folder) "]},{"cell_type":"markdown","metadata":{"id":"WS2DntKdviBl"},"source":["## <font color='#2B4865'>**0. Introduction**\n","---\n","</font>"]},{"cell_type":"markdown","metadata":{"id":"yFEh5EWsvshb"},"source":["###¬†<font color='#2B4865'>*0.1. Hugging Face*</font>"]},{"cell_type":"markdown","metadata":{"id":"99ynm_GMvfGW"},"source":["As we have seen in class, Transformer models have become state-of-the-art for NLP to solve a wide range of tasks. In practice, we will rarely train a Transformer model from scratch, as they tend to be very large, thus requiring time, money, and lots of data to train fully. Instead, we will want to start with a pre-trained model and fine-tune it with our specific dataset if required.\n","\n","[Hugging Face](https://huggingface.co/) (ü§ó) is the best resource for pre-trained transformers. Among other things, it provides:\n","\n","*   APIs and tools to easily download and train state-of-the-art pretrained models, as well as pipelines for carrying out common NLP tasks, in the [Transformers library](https://huggingface.co/docs/transformers/index).\n","*   State-of-the-art tokenizers, optimized for both research and production are also used in Transformers in the [Tokenizers library](https://huggingface.co/docs/tokenizers/index).\n","*   Datasets and metrics in the [Datasets library](https://huggingface.co/docs/datasets/index).\n","\n","It has implementations in PyTorch, Tensorflow, and Flax (though we'll be using the **PyTorch** versions here)."]},{"cell_type":"markdown","source":["Hoy por hoy los transformers es una parte fundamental del estado del arte de los modelos NLP. Rara vez se entrenan desde 0 (suelen ser modelos masivos y el gasto es muy exagerado), es por ello que se suelen usar modelos pre-entrenados y se les tunea para enfocarlos a nuestra tarea con nuestro dataset espec√≠fico.\n","\n","La mejor librer√≠a para esta tarea es \"Hugging face\". Proporciona modelos pre-entrenados y una facil manera de entrenarlos. Tokenizadores, datasets, ...\n","\n","Se puede usar con Pytorch (lo que usaremos), tensorflow y flax."],"metadata":{"id":"pjI7VNh1gsZd"}},{"cell_type":"markdown","metadata":{"id":"bg5_7T1hqXDy"},"source":["###¬†<font color='#2B4865'>*0.2. NLP tasks overview*</font>"]},{"cell_type":"markdown","metadata":{"id":"jkBZjcF-0bsk"},"source":["In the series of notebooks \"Hugging Face Transformers Tutorial\" I, II & III, we will learn how to approach via Hugging Face the tasks of:\n","\n","*   **Sentiment Analysis**\n","*   **Extractive Question Answering**\n","*   **Summarization**\n","*   **Text Generation**\n","\n","Even when we are just going to cover the above-mentioned tasks, bear in mind that many others can be addressed through Hugging Face.\n","\n","In any case, we will use a different Transformer architecture depending on the task we aim to solve. The following table summarizes the most common tasks that can be approached with either an Encoder, Decoder, or a full Encoder-Decoder architecture:\n","\n","<table><thead><tr><th><font color='#256D85'>Model</font></th><th><font color='#256D85'>Examples</font></th><th><font color='#256D85'>Tasks</font></th></tr></thead><tbody><tr><td><b>ENCODER</b></td><td>ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa</td><td>Sentence classification, named entity recognition, extractive question answering</td></tr><tr><td><b>DECODER</b></td><td>CTRL, GPT, GPT-2, Transformer XL</td><td>Text generation</td></tr><tr><td><b>ENCODER-DECODER</b></td><td>BART, T5, Marian, mBART</td><td>Summarization, translation, generative question answering</td></tr></tbody></table>\n","\n","In the following, we will attempt to solve the aforementioned tasks first through inference, and then, via fine-tuning. We will start by presenting a common usage pattern for Hugging Face Transformers, using the example of Sentiment Analysis, and then we will benefit from such a pattern to work out the other two tasks."]},{"cell_type":"markdown","source":["En los 3 tutoriales de hugging face abarcaremos usando las librer√≠ua el uso de modelos pre-entrenaods para analisis de sentimientos, question answering, resumen de textos y generaci√≥n de texto. (aunque se podr√≠an abarcar muchas otras; veamos una tabla con los posibles modelos a crear en funci√≥n del bloque de transformer que utilicemos):\n","\n","<table><thead><tr><th><font color='#256D85'>Model</font></th><th><font color='#256D85'>Examples</font></th><th><font color='#256D85'>Tasks</font></th></tr></thead><tbody><tr><td><b>ENCODER</b></td><td>ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa</td><td>Sentence classification, named entity recognition, extractive question answering</td></tr><tr><td><b>DECODER</b></td><td>CTRL, GPT, GPT-2, Transformer XL</td><td>Text generation</td></tr><tr><td><b>ENCODER-DECODER</b></td><td>BART, T5, Marian, mBART</td><td>Summarization, translation, generative question answering</td></tr></tbody></table>\n","\n","Primero resolveremos el modelo con inference y luego con modelos pre-entrenados\n","\n","\n"],"metadata":{"id":"J5XMNQrShsrc"}},{"cell_type":"markdown","metadata":{"id":"PEE4Jukv0ZWy"},"source":["## <font color='#2B4865'>**1. Sentiment Analysis**\n","---\n","</font>"]},{"cell_type":"markdown","metadata":{"id":"F-4rg_ZJaG5b"},"source":["As we saw in Block I, **Sentiment analysis** is an NLP technique that identifies the polarity of a given text. There are different forms of sentiment analysis, but one of the most widely used techniques labels data as positive, negative, and neutral."]},{"cell_type":"markdown","metadata":{"id":"bZzv6wdltTJj"},"source":["##### <font color='#2B4865'>**Demo**</font>"]},{"cell_type":"markdown","metadata":{"id":"76kbum4UtYbt"},"source":["In the next cell, you can test a Sentiment analysis system built with [Gradio](https://gradio.app/) and a ü§ó fine-tuned model [from the Hub](https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis). You can try it out by inserting any sentence or clicking on the example ones."]},{"cell_type":"markdown","source":["Veamos un ejemplo de un modelo (ya creado) de clasificaci√≥n de frases por sentimiento creado con gradio y la librer√≠a hugging-face (con los t√≠picos labels pos, neg or neut).\n","\n"],"metadata":{"id":"pwgvB0GXk9aj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lO2FWXJ-aJEe","colab":{"base_uri":"https://localhost:8080/","height":634},"outputId":"557522b9-2ea8-4ff2-8f15-cb9a2a72d4a5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fetching model from: https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":8}],"source":["examples = [\n","    [\"I like you. I love you\"],\n","    [\"You are the worst!!\"]\n","]\n","\n","\n","gr.Interface.load(\"huggingface/finiteautomata/bertweet-base-sentiment-analysis\", \n","                  inputs = \"text\", \n","                  outputs = ['text'],\n","                  title = 'Sentiment Analysis', \n","                  examples=examples,\n","                  description=\"Get Sentiment Negative/Positive for the given input\").launch()"]},{"cell_type":"markdown","metadata":{"id":"I_bOeklctm0C"},"source":["##### <font color='#2B4865'>**Architecture for approaching the task**</font>"]},{"cell_type":"markdown","metadata":{"id":"P6UhqQ6dtkIs"},"source":["**Sentiment Analysis** is not more than a use case of the general task named **Token classification**, that is, any problem that can be formulated as \"*attributing a label to each token in a sentence*\". Other types of Token Classification tasks include **Named entity recognition (NER)** and **Part-of-speech tagging (POS)**, among others. All of them are approached via **BERT-like** models."]},{"cell_type":"markdown","metadata":{"id":"twr8jkEWttz6"},"source":["##### <font color='#2B4865'>**Evaluation metrics**</font>"]},{"cell_type":"markdown","metadata":{"id":"w6p5zs64vNhF"},"source":["Same as we did in the Text Vectorization notebooks, we will be analyzing our Sentiment Analysis task based on the **accuracy**, that is the proportion of correct predictions among the total number of cases processed:\n","\n","$$Accuracy = \\frac{(TP + TN)}{(TP + TN + FP + FN)}$$\n","\n","Even though we will be using accuracy, note that there exist other metrics for token classification tasks such as the **F1-score**."]},{"cell_type":"markdown","source":["Primero usaremos modelos tal cual y luego ajustaremos modelos a nuestros propios datasets con fine-tuning"],"metadata":{"id":"Uoc20OBxpwz3"}},{"cell_type":"markdown","metadata":{"id":"ts7IfG2GzX0L"},"source":["###¬†<font color='#2B4865'>*1.1. Inference*</font>"]},{"cell_type":"markdown","metadata":{"id":"KjhZvtO57Wc_"},"source":["####¬†<font color='#2B4865'>*1.1.1. Transformers pipelines*</font>"]},{"cell_type":"markdown","source":["La librer√≠a HF, proporciona pipelines para resolver ciertas tareas.\n","\n","Estas pipelines se forman por: tokenizador (para pasar de texto en crudo a texto limpio tokenizado) + modelo (para ejecutar la tarea; en este caso uno que dado una entraga haga la predicci√≥n del sentimiento) + postprocesado (bloque opcional para mejorar los resultados del modelo).\n","\n","Toda la pipeline se empaqueta en un objeto f√°cil de usar. \n","\n","Como tal podemos usar el objeto piopeline() (el cual engloba dentro todos los tipos de pipelines y se especifica el que usar como atributo en funci√≥n de la tarea a resolver), o usamos pipeline espec√≠ficos Ej: AudioClassificationPipeline.\n","\n"],"metadata":{"id":"dZ77ngPYnYYJ"}},{"cell_type":"markdown","metadata":{"id":"Sou5hO6C6SWo"},"source":["The ü§ó ``Transformers`` library provides ``pipelines`` to solve specific tasks. A **pipeline** consists of:\n","\n","*   a **tokenizer** in charge of mapping raw textual input to tokens\n","*   a **model** to make predictions from the inputs\n","*   some (optional) **postprocessing** for enhancing model‚Äôs output\n","\n","all of them packaged together into an easy-to-use and configurable object.\n","\n","<br><center><img src=\"https://drive.google.com/uc?id=1dTZTRdLRAWWR_8yJf-l7DzKphj7MW9wB\" width=\"60%\"></center><br>\n","\n","Pipelines are an easy way to use models for inference since they are **intended to be used without fine-tuning**. They are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks.\n","\n","There are **two categories of pipeline abstractions** to be aware of: the ``pipeline()`` which is the most powerful object encapsulating all other pipelines, and other **task-specific pipelines**. Some examples of the latter include:\n","\n","```python\n","AudioClassificationPipeline\n","AutomaticSpeechRecognitionPipeline\n","ConversationalPipeline\n","FeatureExtractionPipeline\n","...\n","```\n","\n","**NOTE**: You can create a pipeline without specifying any model. In this case, the default checkpoint associated with the pipeline being instantiated will be used.\n","\n","For more information about pipelines, you can check the [Hugging Face Pipelines Docs](https://huggingface.co/docs/transformers/v4.21.2/en/main_classes/pipelines#transformers.pipeline)."]},{"cell_type":"markdown","metadata":{"id":"aTpUUhYi1Mjp"},"source":["Let's see how to exploit these pipelines for our Sentiment Analysis task.\n","\n","The **first step** is to find a model on [the hub](https://huggingface.co/models). Here, we will be using [``siebert/sentiment-roberta-large-english``](https://huggingface.co/siebert/sentiment-roberta-large-english), a fine-tuned checkpoint of [RoBERTa-large](https://arxiv.org/pdf/1907.11692.pdf) for sentiment classification.\n","\n","Once we have the model we are going to use, we can create our Sentiment Analysis pipeline and use it to predict the polarity of any sentence."]},{"cell_type":"markdown","source":["Lo pirmero es encontrar en el hub de modelos de HF, un modelo acorde a la tarea. Usaremos el de roberta para clasificaci√≥n de sentimientos.\n","\n","Metemos el modelo en un objeto pipeline y con esto le podemos meter frases tal cual y nos dar√° una predicci√≥n del sentimiento asociado a la misma."],"metadata":{"id":"KPtnFe9ZoqT4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgxDiyQ52SB9","colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["c02bb8241a1a4d43aa14e01a3af13fc0","1078d0bb08da4dbda6cc48dc55be6e25","6e32e768434e4ed9b46ffab522a1724e","4db35f7816944e238ce5759e91f0c98e","47d4f017de8e4e68a6e40cd505834eb6","05fbe7dd374f49ce9810113a111030b9","fa5638ad29824236b1550129cea7404c","ec0742bdd1c24f8a993a488f6da6e5a1","56e638b9a1d644ee9f507f99815dafbf","3b3129498e62469484b1eccc14db485f","bb154df37f5340da90dd95753e302838","8221a758ba2e44dd995e3a156fdcfabe","d24d8754caf742db87aed513d16c7d11","14b86fe6d9884891a7833da9c4c6229e","fd843aaadd5249f1bfdd5bb1bf1f0cd1","bc89e933e0c44708be66dfbd8e0d5418","3c8ae455388042bfa5b297354385034c","7b98b04a16464e2faa9392b33f6e6b15","943fcc9e3f924217a961cd8b387a3f0f","e992db9438f34014b29fedcf9e1d9cd9","ee64c37f6fa449629611f45291536049","a205cd913cf24e149f4a0d55d068d528","6c7a13a5a99246fcb60624293fda5e28","976b5fbbc4cc4dc4ac022b37299a92cc","20bb37bebff54a498592c29e56ba7935","be4ceb3b764f4246857503927cab1c11","b8b3f94c710744ebb5a5f1d8c5c23a2b","ff701c6d2c99437cbcdeb5eb497a826b","c9bedc044a434095ae5bca5010970387","5b83a1b685134d9aa209351d029a4f4f","70a8a4626c4c4282b286cea3c62cb4f5","f22c0f836e4b42ce96e46a222e1dbf6b","d7deacfa575143bfabc0af5b3b0ee535","de72c64402e74f41bffb001bbecc61f1","2ccc8b4261b24e0eac327380c975b223","931b0bc0982a467890b9e27ba8363edf","8ae741aed7254093800e8d407e8e6b16","64470ef829dc48f79f81d4688506699e","5568740ee5824079b9a3d2d9a73dfffb","9c9d65b3c25847409e2c82a3d7147bd8","3cd1542de28249979a1c748f83f647a5","242d3df540d5444b8f612869759e6cce","8aa9afd6de6d4d5ca207e8be8431f8f2","d439db56f33a4bc5985fd723adaa1d18","452dab2bc9f94c76b3141f644f17a7d0","de255c1d2b0c424e87db025c9c74b786","c034a0bd797e4245b75e52f19db9fbc7","1cf1f1230f5b4f0291f2c48669333394","3d9f221d836e425b93cfff15e35ef1a2","a981597d479a43f8b5373cacf3d5261e","a192932a590b48f29a71ba4480aac3e1","b0d0869d9a19499aaa0bf2964061e48b","c0d5013efb9c4cbeb15442b35a165f86","c3790c11ff1f484683048c1404ba03a7","0e699330ed1a41a38d92093d3bf715c6","defabe8f342a49ad850358da96e08557","5fa1199529d44bbea8331ccf589787ae","84f0346a78784fe58ac138cdc27fdb1e","db6853a1acc2423495fe71a180f726f1","4ffa4483d527443689ecb4a5cf8db836","473232ae3a99477489e9883ccf1fb889","e1974e5d006c40b68794b580d7841836","16398a5e7ac14b6e88ca5be3fa7b9676","ee7a738370e240d6a6574a5c1b87d547","41e233d690b24ae4b4c681b22a18e1e5","21fdd8392dc54786a6a634db6ddf86e8"]},"outputId":"a181ca52-fcda-4595-e244-5d781d5ef0a1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/687 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c02bb8241a1a4d43aa14e01a3af13fc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8221a758ba2e44dd995e3a156fdcfabe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/256 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7a13a5a99246fcb60624293fda5e28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de72c64402e74f41bffb001bbecc61f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"452dab2bc9f94c76b3141f644f17a7d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"defabe8f342a49ad850358da96e08557"}},"metadata":{}}],"source":["checkpoint_name = \"siebert/sentiment-roberta-large-english\"\n","\n","from transformers import pipeline\n","\n","# Create a TextClassificationPipeline object\n","sentiment_analysis = pipeline(\"sentiment-analysis\", model=checkpoint_name)     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1RNTv2xE181K","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"f35b259d-0788-48f8-b936-4347eefeb1ed"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9988435506820679},\n"," {'label': 'NEGATIVE', 'score': 0.9994413256645203},\n"," {'label': 'POSITIVE', 'score': 0.9983626008033752}]"]},"metadata":{},"execution_count":10}],"source":["# Predict the sentiment of any sentence\n","sentences = [\"I'm excited to keep learning about Transformers!\",\n","             \"I hate this so much!\",\n","             \" This is exciting!\"]\n","sentiment_analysis(sentences)"]},{"cell_type":"markdown","metadata":{"id":"z41tHeSy2s1C"},"source":["Within the pipeline, there are two objects that are initialized, a **tokenizer** and a **model**. We can mimic step by step the process carried out by the pipeline for the classification of the sentiment:"]},{"cell_type":"markdown","source":["Podemos ver paso a paso lo que hacen los dos objetos del pipeline (tokenizador + modelo)."],"metadata":{"id":"rwKCRpVhrVSO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TFjyu6N2208D","colab":{"base_uri":"https://localhost:8080/","height":312},"outputId":"4a637f23-12c5-4065-8abb-585d93d77e29"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[38;5;12m\u001b[1mInputs:\u001b[0m\n","I'm excited to keep learning about Transformers!\n","\n","\u001b[38;5;12m\u001b[1mTokenized Inputs:\u001b[0m\n","{\n","    input_ids:\n","        tensor([[    0,   100,   437,  2283,     7,   489,  2239,    59, 34379,   328,\n","             2]])\n","    attention_mask:\n","        tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","}\n","\n","\u001b[38;5;12m\u001b[1mModel Outputs:\u001b[0m\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.7951,  2.9662]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","\n","The prediction is POSITIVE\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","# Initialize the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint_name)\n","# Initialize the model\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint_name)\n","\n","# Tokenize text inputs\n","tokenized_inputs = tokenizer(sentences[0], return_tensors=\"pt\")\n","\n","# Pass tokenized inputs through the Transformer model\n","outputs = model(**tokenized_inputs)\n","\n","# Get predictions\n","labels = ['NEGATIVE', 'POSITIVE']\n","prediction = torch.argmax(outputs.logits)\n","\n","print(fore.LIGHT_BLUE + style.BOLD + \"Inputs:\" + style.RESET)\n","print(sentences[0]+\"\\n\")\n","\n","print(fore.LIGHT_BLUE + style.BOLD + \"Tokenized Inputs:\" + style.RESET)\n","print_encoding(tokenized_inputs)\n","print()\n","\n","print(fore.LIGHT_BLUE + style.BOLD + \"Model Outputs:\" + style.RESET)\n","print(outputs)\n","print()\n","\n","print(f\"The prediction is {labels[prediction]}\")"]},{"cell_type":"markdown","metadata":{"id":"7xQji6Ow3dYC"},"source":["####¬†<font color='#2B4865'>*1.1.2. Tokenizers*</font>"]},{"cell_type":"markdown","metadata":{"id":"Efi9uaPw6AsZ"},"source":["Pretrained models are implemented along with tokenizers that are used to preprocess their inputs. Tokenizers take raw strings or a list of strings and output what are effectively dictionaries that contain the model inputs.\n","\n","We can access ü§ó Tokenizers either with the Tokenizer class specific to the model (here RoBERTa) or with the ``AutoTokenizer`` class, and its ``from_pretrained()`` method. **Fast Tokenizers** are written in Rust, while their slow versions are written in Python. By doing so, **the tokenizer will preprocess the inputs in exactly the same way as when the model was pretrained**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4P-bJ3G6FgN","colab":{"base_uri":"https://localhost:8080/","height":312},"outputId":"1d8c3a9d-c09d-4965-b6a7-fd0b606af4f3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[38;5;12m\u001b[1mModel-specific tokenizer class\u001b[0m\n","PreTrainedTokenizer(name_or_path='siebert/sentiment-roberta-large-english', vocab_size=50265, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'})\n","\n","\u001b[38;5;12m\u001b[1mFast Model-specific tokenizer class\u001b[0m\n","PreTrainedTokenizerFast(name_or_path='siebert/sentiment-roberta-large-english', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n","\n","\u001b[38;5;12m\u001b[1mAutoTokenizer class -> defaults to Fast!\u001b[0m\n","PreTrainedTokenizerFast(name_or_path='siebert/sentiment-roberta-large-english', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n"]}],"source":["from transformers import RobertaTokenizer, RobertaTokenizerFast, AutoTokenizer\n","\n","tokenizer = RobertaTokenizer.from_pretrained(checkpoint_name)    \n","print(fore.LIGHT_BLUE + style.BOLD + \"Model-specific tokenizer class\" + style.RESET)               \n","print(tokenizer)\n","print()\n","\n","print(fore.LIGHT_BLUE + style.BOLD + \"Fast Model-specific tokenizer class\" + style.RESET)\n","tokenizer = RobertaTokenizerFast.from_pretrained(checkpoint_name)               \n","print(tokenizer)\n","print()\n","\n","print(fore.LIGHT_BLUE + style.BOLD + \"AutoTokenizer class -> defaults to Fast!\" + style.RESET)\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint_name)                      \n","print(tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"Ad8RrtY0irTw"},"source":["Once we have the tokenizer, we can directly pass our sentences to it and we will get back a **dictionary** that‚Äôs ready to feed to our model. The only thing left to do is to **convert the list of input IDs to tensors**, since Transformer models **only accept tensors as input**.\n","\n","To specify the type of tensors we want to get back (PyTorch, TensorFlow, or plain NumPy), we use the ``return_tensors`` argument:"]},{"cell_type":"markdown","source":["Una vez tenemos el tokenizer, le pasamos las frases y por cada una de ellas, nos devuelve una lista donde cada posici√≥n es acorde al index en el diccionario de la palabra de dicha posici√≥n en la frase.\n","\n","Con \"return_tensors\" le indicamos si el tensor que nos devuelve debe ser pytorch, tensorflow o numpy."],"metadata":{"id":"W3Vo-EEPw1Hi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKCbo2KAi_YZ","colab":{"base_uri":"https://localhost:8080/","height":243},"outputId":"64c468f1-c23b-48d6-ea9b-400c30ba8c48"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{\n","    input_ids:\n","        tensor([[    0,   100,   437,  2283,     7,   489,  2239,    59, 34379,   328,\n","             2],\n","        [    0,   100,  4157,    42,    98,   203,   328,     2,     1,     1,\n","             1],\n","        [    0,   152,    16,  3571,   328,     2,     1,     1,     1,     1,\n","             1]])\n","    attention_mask:\n","        tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])\n","}\n"]}],"source":["tokenized_inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n","print_encoding(tokenized_inputs)"]},{"cell_type":"markdown","metadata":{"id":"bDNn2CX-fy7r"},"source":["**Tokenization** takes place in a **three-step process**:\n","1. Split the input into tokens (words, subwords, or symbols): ``tokenize()``\n","2. Map each token into an integer: ``convert_tokens_to_ids()``\n","3. Add additional inputs that may be useful to the model:\n","  *   **Padding.** Batching allows the model to work when you feed it multiple sentences, but this can lead to problems when we attempt to batch together two (or more) sentences that are of different lengths. Since we are working with tensors, we need them to be of rectangular shape. We solve this issue by padding our sentences so they all have the same length by adding a special word called the **padding token** to the sentences with fewer values.\n","A **tokenizer's padding token ID** can be found in ``tokenizer.pad_token_id``.\n","  *   **Attention masks.** They are tensors with the exact same shape as the input IDs tensor, filled with ``0s`` and ``1s``: ``1s`` indicate the corresponding tokens should **be attended to**, and ``0s`` indicate the corresponding tokens should **not be attended to** (i.e., they should be ignored by the attention layers of the model), e.g., the padding tokens should be ignored.\n","  *  **Special tokens.** When encoding an input string sequence, the tokenizer will add some special tokens. For the case of token classification, for example, it adds additional tokens ``[CLS]`` at the beginning and ``[SEP]`` at the end. This is because the model was pretrained with those, so to get the same results for inference we need to add them as well. Note that some models don‚Äôt add special words, or add different ones; models may also add these special words only at the beginning, or only at the end. In any case, the tokenizer knows which ones are expected and will deal with this for you. We can access these tokens as ``tokenizer.cls_token_id`` and ``tokenizer.sep_token_id``, respectively.\n","\n","One last thing that we need to take into account when performing tokenization is the **limit to the lengths of the sequences we can pass the models** that are imposed by the Transformer model in use. Most models handle sequences of up to 512 or 1024 tokens and will crash when asked to process longer sequences. There are two solutions to this problem:\n","\n","* Use a model with a longer supported sequence length.\n","* Truncate the sequences. We can truncate our sequences by specifying the parameter ``truncation=True``. Additionally, we can specify the maximum length after which sentences will be truncated with the ``max_length`` parameter.\n","\n","**Steps 1 and 2** of the Tokenization process above described are normally named together as **encoding**, and its opposite\n","process is referred as **decoding** (``decode()``)."]},{"cell_type":"markdown","source":["La tokenizaci√≥n son tres procesos: Dividir las palabras en tokens, convertir cada token en un entero (su posici√≥n en el diccionario) a√±adir inputs √∫tiles para el modelo.\n","\n","Alguna curiosa es el Attention_Mask (que tiene la misma length que la frase en tokens de entrada e indica al modelo que tokens debe prestarle atenci√≥n y a cuales no)"],"metadata":{"id":"_ZASULfuxLcJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyJdUt2rTCTx","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"737ebdc1-40d9-4699-85fd-809c029efe0d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["cls:  [0]\n","sep:  [2]\n","\n","\u001b[38;5;12m\u001b[1mStart:                \u001b[0m I'm excited to keep learning about Transformers!\n","\u001b[38;5;12m\u001b[1mTokenize:             \u001b[0m ['I', \"'m\", 'ƒ†excited', 'ƒ†to', 'ƒ†keep', 'ƒ†learning', 'ƒ†about', 'ƒ†Transformers', '!']\n","\u001b[38;5;12m\u001b[1mConvert tokens to IDs:\u001b[0m [100, 437, 2283, 7, 489, 2239, 59, 34379, 328]\n","\u001b[38;5;12m\u001b[1mAdd special tokens:   \u001b[0m [0, 100, 437, 2283, 7, 489, 2239, 59, 34379, 328, 2]\n","\u001b[38;5;12m\u001b[1m--------\u001b[0m\n","\u001b[38;5;12m\u001b[1mdecode:               \u001b[0m <s>I'm excited to keep learning about Transformers!</s>\n"]}],"source":["cls = [tokenizer.cls_token_id]\n","sep = [tokenizer.sep_token_id]\n","print(\"cls: \", cls)\n","print(\"sep: \", sep)\n","print()\n","\n","# Tokenization happens in a few steps:\n","input_tokens = tokenizer.tokenize(sentences[0])\n","input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n","input_ids_special_tokens = cls + input_ids + sep\n","\n","decoded_str = tokenizer.decode(input_ids_special_tokens)\n","\n","print(fore.LIGHT_BLUE + style.BOLD + \"Start:                \" + style.RESET, sentences[0])\n","print(fore.LIGHT_BLUE + style.BOLD + \"Tokenize:             \" + style.RESET, input_tokens)\n","print(fore.LIGHT_BLUE + style.BOLD + \"Convert tokens to IDs:\" + style.RESET, input_ids)\n","print(fore.LIGHT_BLUE + style.BOLD + \"Add special tokens:   \" + style.RESET, input_ids_special_tokens)\n","print(fore.LIGHT_BLUE + style.BOLD + \"--------\" + style.RESET)\n","print(fore.LIGHT_BLUE + style.BOLD + \"decode:               \" + style.RESET, decoded_str)\n","# NOTE that these steps don't create the attention mask nor add the special characters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9c1IzGETLYc","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"be7c7c9a-aac8-4742-b294-950489a26f8f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[38;5;12m\u001b[1mNumber of tokens:\u001b[0m 11\n","\u001b[38;5;12m\u001b[1mIds:\u001b[0m [0, 100, 437, 2283, 7, 489, 2239, 59, 34379, 328, 2]\n","\u001b[38;5;12m\u001b[1mTokens:\u001b[0m ['<s>', 'I', \"'m\", 'ƒ†excited', 'ƒ†to', 'ƒ†keep', 'ƒ†learning', 'ƒ†about', 'ƒ†Transformers', '!', '</s>']\n","\u001b[38;5;12m\u001b[1mSpecial tokens mask:\u001b[0m [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"]}],"source":["# For Fast Tokenizers, there's another option too:\n","inputs = tokenizer._tokenizer.encode(sentences[0])\n","\n","print(fore.LIGHT_BLUE + style.BOLD + \"Number of tokens:\" + style.RESET, len(inputs))\n","print(fore.LIGHT_BLUE + style.BOLD + \"Ids:\" + style.RESET, inputs.ids)\n","print(fore.LIGHT_BLUE + style.BOLD + \"Tokens:\" + style.RESET, inputs.tokens)\n","print(fore.LIGHT_BLUE + style.BOLD + \"Special tokens mask:\" + style.RESET, inputs.special_tokens_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NmbTyulTQDa","colab":{"base_uri":"https://localhost:8080/","height":347},"outputId":"64227456-a7fb-401d-9463-ec6165487edd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[38;5;12m\u001b[1mPad token:\u001b[0m <pad>\n","\u001b[38;5;12m\u001b[1mPad token id:\u001b[0m 1\n","\u001b[38;5;12m\u001b[1mPadding:\u001b[0m\n","{\n","    input_ids:\n","        tensor([[    0, 44683,  4489,    32,    10,  6587,   169,     7,   253,   110,\n","           183,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1],\n","        [    0,  2515,  3033,    15, 34546, 29553,  1214,     8,    14,  2551,\n","             7,  3922,    70,     9,    69, 31083, 14186,     4,   970,    16,\n","           117,   357,  2157,    87, 19311,    23,    10,  2204,    19,  1367,\n","          2473,     4,     2]])\n","    attention_mask:\n","        tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","}\n"]}],"source":["# We can pass multiple strings into the tokenizer and pad them as we need\n","model_inputs = tokenizer([\"Situps are a terrible way to end your day.\",\n","                          \"She lived on Monkey Jungle Road and that seemed to explain all of her strangeness.\" +\\\n","                          \"There is no better feeling than staring at a wall with closed eyes.\",\n","                         ],\n","                         return_tensors=\"pt\",\n","                         padding=True,\n","                         truncation=True)\n","print(fore.LIGHT_BLUE + style.BOLD + \"Pad token:\" + style.RESET, tokenizer.pad_token)\n","print(fore.LIGHT_BLUE + style.BOLD + \"Pad token id:\" + style.RESET, tokenizer.pad_token_id)\n","print(fore.LIGHT_BLUE + style.BOLD + \"Padding:\" + style.RESET)\n","print_encoding(model_inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xe8eFhrXTR2r","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"ae3dde1d-0203-432e-e02f-58f76dee97bb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[38;5;12m\u001b[1mBatch Decode:\u001b[0m\n","['<s>Situps are a terrible way to end your day.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<s>She lived on Monkey Jungle Road and that seemed to explain all of her strangeness.There is no better feeling than staring at a wall with closed eyes.</s>']\n","\n","\u001b[38;5;12m\u001b[1mBatch Decode: (no special characters)\u001b[0m\n","['Situps are a terrible way to end your day.', 'She lived on Monkey Jungle Road and that seemed to explain all of her strangeness.There is no better feeling than staring at a wall with closed eyes.']\n"]}],"source":["# We can also decode a whole batch at once:\n","print(fore.LIGHT_BLUE + style.BOLD + \"Batch Decode:\" + style.RESET)\n","print(tokenizer.batch_decode(model_inputs.input_ids))\n","print()\n","print(fore.LIGHT_BLUE + style.BOLD + \"Batch Decode: (no special characters)\" + style.RESET)\n","print(tokenizer.batch_decode(model_inputs.input_ids, skip_special_tokens=True))"]},{"cell_type":"markdown","metadata":{"id":"uPbO_GMBTW80"},"source":["For more information about tokenizers, you can look at:\n","[Hugging Face Transformers Docs](https://huggingface.co/docs/transformers/main_classes/tokenizer) and the [Hugging Face Tokenizers Library](https://huggingface.co/docs/tokenizers/python/latest/quicktour.html) (for the Fast Tokenizers)."]},{"cell_type":"markdown","metadata":{"id":"GqYp6QAA3esJ"},"source":["####¬†<font color='#2B4865'>*1.1.3. Models*</font>"]},{"cell_type":"markdown","metadata":{"id":"NlmPN38ksPY4"},"source":["##### <font color='#2B4865'>**Configuration objects**</font>"]},{"cell_type":"markdown","metadata":{"id":"ikcL_lIu06_x"},"source":["We can check the **configuration of a Transformer model** by loading its associated **configuration object**, which contains many **attributes** that were used to build the model. \n","\n","We could **create a model from the default configuration**, but it gets initialized with random values. While the model can be used in this state, it will output nonsense, as it needs to be trained first."]},{"cell_type":"markdown","source":["Un modelo NLP transformer tiene una configuraci√≥n dada. Podemos verla obteniendo el objeto config del mismo.\n","\n","Al generar el modelo le podemos pasar el objeto config modificado por nosotros para adaptarlo a nuestras necesidades. Podemos no pasarle nada pero el archivo config se inicializa con valores aleatorios.\n","\n","Tras esto el modelo se podr√° utilizar pero, l√≥gicamente, necesitamos entrenarlo para que de resultados con sentido."],"metadata":{"id":"jWXqZ_671b1w"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3HPPwYZspZu","colab":{"base_uri":"https://localhost:8080/","height":416},"outputId":"f787a1c5-41ab-4691-a403-69d707494caa"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["RobertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.25.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}],"source":["from transformers import RobertaConfig, RobertaModel\n","\n","# Building the config\n","config = RobertaConfig()\n","\n","# Building the model from the config\n","model = RobertaModel(config)\n","\n","print(config)"]},{"cell_type":"markdown","metadata":{"id":"G8uGfSzTj-BC"},"source":["##### <font color='#2B4865'>**Loading pretrained models**</font>"]},{"cell_type":"markdown","metadata":{"id":"_jJ2EWn90-KY"},"source":["As an alternative to loading models from their configuration object, we can initialize them in a very similar way as we did with tokenizers. We can either use the model class specific to our model or an ``AutoModel`` class. Both of them also have a ``from_pretrained()`` method. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vf_mBCIkBpF","colab":{"base_uri":"https://localhost:8080/","height":225},"outputId":"385b2910-fd94-4e15-df79-3a323142a839"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at siebert/sentiment-roberta-large-english were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at siebert/sentiment-roberta-large-english and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModel\n","\n","model = AutoModel.from_pretrained(checkpoint_name)"]},{"cell_type":"markdown","metadata":{"id":"62to6RT-kTqv"},"source":["The model object we have instantiated in the former cell contains only the **base Transformer module: given some inputs, it outputs what we will call hidden states, also known as features**. For each model input, we will retrieve a high-dimensional vector representing the contextual understanding of that input by the Transformer model. While these hidden states can be useful on their own, they are usually inputs to another part of the model, known as the **head**. We can **perform different tasks with the same Transformer architecture**, but each of these tasks will have a **different head associated** with it.\n"]},{"cell_type":"markdown","metadata":{"id":"rlAy1UbGgd2C"},"source":["##### <font color='#2B4865'>**Transformer module output**</font>"]},{"cell_type":"markdown","metadata":{"id":"cVTgJmgC1BbP"},"source":["The vector output by the Transformer module is usually large. It generally has **three dimensions:**\n","*  **Batch size:** The number of sequences processed at a time ($2$ in our ``sentences`` example).\n","*  **Sequence length:** The length of the numerical representation of the sequence ($11$ in our ``sentences`` example).\n","*  **Hidden size:** The vector dimension of each model input.\n","\n","It is said to be **\"high dimensional\"** because of the last value. The hidden size can be very large ($768$ is common for smaller models, and in larger models this can reach $3072$ or more)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UBq_fUHshE2b","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"edfd9fb9-76f2-4324-8be9-4cf10bf8a6d3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["outputs = model(**tokenized_inputs)"]},{"cell_type":"markdown","metadata":{"id":"o8ffCPoCj6wh"},"source":["The outputs of Transformers models behave like ``namedtuples`` or ``dictionaries``. We can access the elements **by attributes** or **by key** (``outputs[\"last_hidden_state\"]``), or even **by index** if you know exactly where the thing you are looking for is (``outputs[0]``)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_3AiI6Nj3ui","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"5b9cbe4b-a408-4c13-efd3-6f66221f7f58"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["torch.Size([3, 11, 1024])\n","torch.Size([3, 11, 1024])\n","torch.Size([3, 11, 1024])\n"]}],"source":["print(outputs.last_hidden_state.shape)\n","print(outputs[\"last_hidden_state\"].shape)\n","print(outputs[0].shape)"]},{"cell_type":"markdown","metadata":{"id":"JKaGGDcQkSdd"},"source":["##### <font color='#2B4865'>**Model heads**</font>"]},{"cell_type":"markdown","source":["La salida del modelo transformer se envia al modelo head para ser procesada. La salida del transformer nos da de cada frase, cada token su estado oculto; esto se mete al modelo head donde todo acaba produciendo la representaci√≥n final de las frases.\n","\n"],"metadata":{"id":"5GiGxjJO4cje"}},{"cell_type":"markdown","source":["Cada modelo tendr√° una cabeza para cumplir una tarea u otra. Todas se engloban en RobertaModel pero se pueden usar algunas espec√≠ficas como *ForQuestionAnswering"],"metadata":{"id":"wLWzQW9-4420"}},{"cell_type":"markdown","metadata":{"id":"0iugtPw-1GL7"},"source":["The **model heads** take the high-dimensional vector of hidden states as input and project them onto a different dimension. They are usually composed of one or a few linear layers:\n","\n","<br><center><img src=\"https://drive.google.com/uc?id=1WiBnIPx3Z7QoXJoPVtz11_jylmoseF6y\" width=\"60%\"></center><br>\n","\n","The **output of the Transformer model** is sent directly to the **model head** to be processed. In this diagram, the model is represented by its embeddings layer and the subsequent layers. The **embeddings layer** converts **each input ID** in the tokenized input **into a vector** that represents the associated token. The **subsequent layers** manipulate those vectors using the **attention mechanism to produce the final representation of the sentences**.\n","\n","Hence, we will have **a specific \"head\" depending on the task** we are performing. Hugging Face automatically sets up the architecture we need when we specify the model class. For example, we are doing sentiment analysis, so we are going to use `RobertaForSequenceClassification`. If we were going to continue training RoBERTa on its masked-language modeling training objective, we would use `RobertaForMaskedLM`, and if we just wanted the model's representations, maybe for our own downstream task, we could just use `RobertaModel`. Some examples of heads are:\n","\n","```\n","*\n","*ForMaskedLM\n","*ForSequenceClassification\n","*ForTokenClassification\n","*ForQuestionAnswering\n","*ForMultipleChoice\n","...\n","```\n","\n","where `*` can be `AutoModel` or a specific pretrained model (e.g. `DistilBert`)\n","\n","A full list of choices is available in the [docs](https://huggingface.co/docs/transformers/model_doc/auto). Note that not all models are compatible with all model architectures, for example, RoBERTa is not compatible with the Seq2Seq models because it only consists of an encoder."]},{"cell_type":"markdown","metadata":{"id":"EwEx6JLFmUo3"},"source":["For our example, **we need a model with a sequence classification head** (to be able to classify the sentences as positive or negative). So, we won‚Äôt actually use the ``AutoModel`` class, but ``AutoModelForSequenceClassification``:"]},{"cell_type":"markdown","source":["Necesitamos del modelo general Roberta, la mascara de clasificacion de frases.\n","\n","La salida del modelo es de 3x2 (3 frases y los valores,para cada una, de los 2 labels)."],"metadata":{"id":"vQjlnrOk6ooD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-oOIzqL2mXq2","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2cf4eb56-e64d-4ddd-e641-7b16ecb9aa8e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["torch.Size([3, 2])\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint_name)\n","outputs = model(**tokenized_inputs) # model outputs\n","\n","print(outputs.logits.shape) # Since we have just two sentences and two labels, the result we get from our model is of shape 2 x 2."]},{"cell_type":"markdown","metadata":{"id":"bZi3-Aabobn7"},"source":["##### <font color='#2B4865'>**Postprocessing the output**</font>"]},{"cell_type":"markdown","metadata":{"id":"EtQT6TQM1Ip-"},"source":["We refer to the outputs that we get from our model as **logits**, and these don‚Äôt necessarily make sense by themselves:"]},{"cell_type":"markdown","source":["Las salidas de mi modelo se les llama \"logits\" "],"metadata":{"id":"tdyUbN1c644b"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HE49qNwmq7iv","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"6e52f78c-d598-4745-888a-a7eb6db59486"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["tensor([[-3.7951,  2.9662],\n","        [ 3.9312, -3.5583],\n","        [-3.6262,  2.7869]], grad_fn=<AddmmBackward0>)\n"]}],"source":["print(outputs.logits)"]},{"cell_type":"markdown","metadata":{"id":"Z2xbyq1RrNNe"},"source":["Our model predicted $[-3.7951, 2.9662]$ for the first sentence and $[3.9312, -3.5583]$ for the second one. **Those are not probabilities but logits**, that is, the raw and unnormalized scores that the model's last layer outputs. In order to convert them into probabilites, we pass them through a **SoftMax layer**:"]},{"cell_type":"markdown","source":["Los logits no tienen sentido como tal, por ello, los pasamos por una capa SoftMax para darles sentido probabil√≠stico."],"metadata":{"id":"4aqROQj87fOE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0zbuPjErMt8","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"e5c4babf-39fb-48b5-e115-c8a9d85b6637"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Distribution over labels: tensor([[1.1564e-03, 9.9884e-01],\n","        [9.9944e-01, 5.5860e-04],\n","        [1.6373e-03, 9.9836e-01]], grad_fn=<SoftmaxBackward0>)\n"]}],"source":["import torch\n","\n","predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","print(f\"Distribution over labels: {predictions}\")"]},{"cell_type":"markdown","metadata":{"id":"jA12gIOurY0O"},"source":["Now we can see that the model predicted $[0.0012, 0.9998]$ for the first sentence and $[0.9995, 0.0005]$ for the second one, which are now recognizable probability scores.\n","\n","To get the **labels corresponding to each position**, we can inspect the ``id2label`` attribute of the model config:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1stTZYxzrauU","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ebe59fa4-806f-4f4f-c5e8-e666bc6fb225"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{0: 'NEGATIVE', 1: 'POSITIVE'}"]},"metadata":{},"execution_count":25}],"source":["model.config.id2label"]},{"cell_type":"markdown","source":["Con esto ya vemos que los labels de las 3 frases son:\n","Positivo\n","Negativo\n","Positivo"],"metadata":{"id":"nrpakTkU70xr"}},{"cell_type":"markdown","metadata":{"id":"52Bx8608wdGO"},"source":["###¬†<font color='#2B4865'>*1.2. Fine-tuning*</font>"]},{"cell_type":"markdown","metadata":{"id":"c4BuIHUI2_U2"},"source":["Pipeline objects can be used to benefit from transformer models for\n","solving NLP tasks. Though, they sometimes do not provide us with the desired outputs.\n","\n","To fine-tune a general-purpose transformer model to work for specific\n","tasks, we will leverage three Hugging Face components:\n","1. Tokenizers\n","2. Transformers\n","3. Datasets\n","\n","Here we will be **fine-tuning BERT on the IMDB dataset.**"]},{"cell_type":"markdown","source":["Podemos utilizar modelos NLP ya entrenados y tunearlos para usarlos en nuestras tareas espec√≠ficas.\n","\n","Vamos, en este caso, a tunear el modelo BERT para el dataset \"IMDB\" (dataset de reviews de pel√≠culas)"],"metadata":{"id":"1kmQed-QSTyc"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"HCJfyFQyCJE-","outputId":"a38b4a44-7582-404f-a227-9b46d2c4dfb6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["checkpoint_name = \"bert-base-uncased\""]},{"cell_type":"markdown","metadata":{"id":"cW-AeHlH6BgN"},"source":["####¬†<font color='#2B4865'>*1.2.1. Loading in a dataset*</font>"]},{"cell_type":"markdown","metadata":{"id":"9b6Y0Anz7lUe"},"source":["[The Hub ](https://huggingface.co/datasets) contains multiple datasets in many languages. The ü§ó datasets library allows to load local and remote data in several formats, such as CSV, JSON, text files and even parquet (you can check the supported formats in the [documentation](https://huggingface.co/docs/datasets/loading#from-the-huggingface-hub)).\n","\n","The loading of a dataset is carried out through the method ``load_dataset()`` which returns a ``Dataset`` or a ``DatasetDict`` object."]},{"cell_type":"markdown","metadata":{"id":"xA5wFuD0TESB"},"source":["Let's download the IMDB dataset from the Hub:"]},{"cell_type":"markdown","source":["Cargamos el dataset IMDB del HUB con load_dataset (de la librer√≠a datasets)"],"metadata":{"id":"RB6RKzPgTQp8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNLS7QDNTWcy","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["b25166e6ad434deabbb4b6dd2bcd0154","cb17d7e22ac44bac8fabc353bc9803e8","4a3aa0f672d44901a6f8c776ed229549","38f91c4715c24b03b6e309a5f3bd74e0","ed22066780864c0088180148def825d9","554b02b49ce544a3b7ffbc6282bf2ca1","aa3a62ee84084140951a1393a9cf6f90","2e60863116a54be580a1147a82e8306e","059501a771bd4c2087b18f04be1aa781","bd87a0373d0e45a7a3f4f942a3d6d74a","8c5be33a11db4de585663b4d90a372ed"]},"outputId":"250ed477-032a-4bdf-c2d4-0f27c2db86ae"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b25166e6ad434deabbb4b6dd2bcd0154"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 25000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 25000\n","    })\n","    unsupervised: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 50000\n","    })\n","})"]},"metadata":{},"execution_count":38}],"source":["from datasets import load_dataset, DatasetDict\n","\n","imdb_dataset = load_dataset(\"imdb\")\n","imdb_dataset"]},{"cell_type":"markdown","source":["Obtenemos el train, el test y unsupervised (train + test) donde, cada una tiene text (reviews) y label (etiqueta asociada)"],"metadata":{"id":"ll3u7ZcyTexD"}},{"cell_type":"markdown","metadata":{"id":"-EoaYwVcTskJ"},"source":["As you can see, we get a ``DatasetDict`` object with the ``train`` set, the ``test`` set, and a set with both of them included (``unsupervised``). Each of those contains two columns (``text``, ``label``), which are the [**features**](https://huggingface.co/docs/datasets/about_dataset_features) of the dataset (i.e., its internal structure); and a variable number of rows, which are the number of elements in each set.\n","\n","We can **access the data within each feature** in our ``imdb_dataset`` object **by indexing**, like in a dictionary:"]},{"cell_type":"markdown","source":["Tomemos el train y veamos una muestra cualquiera"],"metadata":{"id":"06ad2XfDU7E6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJ-7Dm6kUeoM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fbd4aa19-3dbb-4257-a140-c57e9b110feb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n"," 'label': 0}"]},"metadata":{},"execution_count":39}],"source":["imdb_train_dataset = imdb_dataset[\"train\"]\n","imdb_train_dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"Nas1R-opUoyI"},"source":["We can also inspect our dataset's features through the ``features`` attribute.\n","We can see that the labels are already integers, so we do not need any preprocessing here. We can also observe that ``label`` is of type [``ClassLabel``](https://huggingface.co/docs/datasets/v2.7.1/en/package_reference/main_classes#datasets.ClassLabel): 0 corresponds to ``neg``, and 1 to ``pos``."]},{"cell_type":"markdown","source":["Accedemos al feature y vemos que la clasificaci√≥n es binaria ; negativo o positivo."],"metadata":{"id":"uADhdUZfU_36"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8fw2buP-U6x6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1d927d9-6fb9-4005-caed-ebb1f925c8b1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'text': Value(dtype='string', id=None),\n"," 'label': ClassLabel(names=['neg', 'pos'], id=None)}"]},"metadata":{},"execution_count":40}],"source":["imdb_train_dataset.features"]},{"cell_type":"markdown","metadata":{"id":"yvKGwR5qNfN6"},"source":["For our tasks, we will not be using the ``unsupervised`` column. However, it will be of use to have a **validation set** in addition to our train and test sets. Let's generate such a validation set from the test set. For this, we will use the Hugging Face datasets' function ``train_test_split()``, which creates train and test splits if your dataset doesn‚Äôt already have them."]},{"cell_type":"markdown","source":["Dividimos el test en 50% test, 50% validation"],"metadata":{"id":"agsAmtcEVRYR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rdsfe2b7NfN7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d20260b-76a3-4b82-ba13-f497f3c5dd3f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-0d750cc997d17d84.arrow and /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f50324fdfad826f7.arrow\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 12500\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 12500\n","    })\n","})"]},"metadata":{},"execution_count":41}],"source":["from sklearn.model_selection import train_test_split\n","\n","test_valid = imdb_dataset[\"test\"].train_test_split(test_size=0.5, seed=42)\n","test_valid"]},{"cell_type":"markdown","metadata":{"id":"QNlxp-PBNfN7"},"source":["Also, to make the training more straightforward and faster, we will extract a subset of the train, test, and validation datasets. For that purpose, we will use the Hugging Face Dataset object's methods `select()` and ``shuffle()``. The first allows us to take some data points by their index, and the second randomly rearrange the column values. Here we will be selecting $2000$ training rows, and $500$ of test and validation, respectively. You can play with the number of data points but consider that this will increase the training time."]},{"cell_type":"markdown","source":["Para entrenar r√°pido, tomamos 2000 muestras de train y 1000 de test y validaci√≥n. SOLO."],"metadata":{"id":"goeiYpFsVebC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vn5rILJrNfN8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6685bcb1-b8c4-46ab-9293-9f48d7af601d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-8a9e43a6ac4acdff.arrow\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","test_valid = imdb_dataset[\"test\"].train_test_split(test_size=0.5)\n","imdb_dataset = DatasetDict({\n","    \"train\": imdb_dataset[\"train\"].shuffle(seed=42).select(range(2000)),\n","    \"test\": test_valid[\"train\"].shuffle(seed=42).select(range(1000)),\n","    \"val\": test_valid[\"test\"].shuffle(seed=42).select(range(1000)),\n","    })"]},{"cell_type":"markdown","metadata":{"id":"rn9vED2grPb_"},"source":["For future use, we will save the test text and labels separately in two lists:"]},{"cell_type":"markdown","source":["Guardamos el texto y las labels de test en listas separadas para analizar el modelo y su capacidad m√°s adelante"],"metadata":{"id":"9TTyMJH8VpZr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_Z6sT7VyYAO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b5ffffa-e78f-44f1-d52d-348b52d367d8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["test_texts = [imdb_dataset['test'][i]['text'] for i in range(len(imdb_dataset['test']))]\n","test_labels = [imdb_dataset['test'][i]['label'] for i in range(len(imdb_dataset['test']))]"]},{"cell_type":"markdown","metadata":{"id":"Rjodv027-I_Q"},"source":["####¬†<font color='#2B4865'>*1.2.2. Dataset preprocessing*</font>"]},{"cell_type":"markdown","metadata":{"id":"9_2iHJ2XWftB"},"source":["Same as we did when we were making inference, we need to convert the text of our dataset to numbers the model can make sense of. This preprocessing is also carried out through **Tokenizers**.\n","\n","Some things to take into account when we are approaching this are:\n","* If we are working with **sentence pairs**, we need to handle the two sequences as a pair and apply the appropriate preprocessing. Fortunately, the tokenizer can make this for us in the way our model expects. Yet, for the case we are dealing with right now, we will not be using this.\n","* To keep the data as a dataset, instead of a dictionary (it will only work if we have enough RAM to store the whole dataset during tokenization), we utilize the method ``Dataset.map()``, which works by applying a function on each dataset‚Äôs element. This function takes a dictionary (like the items of our dataset) and returns a new dictionary with the keys the tokenizer returns (here, ``input_ids`` and ``attention_mask``).\n","* By using the option ``batched=True`` in the map call allows applying the custom function to multiple elements of the dataset at once, thus greatly speeding up the tokenization."]},{"cell_type":"markdown","metadata":{"id":"_96WtMQFr6wa"},"source":["For the case of the IMDB dataset, we will be tokenizing the ``text`` field of the dataset by allowing truncation. To do so, we can define a custom ``tokenize_function`` and apply it to the whole dataset via the ``Dataset.map()`` function mentioned above:"]},{"cell_type":"markdown","source":["Tomamos un tokenizador pre-entrenado y tokenizamos nuestro dataset"],"metadata":{"id":"39mdEDs1ZU8X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxHR9yIBZFxd","colab":{"base_uri":"https://localhost:8080/","height":396,"referenced_widgets":["a377a5afbb074c69989fcb2696e6d6ca","dd9cbf39e2374ee3a048deb5a8bbda55","d35d48c5340341378b972452e9eadc64","f5d461ed447d46b68aecbabadd4d6554","f6d73c41b55e44ae946702a77c7e3c08","de68f97bf7784eca8ce06225c77c5e08","a38d887a9ba34d89ac70f4729c4291ab","ed55107b52b5497785dcc7e57c7a0618","10d90b0756e04e0289c6a56359308222","ff72b436dfb64b938fd4f73a9a5bce7d","ebd7fdcac4e84dc8b2e6f45d6681c1d5","18cf58a65e3e47d4bd6b6e16d4c3c59a","3d8669a8ec9c4cb284b01f7da946b924","ce5b990ae26b442a9b35fe6f9d5e769a","ffd39d499b8f45e989595c4f1be601d3","6eda56bddc5c497986ffc3c2abb574b8","dfbf1f9febca4368ac90dd8bc49e8e36","af210a23e0914ceb83834bd9c9e798d7","61d938a61dba44979d8043b0f39f9177","8fce3faf27f64e7c946e9314e0394de2","353f3589270b4d12b3ece30f03cb0bfe","7e8c8bc54e094428927d50f5c7dc402f"]},"outputId":"22225da4-5221-42b7-8aeb-465d90aac13b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-92db4736c5780a75.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a377a5afbb074c69989fcb2696e6d6ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18cf58a65e3e47d4bd6b6e16d4c3c59a"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 2000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1000\n","    })\n","    val: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1000\n","    })\n","})"]},"metadata":{},"execution_count":44}],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained(checkpoint_name)\n","\n","def tokenize_function(example):\n","  return tokenizer(example[\"text\"], truncation=True) # Truncamos cuando llegamos al limite de texto a tokenizar\n","\n","tokenized_imdb_dataset = imdb_dataset.map(tokenize_function, batched=True) # Aplicamos la tokenizacion con batched a varias frases a la vez ; mejora gasto computacional\n","tokenized_imdb_dataset"]},{"cell_type":"markdown","metadata":{"id":"KGMCkgyNDuOB"},"source":["Once we have carried out the tokenization, we need to remove all the text features that are in the dataset since from now on we are going to be working with tensors and we can‚Äôt create tensors with strings. We can achieve this through the Dataset's function ``remove_columns()``. In addition, the model expected a field named ``labels`` with the true samples' labels; we have these labels but saved within a field named ``label``, so we just need to rename it. We achieve this with the ``rename_column`` function. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pU-Ai2M8Dx0N","colab":{"base_uri":"https://localhost:8080/","height":260},"outputId":"2fbeaa1f-df57-40e4-c684-e793979ed187"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 2000\n","    })\n","    test: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1000\n","    })\n","    val: Dataset({\n","        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1000\n","    })\n","})"]},"metadata":{},"execution_count":45}],"source":["# Remove text features\n","tokenized_imdb_dataset = tokenized_imdb_dataset.remove_columns([\"text\"])\n","# Rename \"label\" to \"labels\" as expected by the model\n","tokenized_imdb_dataset = tokenized_imdb_dataset.rename_column(\"label\", \"labels\")\n","tokenized_imdb_dataset"]},{"cell_type":"markdown","metadata":{"id":"YNI-6UCq-PRV"},"source":["#####¬†<font color='#2B4865'>**Dynamic padding**</font>"]},{"cell_type":"markdown","metadata":{"id":"qCbLC3HSaXjK"},"source":["Padding all the samples to the maximum length as we saw before is not efficient. As an alternative, we can **pad the samples at batch building time**. Hence, we only need to pad to the maximum length in that batch, and not the maximum length in the entire dataset. For doing so:\n","* We define a **collate function** that will apply the correct amount of padding to the items of the dataset we want to batch together\n","* The Transformers library provides us with such a function: ``DataCollatorWithPadding``."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8oBKQDKbHzJ","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"72f16969-0688-4ab3-a048-1786e33803f4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"EedB1GRQDObG"},"source":["Let's take some samples from the training dataset and check how the data_collator works. "]},{"cell_type":"markdown","source":["Normalmente hacemos un padding de manera que toda frase se rellene con tokens nulos hasta llegar a la length de la frase m√°s larga del corpus (para poder ser usados).\n","\n","Sin embargo, esto es poco eficiente y, generalmente, se utiliza dynamic paddding donde se aplica el padding pero solo en batches de \"x\" frases.\n","\n","Ejemplo:"],"metadata":{"id":"IP0a3NanbV__"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbfYPXzgbwBW","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e31f1e05-498a-4f5c-b931-18163160bc86"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[179, 159, 237, 163, 512, 266, 138, 239]"]},"metadata":{},"execution_count":47}],"source":["samples = tokenized_imdb_dataset[\"train\"][:8]\n","[len(x) for x in samples[\"input_ids\"]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAdgP5Upb8aT","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"40f7b997-c45c-42db-c187-4b87346cd8e7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'labels': torch.Size([8]),\n"," 'input_ids': torch.Size([8, 512]),\n"," 'token_type_ids': torch.Size([8, 512]),\n"," 'attention_mask': torch.Size([8, 512])}"]},"metadata":{},"execution_count":48}],"source":["batch = data_collator(samples)\n","{k: v.shape for k, v in batch.items()}"]},{"cell_type":"markdown","source":["Ha funcionado ya que el padding ha sido solo al max length del batch, 512."],"metadata":{"id":"TJVasVz3bsT9"}},{"cell_type":"markdown","metadata":{"id":"m3_mNcMBcRsP"},"source":["We can observe how the dynamic padding is working properly: each sample in the batch is padded to a length of $512$, the maximum length inside the batch. Without dynamic padding, all of the samples would have to be padded to the maximum length in the whole dataset, or the maximum length the model can accept."]},{"cell_type":"markdown","metadata":{"id":"SuHSF8Yt-p86"},"source":["####¬†<font color='#2B4865'>*1.2.3. Fine-tuning*</font>"]},{"cell_type":"markdown","metadata":{"id":"31i597dz6P4d"},"source":["To train a model, we can just use the same kind of training loop that we would use in Pytorch. ü§ó models are also ``torch.nn.Module``s so backpropagation happens the same way and you can even use the same optimizers. However, we will not be covering this functionality in this tutorial, but we will use the Hugging Face ``Trainer`` class with which we can handle most needs."]},{"cell_type":"markdown","metadata":{"id":"vnuSKhXXmFOv"},"source":["#####¬†<font color='#2B4865'>**Training**</font>"]},{"cell_type":"markdown","source":["Entrenaremos como con Pytorch en DeepLearning pero no cubriremos esto, sino que usaremos directamente la clase trainer para entrenar.\n","\n","E√± primer paso es definir los TrainerArguments (n_epocas, tama√±o batches, ....)"],"metadata":{"id":"M8_WG1Xtck3F"}},{"cell_type":"markdown","metadata":{"id":"fmKn5h5DoKug"},"source":["The **first step** before defining our ``Trainer`` is to define a ``TrainerArguments`` class, where we can specify different training parameters like how often to evaluate and save model checkpoints, where to save them, etc.  There are [many aspects](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments) that you can customize, the most important being:\n","\n","| Parameter | Explanation |\n","|-----------| ------------|\n","| num_train_epochs | total number of training epochs (how many times to pass through the entire dataset; too much can cause overfitting) |\n","| per_device_train_batch_size | batch size per device during training |\n","| per_device_eval_batch_size |  batch size for evaluation |\n","|  warmup_steps |  number of warmup steps for learning rate scheduler |\n","| weight_decay | strength of weight decay (reduces size of weights, like regularization) |\n","| output_dir | output directory for the fine-tuned model and configuration files |\n","| logging_dir | directory for storing logs |\n","| logging_steps | how often to print logging output (so that we can stop training early if the loss isn't going down) |\n","| evaluation_strategy | evaluate while training so that we can see the accuracy going up |\n","\n","Yet, the **only mandatory argument to be provided** is a directory where the trained model will be saved, as well as the checkpoints along the way. For all the rest, you can leave the defaults, which should work pretty well for basic fine-tuning."]},{"cell_type":"markdown","source":["Sin embargo, el √∫nico argumento obligatorio es el directorio donde vamos a guardar el modelo entrenado (tanto el final como los puntos de control por el camino). Para el resto, se puede dejar los valores predeterminados.\n","\n","Guardamos un objeto de training con los par√°metros especificados."],"metadata":{"id":"KjFIgjerdE7l"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXTZGT6EoidS","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"c459ff06-7704-4960-db60-62276f7e8616"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(output_dir=f\"{checkpoint_name}-finetuned-imdb\")"]},{"cell_type":"markdown","metadata":{"id":"AYUAEZ4Hoq07"},"source":["The **second step** is to define our model. We will be using the same **AutoModelForSequenceClassification** class that we used during inference, with two labels, but now with the BERT checkpoint:"]},{"cell_type":"markdown","source":["Ahora definimos nuestro modelo (utilizamos el modelo pre-entrenado de clf de secuencias)"],"metadata":{"id":"ewp1bfRjfeEb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"njANZ_DQoycK","colab":{"base_uri":"https://localhost:8080/","height":292,"referenced_widgets":["74dfc9eb73504585899109c4d74c68eb","c339fd8726d44eaeb5757db2745ab781","bcc42c3c6f8843fe8a7a00b3a64d673f","7b6fae2668b24bb79880d620d0ba725c","721a0d53ff41484082e4fb659b352f41","86d1054579dd4235ad4e8c23417d4301","7dd3f910d4a04f9b84f3ce64acd288fe","4904899eb32a42f8933720b53a755325","deb1e9d1364d42d88f085e5b833dc6ad","74d25413d2e743bf91b030fe72c85863","7ab78d3c4dfb4bc89c2af238a0794d47"]},"outputId":"3881a9ae-3d9e-40b7-fd12-6bac0292c57b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74dfc9eb73504585899109c4d74c68eb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint_name, num_labels=2)"]},{"cell_type":"markdown","metadata":{"id":"zN4MZW7OF8V_"},"source":["You will notice after executing the former cell that you **get a warning after instantiating the pretrained model**. This is because BERT has not been pretrained on classifying pairs of sentences but on a masked language modeling objective, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head). It concludes by encouraging you to train the model, which is exactly what we are going to do now."]},{"cell_type":"markdown","metadata":{"id":"ZSnllE_7oWJP"},"source":["Once we have our model, we can create a **Trainer** instance by passing it all the objects constructed up to now:\n","\n"]},{"cell_type":"markdown","source":["Podemos crear el trainer pasandole el modelo, los ajustes de entrernamiento y el dastaset de entrenamiento y validaci√≥n as√≠ como el tokenizador"],"metadata":{"id":"PiY1zuByf2JT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAa8DMZJpafL","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"d65c3a3c-0372-411c-db15-0696630cf257"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_imdb_dataset[\"train\"],\n","    eval_dataset=tokenized_imdb_dataset[\"val\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"markdown","metadata":{"id":"pVGx4kxhieaO"},"source":["To start the fine-tuning, we would just need to invoke the ``train()`` method of our Trainer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8eA_24Vjqeq","colab":{"base_uri":"https://localhost:8080/","height":471},"outputId":"c8a5a1f3-9b60-45ce-b619-151d8aa3535d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 2000\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 750\n","  Number of trainable parameters = 109483778\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 08:38, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.342200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to bert-base-uncased-finetuned-imdb/checkpoint-500\n","Configuration saved in bert-base-uncased-finetuned-imdb/checkpoint-500/config.json\n","Model weights saved in bert-base-uncased-finetuned-imdb/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-imdb/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-imdb/checkpoint-500/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=750, training_loss=0.2668477554321289, metrics={'train_runtime': 522.2782, 'train_samples_per_second': 11.488, 'train_steps_per_second': 1.436, 'total_flos': 1467987022278720.0, 'train_loss': 0.2668477554321289, 'epoch': 3.0})"]},"metadata":{},"execution_count":52}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"OrY14qmJj-Ox"},"source":["The former call reports the training loss every 500 steps, but it does not tell us how well our model is performing since we have not specified how the evaluation is going to take place."]},{"cell_type":"markdown","metadata":{"id":"oR1_k25kmFYU"},"source":["#####¬†<font color='#2B4865'>**Evaluation**</font>"]},{"cell_type":"markdown","metadata":{"id":"xuKGMZvPgnfC"},"source":["Regarding the evaluation, there are two last aspects to take care of:\n","\n","1.   The **evaluation strategy during the training**. We can set it through the Trainer's parameter ``evaluation_strategy``to either ``steps`` (evaluate every eval_steps) or ``epoch`` (evaluate at the end of each epoch).\n","2.   The **metric to calculate during said evaluation**. Here, there are two possible actions that we can carry out. If we create the Trainer instance without specifying anything on the ``compute_metrics`` parameter, the evaluation will be based on the loss. Otherwise, we can define a ``compute_metrics()`` and pass it to the trainer, then the evaluation will be based on the metric specified in such a function. For this case, we will be using an ad-hoc ``compute_metrics()`` function."]},{"cell_type":"markdown","metadata":{"id":"NM_XlSqBqnuU"},"source":["The ``compute_metrics()``function must take an ``EvalPrediction`` object, that is, a ``namedtuple`` with two fields:\n","* ``predictions``\n","*``label_ids`` \n","\n","and return a **dictionary mapping strings to floats**, where:\n","* The **strings** are the names of the metrics returned\n","* The **floats** are their values\n","\n","To get some predictions from our model, we can use the Trainer's method ``predict()``. The output of this method is another ``namedtuple`` with three fields:\n","* ``predictions``\n","* ``label_ids``\n","* ``metrics``\n","\n","The ``metrics`` field contains the loss on the dataset passed, as well as some time metrics (how long it took to predict, in total and on average). Once we complete our ``compute_metrics()`` function and pass it to the Trainer, that field will also contain the metrics returned by ``compute_metrics()``."]},{"cell_type":"markdown","source":["Vamos a usar el trainer (que es el modelo pre-entrenado pero entrenado a nuestro dataset en concreto) para predecir las salidas del conjunto de validaci√≥n"],"metadata":{"id":"89l5b28NjS5A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGK2-lct6r3t","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"a7e926bb-b77a-48b7-dd70-670879e36bca"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 1000\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1000, 2) (1000,)\n"]}],"source":["predictions = trainer.predict(tokenized_imdb_dataset[\"val\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"markdown","metadata":{"id":"lD0zpvtoq1ZD"},"source":["As you can see, ``predictions`` is a **two-dimensional array** with shape $1000 \\times 2$ ($1000$ being the number of elements in the validation dataset we used). Those are the logits for each element of the dataset we passed to ``predict()``. To transform them into predictions that we can compare to our labels, we need to take the **index with the maximum value on the second axis**:"]},{"cell_type":"markdown","source":["Nos da en las predicciones, para cada una de las 1k frases los logits de ambos labels; los pasamos por un argmax para obtener el label que toca de cada frase"],"metadata":{"id":"ezth_T3HjfGw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILzNWYu6q3Cw","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"23ad783f-7279-4187-c80d-cf22412d3255"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["import numpy as np\n","\n","preds = np.argmax(predictions.predictions, axis=1)"]},{"cell_type":"markdown","metadata":{"id":"4m4twsL6q5Pa"},"source":["We can now compare those ``preds`` to the ``labels`` that we have available in our dataset. To build our ``compute_metric()`` function, we will rely on the ``accuracy`` metric from Sklearn."]},{"cell_type":"markdown","source":["Podemos comparar los labels verdaderos con las predicciones y estudiar el accuracy_de_validacion"],"metadata":{"id":"t3j-sZx0jwuJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHmZtGsZq7Ud","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0f7f0967-1ff4-408e-d4b7-d05109fd9fbd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["0.913"]},"metadata":{},"execution_count":55}],"source":["from sklearn.metrics import accuracy_score\n","\n","labels = tokenized_imdb_dataset[\"val\"][\"labels\"]\n","\n","accuracy_score(y_true=labels, y_pred=preds)"]},{"cell_type":"markdown","source":["  Nice!"],"metadata":{"id":"noMDAVOMj3LH"}},{"cell_type":"markdown","metadata":{"id":"3ZDQW5X1mFgY"},"source":["#####¬†<font color='#2B4865'>**Callbacks**</font>"]},{"cell_type":"markdown","metadata":{"id":"hR4PxG0vmGOP"},"source":["Hugging Face Transformers also allows you to write \n","\n","**Callbacks** if you want certain things to happen at different points during training (e.g. after evaluation or after an epoch has finished). For example, there is a callback for early stopping:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgLYuq2Nw0P1","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"ea02eb02-68a5-4452-b6ea-769f68de4159"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["from transformers import EarlyStoppingCallback\n","\n","trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=1, early_stopping_threshold=0.0))"]},{"cell_type":"markdown","metadata":{"id":"q3jkULelw5pW"},"source":["We can add the callback after the training has been instantiated, as shown in the cell above, or while creating the Trainer object by passing it to the ``callbacks`` parameter. Take into account that to use a callback, you must set the ``load_best_model_at_end`` argument in the instantiation of the ``TrainingArguments`` object to ``True``.\n","\n","For more information on callbacks see [here](https://huggingface.co/docs/transformers/main_classes/callback#transformers.TrainerCallback)."]},{"cell_type":"markdown","metadata":{"id":"SrpOxEIgm1Wp"},"source":["#####¬†<font color='#2B4865'>**Some practical tips for finetuning**</font>"]},{"cell_type":"markdown","source":["Se puede hacer busca grid de hiperpar√°metros. Algunos ejemplos:"],"metadata":{"id":"WuZjLZSwpAHN"}},{"cell_type":"markdown","metadata":{"id":"kZH6jrb_7UHt"},"source":["**Good default hyperparameters.** The hyperparameters will depend on your task and dataset. You should do a hyperparameter search to find the best ones. That said, here are some good initial values for fine-tuning.\n","* **Epochs**: {2, 3, 4} (larger amounts of data need fewer epochs)\n","* **Batch size:** bigger is better (as large as you can make it)\n","* **Optimizer:** AdamW\n","* **AdamW learning rate:** {2e-5, 5e-5}\n","* **Learning rate scheduler:** linear warm-up for first {0, 100, 500} steps of training\n","* **weight_decay (l2 regularization):** {0, 0.01, 0.1}\n","\n","You should monitor your validation loss to decide when you've found good hyperparameters.\n","\n","There's a lot more that we can integrate into the Trainer to make it more useful. You can check out [this link](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer) for more information about it."]},{"cell_type":"markdown","metadata":{"id":"y-ozu4lZ_P0X"},"source":["####¬†<font color='#2B4865'>*1.2.4. Full training*</font>"]},{"cell_type":"markdown","metadata":{"id":"ylVh-FiKoCjH"},"source":["<font color='#2B4865'><u>**REACP: TRAINER API FINE-TUNING STEPS**</u></font>\n","1. Define ``TrainingArguments`` class to harbor the hyperparameters that\n","the Trainer will use for training and evaluation and specify the\n","evaluation strategy to be used.\n","2. Define the Transformer model to be used.\n","3. Build a ``compute_metrics()`` function to evaluate the performance of\n","the model at training time based on metrics from the ``Evaluate`` library. Otherwise, the evaluation will be based on the loss.\n","4. Define a ``Trainer`` by passing the model, the training arguments,\n","training and validation datasets, the tokenizer, the collator and the\n","``compute_metrics()`` function.\n","5. Add additional callbacks if desired.\n","5. Invoke ``trainer.train()``."]},{"cell_type":"markdown","source":["Entrenamiento al completo: Definimos los par√°metros de train, el modelo, la forma de evaluar el modelo (en este caso con accuracy), creamos el trainer, a√±adimos callback si hace falta y entrenamos."],"metadata":{"id":"XvuhQTt0pUgd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RTNh2EQkiCsM","colab":{"base_uri":"https://localhost:8080/","height":780},"outputId":"118c2f78-12dd-4744-d9b1-11f63494087a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 2000\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 625\n","  Number of trainable parameters = 109483778\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='250' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/625 07:09 < 10:48, 0.58 it/s, Epoch 2/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.082800</td>\n","      <td>0.401087</td>\n","      <td>0.918000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.046600</td>\n","      <td>0.492312</td>\n","      <td>0.902000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 16\n","Saving model checkpoint to bert-base-uncased-finetuned-imdb/checkpoint-125\n","Configuration saved in bert-base-uncased-finetuned-imdb/checkpoint-125/config.json\n","Model weights saved in bert-base-uncased-finetuned-imdb/checkpoint-125/pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-imdb/checkpoint-125/tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-imdb/checkpoint-125/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 16\n","Saving model checkpoint to bert-base-uncased-finetuned-imdb/checkpoint-250\n","Configuration saved in bert-base-uncased-finetuned-imdb/checkpoint-250/config.json\n","Model weights saved in bert-base-uncased-finetuned-imdb/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in bert-base-uncased-finetuned-imdb/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in bert-base-uncased-finetuned-imdb/checkpoint-250/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from bert-base-uncased-finetuned-imdb/checkpoint-125 (score: 0.918).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=250, training_loss=0.06471184921264649, metrics={'train_runtime': 430.4287, 'train_samples_per_second': 23.233, 'train_steps_per_second': 1.452, 'total_flos': 1039444890861120.0, 'train_loss': 0.06471184921264649, 'epoch': 2.0})"]},"metadata":{},"execution_count":57}],"source":["from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n","                             recall_score)\n","from transformers import Trainer\n","from transformers import EarlyStoppingCallback\n","\n","\n","training_args = TrainingArguments(\n","    output_dir=f\"{checkpoint_name}-finetuned-imdb\",\n","    per_device_train_batch_size=16,                                             # The batch size per GPU/TPU core/CPU for training\n","    per_device_eval_batch_size=16,                                              # The batch size per GPU/TPU core/CPU for validation\n","    num_train_epochs=5,                                                         # Total number of training epochs to perform\n","    evaluation_strategy=\"epoch\",                                                # During training evaluation strategy: here, evaluation is done at the end of each epoch\n","    logging_strategy=\"epoch\",                                                   # Logging strategy to adopt during training: here, logging is done at the end of each epoch\n","    save_strategy=\"epoch\",                                                      # Checkpoint save strategy to adopt during training: here, save is done at the end of each epoch\n","    learning_rate=2e-5,                                                         # The initial learning rate for AdamW optimizer\n","    load_best_model_at_end=True,                                                # Whether or not to load the best model found during training at the end of training: here, yes\n","    metric_for_best_model='accuracy',                                           # Metric to use to compare two different models.\n","    seed=42,                                                                    # Random seed that will be set at the beginning of training\n",")\n","\n","def compute_metrics(eval_preds):\n","    '''Evaluation function based on accuracy'''\n","    pred, labels = eval_preds\n","    pred = np.argmax(pred, axis=-1)\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","\n","    return {\"accuracy\": accuracy}\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_imdb_dataset['train'],\n","    eval_dataset=tokenized_imdb_dataset['val'],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics, # evaluaci√≥n de m√©tricas\n","    callbacks = [EarlyStoppingCallback(early_stopping_patience=1, early_stopping_threshold=0.0)] # callbacks (early stoping)\n",") # con este call back, cada √©poca para para estudiar el modelo de validaci√≥n usando compute_metrics\n","# a su vez, el entrenamiento para en cuanto empeora el val accuracy respecto a la iter anterior (as√≠ nos quedamos con el mejor modelo) ; para eso es el threshold de cuanto puede empeorar sin que pare\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"dKfy-3qGt3R2"},"source":["Once trained, evaluating the model is straightgforward:"]},{"cell_type":"markdown","source":["Con .evaluate() al modelo entrenado podemos estudiar todas las m√©tricas del modelo.\n","\n"],"metadata":{"id":"t60BQsWprfFb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lravXYVsjNvh","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"7ba294fe-b9bd-40b4-d9d5-c1fe11ccc699"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 1000\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:29]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 0.4010871946811676, 'eval_accuracy': 0.918, 'eval_runtime': 29.9925, 'eval_samples_per_second': 33.342, 'eval_steps_per_second': 2.101, 'epoch': 2.0}\n"]}],"source":["results = trainer.evaluate()   # just gets evaluation metrics\n","print(results)"]},{"cell_type":"markdown","source":["Al entrenar con nuestro dataset sobre un modelo pre-entrenado, en solo 2 √©pocas obtenemos resultados muy altos de accuracy."],"metadata":{"id":"qcjmMMGbryKS"}},{"cell_type":"markdown","metadata":{"id":"jemgILqCuKCK"},"source":["Now we can make predictions with our model.\n"]},{"cell_type":"markdown","metadata":{"id":"ErBXwNdbu1Ab"},"source":["####¬†<font color='#2B4865'>*1.2.5. Make predictions with the fine-tuned model*</font>"]},{"cell_type":"markdown","source":["Cargamos nuestro modelo entrenado:"],"metadata":{"id":"_KQz8oHztyVB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HtQGleHVm-c6","colab":{"base_uri":"https://localhost:8080/","height":694},"outputId":"9c6d7348-45c0-42c8-937b-6e89b5d9eeed"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/Cosas/NLP_IA/Cosas_LAB_4/bert-base-uncased-finetuned-imdb/checkpoint-125/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Cosas/NLP_IA/Cosas_LAB_4/bert-base-uncased-finetuned-imdb/checkpoint-125\",\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.25.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Cosas/NLP_IA/Cosas_LAB_4/bert-base-uncased-finetuned-imdb/checkpoint-125/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Cosas/NLP_IA/Cosas_LAB_4/bert-base-uncased-finetuned-imdb/checkpoint-125.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"]}],"source":["# Load trained model\n","model_path = path_to_folder + \"/bert-base-uncased-finetuned-imdb/checkpoint-125\" ## TODO: Update this path to the last saved checkpoint in the former cell\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)"]},{"cell_type":"markdown","source":["Obtenemos accuracy de test"],"metadata":{"id":"xMChsCrVt92p"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EP8NwPCuuP69","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"fae9a095-128c-4027-9c6b-dfc4069a66b2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running Prediction *****\n","  Num examples = 100\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Accuracy:\t0.93\n"]}],"source":["# Define test trainer\n","test_trainer = Trainer(model, data_collator=data_collator, tokenizer=tokenizer)\n","\n","# Make prediction\n","test_dataset = tokenized_imdb_dataset[\"test\"].select(range(100))\n","predicted_results = test_trainer.predict(test_dataset)\n","\n","# Preprocess raw predictions\n","y_pred = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n","\n","# Calculate accuracy\n","labels = test_dataset[\"labels\"]\n","print(f\"Accuracy:\\t{accuracy_score(y_true=labels, y_pred=y_pred)}\")"]},{"cell_type":"markdown","metadata":{"id":"qFNVRCweubHY"},"source":["We can also make predictions on new data:"]},{"cell_type":"markdown","source":["Podemos incluso predecir para datos nuevos"],"metadata":{"id":"Ouk8frtwt_ho"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1y9eiTG7Q_L","colab":{"base_uri":"https://localhost:8080/","height":415},"outputId":"a2d35660-fb24-4ce5-a8fa-1ba7b5a7a27f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-8df095b1cb7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The movie was not what I expected\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpos_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"negative\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"positive\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The sentiment of the sentence is: {pos_preds[prediction]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1567\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"]}],"source":["test_str = \"The movie was not what I expected\"\n","model_inputs = tokenizer(test_str, return_tensors=\"pt\")\n","prediction = torch.argmax(model(**model_inputs).logits)\n","pos_preds = [\"negative\", \"positive\"]\n","print(f\"The sentiment of the sentence is: {pos_preds[prediction]}\")"]},{"cell_type":"markdown","metadata":{"id":"mrEmXe8J1vrf"},"source":["To finish, we can aslo pull out correct and incorrect classification from the test set for examination. First, let's print out some example predictions that were correct."]},{"cell_type":"markdown","source":["Podemos extraer clasificaciones correctas e incorrectas del conjunto de test para verlas y analizar donde falla el modelo"],"metadata":{"id":"KBlBUCqowNsA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pfv2U8b6z_Ec","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"883236e6-c8e0-4ef3-ab60-02356feb3b73"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["predicted_labels = y_pred.flatten().tolist()                                     # Flatten the predictions into a 1D list\n","\n","unique_labels = set(label for label in [\"negative\", \"positive\"])\n","label2id = {label: id for id, label in enumerate(unique_labels)}\n","id2label = {id: label for label, id in label2id.items()}\n","\n","predicted_labels = [id2label[l] for l in predicted_labels]                      # Convert from integers back to strings for readability\n","test_labels = [id2label[l] for l in test_labels]"]},{"cell_type":"markdown","source":["Veamos algunas correctas"],"metadata":{"id":"dvbldZPawYUf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7KrvGuZkDAV","colab":{"base_uri":"https://localhost:8080/","height":1059},"outputId":"943733c7-aab1-4f0b-9e5a-2c73f8a0978b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m Jeremy Irons and Forrest Whitaker are good actors. But this movie was badly written. First of all, d ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m A friend of mine loves tacky horror films so I often get to see low budget stuff like this. This is, ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m .... could it be that ITV wouldn't want to release this absolute classic because it would show up th ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m This movie is a masterpiece of brilliant acting and timely patriotic sense of pride in America. The  ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m Most of the criticism of \"Attack of Show\" is from people who are unfairly comparing it to an old com ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m great historical movie, will not allow a viewer to leave once you begin to watch. View is presented  ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m This is a very strange film, with a no-name cast and virtually nothing known about it on the web. It ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m I was surprised how much I enjoyed this. Sure it is a bit slow moving in parts, but what else would  ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m ...and that's a goddamn shame! Please make the sun rise and have it incinerate all copies of Dracula ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m This a fantastic movie of three prisoners who become famous. One of the actors is george clooney and ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m I gave 9 of 10 points. I was sitting in tears nearly the whole movie, because I had to laugh!<br />< ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m If I was still 5 I might find it scary. It is (I guess) a low budget film. The acting is not good, b ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m A plane carrying a rich scientist's daughter goes down in thick wilderness. He assembles a group to  ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m Scary in places though the effects did leave something to be desired unless you have bad eyesight or ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m I have not seen such a stupid,dumb movie since quite a while. It absolutely has no logic, no horror- ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m I made a big mistake going to see this film. That's the lottery of going to see films I guess. After ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m A German freshman, Stefan hitch hikes to Paris during summer break were he falls for a mysterious yo ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m I found the film Don't Look In The Basement to be very good, with some great characters in it. It is ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m I bought a tape of this film based on the recommendation of other IMDb users and have to say that I  ...\n","\n","\u001b[38;5;2m\u001b[1mLABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m Awful, dreadful, terrible. The actors are bad, the music is ridiculous and the filming pathetic. I r ...\n","\n"]}],"source":["for _true_label, _predicted_label, _text in random.sample(list(zip(test_labels, predicted_labels, test_texts)), 20):\n","  if _true_label == _predicted_label:\n","    print(fore.GREEN + style.BOLD + \"LABEL:\" + style.RESET, _true_label)\n","    print(fore.LIGHT_BLUE + style.BOLD + \"REVIEW TEXT:\" + style.RESET, _text[:100], '...')\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"pW30Z6ynkDPI"},"source":["Now let's print out some misclassifications."]},{"cell_type":"markdown","source":["Pasemos a algunas incorrectas"],"metadata":{"id":"SkC-NVBDwZtB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xmx1RSKDkIpG","colab":{"base_uri":"https://localhost:8080/","height":364},"outputId":"de5c9487-d8b0-4cc9-9ffd-51519d442ef9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m\u001b[1mTRUE LABEL:\u001b[0m negative\n","\u001b[38;5;1m\u001b[1mPREDICTED LABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m I'll say one thing for Herman, USA: it will probably always play well to Minnesota audiences. I can' ...\n","\n","\u001b[38;5;2m\u001b[1mTRUE LABEL:\u001b[0m negative\n","\u001b[38;5;1m\u001b[1mPREDICTED LABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m Slaughter Trail is a B western with some grand pretensions. But it's come down in Hollywood history  ...\n","\n","\u001b[38;5;2m\u001b[1mTRUE LABEL:\u001b[0m positive\n","\u001b[38;5;1m\u001b[1mPREDICTED LABEL:\u001b[0m negative\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m An Arab American man is kidnapped from an American Airport and flown to \"somewhere in North Africa\"  ...\n","\n","\u001b[38;5;2m\u001b[1mTRUE LABEL:\u001b[0m negative\n","\u001b[38;5;1m\u001b[1mPREDICTED LABEL:\u001b[0m positive\n","\u001b[38;5;12m\u001b[1mREVIEW TEXT:\u001b[0m In all, it took me three attempts to get through this movie. Although not total trash, I've found a  ...\n","\n"]}],"source":["for _true_label, _predicted_label, _text in random.sample(list(zip(test_labels, predicted_labels, test_texts)), 50):\n","  if _true_label != _predicted_label:\n","    print(fore.GREEN + style.BOLD + \"TRUE LABEL:\" + style.RESET, _true_label)\n","    print(fore.RED + style.BOLD + \"PREDICTED LABEL:\" + style.RESET, _predicted_label)\n","    print(fore.LIGHT_BLUE + style.BOLD + \"REVIEW TEXT:\" + style.RESET, _text[:100], '...')\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"3MZqyFrckJBB"},"source":["Finally, we can some heatmaps to examine misclassification patterns:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8yJ3-Z7hLXf","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"56986eca-af05-4471-8f55-3dde119cc997"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["imdb_classifications_dict = defaultdict(int)\n","for _true_label, _predicted_label in zip(test_labels, predicted_labels):\n","  imdb_classifications_dict[(_true_label, _predicted_label)] += 1\n","  \n","dicts_to_plot = []\n","for (_true_genre, _predicted_genre), _count in imdb_classifications_dict.items():\n","  dicts_to_plot.append({'True Sentiment': _true_genre,\n","                        'Predicted Sentiment': _predicted_genre,\n","                        'Number of Classifications': _count})\n","  \n","df_to_plot = pd.DataFrame(dicts_to_plot)\n","df_wide = df_to_plot.pivot_table(index='True Sentiment', \n","                                 columns='Predicted Sentiment', \n","                                 values='Number of Classifications')"]},{"cell_type":"markdown","source":["Veamos la matriz de confusi√≥n del modelo. El resultado es MUY bueno"],"metadata":{"id":"4EzNzVHzwe-Q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wSAgS6tvivvz","colab":{"base_uri":"https://localhost:8080/","height":431},"outputId":"677d3e58-8353-46cd-a749-69b3ef99a15f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 576x432 with 2 Axes>"],"image/png":"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\n"},"metadata":{"image/png":{"width":526,"height":414}}}],"source":["sns.set(style='ticks', font_scale=1.2)\n","sns.heatmap(df_wide, linewidths=1, cmap='Blues')    \n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"eiukJdYRqyjm"},"source":["Looks good! We can see that overall, our model is assigning the correct sentiment for each review. "]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["eSmDpTHvbv5R","H_ak68EcROir","WS2DntKdviBl","yFEh5EWsvshb","bg5_7T1hqXDy","bZzv6wdltTJj","I_bOeklctm0C","twr8jkEWttz6","ts7IfG2GzX0L","KjhZvtO57Wc_","7xQji6Ow3dYC","GqYp6QAA3esJ","NlmPN38ksPY4","G8uGfSzTj-BC","rlAy1UbGgd2C","JKaGGDcQkSdd","bZi3-Aabobn7","cW-AeHlH6BgN"]},"gpuClass":"standard","kernelspec":{"display_name":"ids","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"4f4b3e375183431ea8a402488496d3aca3ba53f2cb8b44eeb3f5fe53d953a410"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"c02bb8241a1a4d43aa14e01a3af13fc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1078d0bb08da4dbda6cc48dc55be6e25","IPY_MODEL_6e32e768434e4ed9b46ffab522a1724e","IPY_MODEL_4db35f7816944e238ce5759e91f0c98e"],"layout":"IPY_MODEL_47d4f017de8e4e68a6e40cd505834eb6"}},"1078d0bb08da4dbda6cc48dc55be6e25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05fbe7dd374f49ce9810113a111030b9","placeholder":"‚Äã","style":"IPY_MODEL_fa5638ad29824236b1550129cea7404c","value":"Downloading: 100%"}},"6e32e768434e4ed9b46ffab522a1724e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec0742bdd1c24f8a993a488f6da6e5a1","max":687,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56e638b9a1d644ee9f507f99815dafbf","value":687}},"4db35f7816944e238ce5759e91f0c98e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b3129498e62469484b1eccc14db485f","placeholder":"‚Äã","style":"IPY_MODEL_bb154df37f5340da90dd95753e302838","value":" 687/687 [00:00&lt;00:00, 10.9kB/s]"}},"47d4f017de8e4e68a6e40cd505834eb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05fbe7dd374f49ce9810113a111030b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa5638ad29824236b1550129cea7404c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec0742bdd1c24f8a993a488f6da6e5a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56e638b9a1d644ee9f507f99815dafbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b3129498e62469484b1eccc14db485f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb154df37f5340da90dd95753e302838":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8221a758ba2e44dd995e3a156fdcfabe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d24d8754caf742db87aed513d16c7d11","IPY_MODEL_14b86fe6d9884891a7833da9c4c6229e","IPY_MODEL_fd843aaadd5249f1bfdd5bb1bf1f0cd1"],"layout":"IPY_MODEL_bc89e933e0c44708be66dfbd8e0d5418"}},"d24d8754caf742db87aed513d16c7d11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c8ae455388042bfa5b297354385034c","placeholder":"‚Äã","style":"IPY_MODEL_7b98b04a16464e2faa9392b33f6e6b15","value":"Downloading: 100%"}},"14b86fe6d9884891a7833da9c4c6229e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_943fcc9e3f924217a961cd8b387a3f0f","max":1421616707,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e992db9438f34014b29fedcf9e1d9cd9","value":1421616707}},"fd843aaadd5249f1bfdd5bb1bf1f0cd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee64c37f6fa449629611f45291536049","placeholder":"‚Äã","style":"IPY_MODEL_a205cd913cf24e149f4a0d55d068d528","value":" 1.42G/1.42G [00:26&lt;00:00, 43.3MB/s]"}},"bc89e933e0c44708be66dfbd8e0d5418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c8ae455388042bfa5b297354385034c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b98b04a16464e2faa9392b33f6e6b15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"943fcc9e3f924217a961cd8b387a3f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e992db9438f34014b29fedcf9e1d9cd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee64c37f6fa449629611f45291536049":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a205cd913cf24e149f4a0d55d068d528":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c7a13a5a99246fcb60624293fda5e28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_976b5fbbc4cc4dc4ac022b37299a92cc","IPY_MODEL_20bb37bebff54a498592c29e56ba7935","IPY_MODEL_be4ceb3b764f4246857503927cab1c11"],"layout":"IPY_MODEL_b8b3f94c710744ebb5a5f1d8c5c23a2b"}},"976b5fbbc4cc4dc4ac022b37299a92cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff701c6d2c99437cbcdeb5eb497a826b","placeholder":"‚Äã","style":"IPY_MODEL_c9bedc044a434095ae5bca5010970387","value":"Downloading: 100%"}},"20bb37bebff54a498592c29e56ba7935":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b83a1b685134d9aa209351d029a4f4f","max":256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70a8a4626c4c4282b286cea3c62cb4f5","value":256}},"be4ceb3b764f4246857503927cab1c11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f22c0f836e4b42ce96e46a222e1dbf6b","placeholder":"‚Äã","style":"IPY_MODEL_d7deacfa575143bfabc0af5b3b0ee535","value":" 256/256 [00:00&lt;00:00, 14.6kB/s]"}},"b8b3f94c710744ebb5a5f1d8c5c23a2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff701c6d2c99437cbcdeb5eb497a826b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9bedc044a434095ae5bca5010970387":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b83a1b685134d9aa209351d029a4f4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70a8a4626c4c4282b286cea3c62cb4f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f22c0f836e4b42ce96e46a222e1dbf6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7deacfa575143bfabc0af5b3b0ee535":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de72c64402e74f41bffb001bbecc61f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ccc8b4261b24e0eac327380c975b223","IPY_MODEL_931b0bc0982a467890b9e27ba8363edf","IPY_MODEL_8ae741aed7254093800e8d407e8e6b16"],"layout":"IPY_MODEL_64470ef829dc48f79f81d4688506699e"}},"2ccc8b4261b24e0eac327380c975b223":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5568740ee5824079b9a3d2d9a73dfffb","placeholder":"‚Äã","style":"IPY_MODEL_9c9d65b3c25847409e2c82a3d7147bd8","value":"Downloading: 100%"}},"931b0bc0982a467890b9e27ba8363edf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cd1542de28249979a1c748f83f647a5","max":798293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_242d3df540d5444b8f612869759e6cce","value":798293}},"8ae741aed7254093800e8d407e8e6b16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aa9afd6de6d4d5ca207e8be8431f8f2","placeholder":"‚Äã","style":"IPY_MODEL_d439db56f33a4bc5985fd723adaa1d18","value":" 798k/798k [00:00&lt;00:00, 919kB/s]"}},"64470ef829dc48f79f81d4688506699e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5568740ee5824079b9a3d2d9a73dfffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c9d65b3c25847409e2c82a3d7147bd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cd1542de28249979a1c748f83f647a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"242d3df540d5444b8f612869759e6cce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8aa9afd6de6d4d5ca207e8be8431f8f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d439db56f33a4bc5985fd723adaa1d18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"452dab2bc9f94c76b3141f644f17a7d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de255c1d2b0c424e87db025c9c74b786","IPY_MODEL_c034a0bd797e4245b75e52f19db9fbc7","IPY_MODEL_1cf1f1230f5b4f0291f2c48669333394"],"layout":"IPY_MODEL_3d9f221d836e425b93cfff15e35ef1a2"}},"de255c1d2b0c424e87db025c9c74b786":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a981597d479a43f8b5373cacf3d5261e","placeholder":"‚Äã","style":"IPY_MODEL_a192932a590b48f29a71ba4480aac3e1","value":"Downloading: 100%"}},"c034a0bd797e4245b75e52f19db9fbc7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0d0869d9a19499aaa0bf2964061e48b","max":456356,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0d5013efb9c4cbeb15442b35a165f86","value":456356}},"1cf1f1230f5b4f0291f2c48669333394":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3790c11ff1f484683048c1404ba03a7","placeholder":"‚Äã","style":"IPY_MODEL_0e699330ed1a41a38d92093d3bf715c6","value":" 456k/456k [00:00&lt;00:00, 1.30MB/s]"}},"3d9f221d836e425b93cfff15e35ef1a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a981597d479a43f8b5373cacf3d5261e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a192932a590b48f29a71ba4480aac3e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0d0869d9a19499aaa0bf2964061e48b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0d5013efb9c4cbeb15442b35a165f86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3790c11ff1f484683048c1404ba03a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e699330ed1a41a38d92093d3bf715c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"defabe8f342a49ad850358da96e08557":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fa1199529d44bbea8331ccf589787ae","IPY_MODEL_84f0346a78784fe58ac138cdc27fdb1e","IPY_MODEL_db6853a1acc2423495fe71a180f726f1"],"layout":"IPY_MODEL_4ffa4483d527443689ecb4a5cf8db836"}},"5fa1199529d44bbea8331ccf589787ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_473232ae3a99477489e9883ccf1fb889","placeholder":"‚Äã","style":"IPY_MODEL_e1974e5d006c40b68794b580d7841836","value":"Downloading: 100%"}},"84f0346a78784fe58ac138cdc27fdb1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16398a5e7ac14b6e88ca5be3fa7b9676","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee7a738370e240d6a6574a5c1b87d547","value":150}},"db6853a1acc2423495fe71a180f726f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41e233d690b24ae4b4c681b22a18e1e5","placeholder":"‚Äã","style":"IPY_MODEL_21fdd8392dc54786a6a634db6ddf86e8","value":" 150/150 [00:00&lt;00:00, 4.62kB/s]"}},"4ffa4483d527443689ecb4a5cf8db836":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"473232ae3a99477489e9883ccf1fb889":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1974e5d006c40b68794b580d7841836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16398a5e7ac14b6e88ca5be3fa7b9676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee7a738370e240d6a6574a5c1b87d547":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41e233d690b24ae4b4c681b22a18e1e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21fdd8392dc54786a6a634db6ddf86e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b25166e6ad434deabbb4b6dd2bcd0154":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb17d7e22ac44bac8fabc353bc9803e8","IPY_MODEL_4a3aa0f672d44901a6f8c776ed229549","IPY_MODEL_38f91c4715c24b03b6e309a5f3bd74e0"],"layout":"IPY_MODEL_ed22066780864c0088180148def825d9"}},"cb17d7e22ac44bac8fabc353bc9803e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_554b02b49ce544a3b7ffbc6282bf2ca1","placeholder":"‚Äã","style":"IPY_MODEL_aa3a62ee84084140951a1393a9cf6f90","value":"100%"}},"4a3aa0f672d44901a6f8c776ed229549":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e60863116a54be580a1147a82e8306e","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_059501a771bd4c2087b18f04be1aa781","value":3}},"38f91c4715c24b03b6e309a5f3bd74e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd87a0373d0e45a7a3f4f942a3d6d74a","placeholder":"‚Äã","style":"IPY_MODEL_8c5be33a11db4de585663b4d90a372ed","value":" 3/3 [00:00&lt;00:00, 103.48it/s]"}},"ed22066780864c0088180148def825d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"554b02b49ce544a3b7ffbc6282bf2ca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa3a62ee84084140951a1393a9cf6f90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e60863116a54be580a1147a82e8306e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"059501a771bd4c2087b18f04be1aa781":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd87a0373d0e45a7a3f4f942a3d6d74a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c5be33a11db4de585663b4d90a372ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a377a5afbb074c69989fcb2696e6d6ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd9cbf39e2374ee3a048deb5a8bbda55","IPY_MODEL_d35d48c5340341378b972452e9eadc64","IPY_MODEL_f5d461ed447d46b68aecbabadd4d6554"],"layout":"IPY_MODEL_f6d73c41b55e44ae946702a77c7e3c08"}},"dd9cbf39e2374ee3a048deb5a8bbda55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de68f97bf7784eca8ce06225c77c5e08","placeholder":"‚Äã","style":"IPY_MODEL_a38d887a9ba34d89ac70f4729c4291ab","value":"100%"}},"d35d48c5340341378b972452e9eadc64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed55107b52b5497785dcc7e57c7a0618","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10d90b0756e04e0289c6a56359308222","value":1}},"f5d461ed447d46b68aecbabadd4d6554":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff72b436dfb64b938fd4f73a9a5bce7d","placeholder":"‚Äã","style":"IPY_MODEL_ebd7fdcac4e84dc8b2e6f45d6681c1d5","value":" 1/1 [00:04&lt;00:00,  4.94s/ba]"}},"f6d73c41b55e44ae946702a77c7e3c08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de68f97bf7784eca8ce06225c77c5e08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a38d887a9ba34d89ac70f4729c4291ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed55107b52b5497785dcc7e57c7a0618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10d90b0756e04e0289c6a56359308222":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff72b436dfb64b938fd4f73a9a5bce7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebd7fdcac4e84dc8b2e6f45d6681c1d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18cf58a65e3e47d4bd6b6e16d4c3c59a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d8669a8ec9c4cb284b01f7da946b924","IPY_MODEL_ce5b990ae26b442a9b35fe6f9d5e769a","IPY_MODEL_ffd39d499b8f45e989595c4f1be601d3"],"layout":"IPY_MODEL_6eda56bddc5c497986ffc3c2abb574b8"}},"3d8669a8ec9c4cb284b01f7da946b924":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfbf1f9febca4368ac90dd8bc49e8e36","placeholder":"‚Äã","style":"IPY_MODEL_af210a23e0914ceb83834bd9c9e798d7","value":"100%"}},"ce5b990ae26b442a9b35fe6f9d5e769a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61d938a61dba44979d8043b0f39f9177","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8fce3faf27f64e7c946e9314e0394de2","value":1}},"ffd39d499b8f45e989595c4f1be601d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_353f3589270b4d12b3ece30f03cb0bfe","placeholder":"‚Äã","style":"IPY_MODEL_7e8c8bc54e094428927d50f5c7dc402f","value":" 1/1 [00:05&lt;00:00,  5.27s/ba]"}},"6eda56bddc5c497986ffc3c2abb574b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfbf1f9febca4368ac90dd8bc49e8e36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af210a23e0914ceb83834bd9c9e798d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61d938a61dba44979d8043b0f39f9177":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fce3faf27f64e7c946e9314e0394de2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"353f3589270b4d12b3ece30f03cb0bfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e8c8bc54e094428927d50f5c7dc402f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74dfc9eb73504585899109c4d74c68eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c339fd8726d44eaeb5757db2745ab781","IPY_MODEL_bcc42c3c6f8843fe8a7a00b3a64d673f","IPY_MODEL_7b6fae2668b24bb79880d620d0ba725c"],"layout":"IPY_MODEL_721a0d53ff41484082e4fb659b352f41"}},"c339fd8726d44eaeb5757db2745ab781":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86d1054579dd4235ad4e8c23417d4301","placeholder":"‚Äã","style":"IPY_MODEL_7dd3f910d4a04f9b84f3ce64acd288fe","value":"Downloading: 100%"}},"bcc42c3c6f8843fe8a7a00b3a64d673f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4904899eb32a42f8933720b53a755325","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_deb1e9d1364d42d88f085e5b833dc6ad","value":440473133}},"7b6fae2668b24bb79880d620d0ba725c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74d25413d2e743bf91b030fe72c85863","placeholder":"‚Äã","style":"IPY_MODEL_7ab78d3c4dfb4bc89c2af238a0794d47","value":" 440M/440M [00:12&lt;00:00, 46.4MB/s]"}},"721a0d53ff41484082e4fb659b352f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86d1054579dd4235ad4e8c23417d4301":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dd3f910d4a04f9b84f3ce64acd288fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4904899eb32a42f8933720b53a755325":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"deb1e9d1364d42d88f085e5b833dc6ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74d25413d2e743bf91b030fe72c85863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab78d3c4dfb4bc89c2af238a0794d47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}