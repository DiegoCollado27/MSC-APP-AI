{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU_gqVHcSuHE"
      },
      "source": [
        "# <font color='#2B4865'>**Hugging Face ðŸ¤— Transformers Tutorial II**</font>\n",
        "\n",
        "---\n",
        "### Natural Language Processing\n",
        "Date: Dec 21, 2022\n",
        "\n",
        "Last Update: Nov 26, 2023\n",
        "\n",
        "Author: Lorena Calvo-BartolomÃ© (lcalvo@pa.uc3m.es)\n",
        "\n",
        "Version 1.1\n",
        "\n",
        "---\n",
        "This notebook is based on the [Hugging Face course](https://huggingface.co/course/chapter1/1) and documentation available at the Hugging Face website.\n",
        "\n",
        "It constitutes the second tutorial notebook on the usage of Hugging Face libraries as well as its application for solving a series of NLP tasks.\n",
        "\n",
        "Its main **goal** is to revise the specific inference and fine-tuning examples of the Question Answering and Summarization tasks at the same time that more advanced functionalities of the Hugging Face ðŸ¤— Python library are learned.\n",
        "\n",
        "---\n",
        "\n",
        "<font color='#E0144C'>**For this notebook's execution, we highly encourage you to use Google Colaboratory. While for the inference part it is not necessary, you will highly speed up the execution if you make use of a GPU. For doing so, follow the following steps:**</font>\n",
        "\n",
        "<font color='#E0144C'>**1. Connect to hosted runtime**</font>\n",
        "\n",
        "<font color='#E0144C'>**2. Enable GPU setting by clicking Edit -> Notebook Settings -> Select GPU in Hardware Acceleration Tab -> Save**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_ak68EcROir"
      },
      "source": [
        "## <font color='#2B4865'>Installing necessary packages, imports and auxiliary functions</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNmR0A9v3gG7",
        "outputId": "9de6738f-0445-45da-8dd3-6a9ba18d478a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing package transformers[sentencepiece,torch]\n",
            "Package datasets already installed!\n",
            "Package wikipedia already installed!\n",
            "Package nltk already installed!\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "import importlib, os\n",
        "\n",
        "necessary_packages = ['transformers[sentencepiece,torch]', 'datasets', 'colored', 'wikipedia', 'evaluate', 'nltk', 'rouge_score']\n",
        "def import_missing(packages):\n",
        "  for p in packages:\n",
        "    try:\n",
        "      mod = importlib.import_module(p)\n",
        "      print(f\"Package {p} already installed!\")\n",
        "      packages.remove(p)\n",
        "    except ModuleNotFoundError:\n",
        "      print(f\"Installing package {p}\")\n",
        "      with open(\"requirements.txt\", 'w') as f:\n",
        "        f.write(\"\\n\".join(str(i) for i in packages))\n",
        "  if os.path.isfile(\"requirements.txt\"):\n",
        "    %pip install --quiet -r \"requirements.txt\"\n",
        "\n",
        "import_missing(necessary_packages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VszD2tguTJcS",
        "outputId": "af1e9074-27c9-40a2-fca9-bf149d4addb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Common imports\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from termcolor import colored\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import scipy\n",
        "from colored import Fore, Back, Style\n",
        "import torch\n",
        "import json\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Figures plotted inside the notebook\n",
        "%matplotlib inline\n",
        "# High quality figures\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "# Figues size\n",
        "plt.rcParams['figure.figsize'] = [8, 6]\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings(action='ignore',module='gradio')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhwq7n9ETRuL"
      },
      "outputs": [],
      "source": [
        "# To wrap long text lines\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <Style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </Style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "# For fancy table Display\n",
        "%load_ext google.colab.data_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cyl8upfClMag",
        "outputId": "872048a4-22ff-4f6f-e45d-164f7def6359"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Auxiliary funcion to print Trasnformer encodings\n",
        "def print_encoding(model_inputs, indent=4):\n",
        "    indent_str = \" \" * indent\n",
        "    print(\"{\")\n",
        "    for k, v in model_inputs.items():\n",
        "        print(indent_str + k + \":\")\n",
        "        print(indent_str + indent_str + str(v))\n",
        "    print(\"}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMwVQsO_eHs1"
      },
      "source": [
        "We are going to save all the files in this notebook generated into Drive. Fill the variable ``path_to_folder`` in the next with your Drive's folder in which you want to save the files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "h7wQkXVnvnvu",
        "outputId": "966823e1-171e-446a-c834-81ed23d688fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "path_to_folder = '/content/drive/My Drive/NLP_IA'  # UPDATE THIS ACCORDING TO WHERE YOU WANT TO SAVE THE FILES!!!!\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change to assignment directory\n",
        "os.chdir(path_to_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZqNyqb80hXm"
      },
      "source": [
        "## <font color='#2B4865'>**2. Question Answering**\n",
        "---\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Z5JWlx1OJ6"
      },
      "source": [
        "**Question Answering (QA)** is the task of retrieving the answer to a question from a given text, which is useful for searching for an answer in a document. Some question answering models can even generate answers without context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6pqM0ki3SQG"
      },
      "source": [
        "##### <font color='#2B4865'>**Architecture for approaching the task**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAHk3V312jrE"
      },
      "source": [
        "There are different QA variants based on the inputs and outputs:\n",
        "\n",
        "<table>\n",
        "    <thead>\n",
        "        <tr>\n",
        "            <th> </th>\n",
        "            <th><font color='#256D85'>Definition</font></th>\n",
        "            <th><font color='#256D85'>Solved By</font></th>\n",
        "            <th><font color='#256D85'>Good At</font></th>\n",
        "        </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td><b>EXTRACTIVE</b></td>\n",
        "            <td>The model extracts an answer from <br>a\n",
        "            given context (e.g., a text, a <br>\n",
        "            table, an HTML, etc.)\n",
        "            </td>\n",
        "            <td>Encoder-only models<br>(e.g., BERT)\n",
        "            </td>\n",
        "            <td>\n",
        "            Answering factoid questions:<br> e.g.: \"Who\n",
        "            invented the transformers<br>\n",
        "            architecture?\"\n",
        "            </td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td><b>OPEN GENERATIVE</b></td>\n",
        "            <td>The model generates free text<br>\n",
        "            directly based on the context.\n",
        "            </td>\n",
        "            <td rowspan=2>Encoder-decoder models<br>\n",
        "            (e.g., T5)</td>\n",
        "            <td rowspan=2>Answering open-ended\n",
        "            questions:<br>\n",
        "            e.g.: \"Why the sky is blue?\"\n",
        "            </td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td><b>CLOSED GENERATIVE</b></td>\n",
        "            <td>No context is provided so the<br>\n",
        "            answer is generated completely by<br>\n",
        "            the model.\n",
        "            </td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIu20pZG3XIE"
      },
      "source": [
        "##### <font color='#2B4865'>**Evaluation metrics**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6KW6t8t4Bhm"
      },
      "source": [
        "**Typical metrics** for Question Answering are:\n",
        "\n",
        "\n",
        "*   **Exact-match**, which is based on the strict character match of the predicted answer and the right answer. For answers predicted correctly, the Exact Match will be $1$. Even if only one character is different, the Exact Match will be $0$.\n",
        "*   **F1-Score** metric is useful if we value both false positives and false negatives equally. The F1-Score is calculated on each word in the predicted sequence against the correct answer. It ranges from $0$ to $1$, where $0$ is the worst possible score and $1$ is a perfect score indicating that the model predicts each observation correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDDj3KeJ0i_G"
      },
      "source": [
        "In the what is left of this section, we will be working with **Extractive Question Answering**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaBtAvwr1nBQ"
      },
      "source": [
        "###Â <font color='#2B4865'>*2.1. Inference*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMCTABzVdkYZ"
      },
      "source": [
        "As you know from Section 1.1, the first step to perform inference with any Hugging Face pipeline is to find a model on [the hub](https://huggingface.co/models). Here, we will be using ``DistilBERT``, a Transformer model trained by distilling BERT base, that was proposed in [this paper](https://arxiv.org/pdf/1910.01108.pdf). In particular, we will be using [this fine-tune checkpoint](https://huggingface.co/distilbert-base-cased-distilled-squad) of ``DistilBERT-base-cased``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCM0moPlOjll"
      },
      "source": [
        "###### **Exercise 2.1**\n",
        "\n",
        "Create a QA pipeline named ``question_answerer`` by invoking ``pipeline()`` with the task identifier ``\"question-answering\"`` and the checkpoint mentioned above. What type of object does it return?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "GLoZisp7fQrl",
        "outputId": "3cc0637f-9b72-4682-a627-3be9f48e86e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "checkpoint_name = \"distilbert-base-cased-distilled-squad\"\n",
        "\n",
        "# <SOL>\n",
        "# TODO: Add necessary imports\n",
        "\n",
        "\n",
        "# TODO: Create pipeline\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi7j-5Pkum-2"
      },
      "source": [
        "After running the last cell, we have a pipeline for performing question answering given a context string. For example, the variable ``context1`` in the next cell defines the first few paragraphs from the [Wikipedia entry for David (son of Heraclius)](https://en.wikipedia.org/wiki/David_(son_of_Heraclius)) that we will be using as context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "h732y0g3MJJt",
        "outputId": "bd3a683f-0375-407b-9919-8399e9c03788"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "David (Greek: Î”Î±Ï…Î¯Î´; fl.â€‰630â€“641) was one of three co-emperors of Byzantium for a few months in late 641, and had the regnal name Tiberius. David was the son of Emperor Heraclius and his wife and niece Empress Martina. He was born after the emperor and empress had visited Jerusalem and his given name reflects a deliberate attempt to link the imperial family with the Biblical David. The David Plates, which depict the life of King David, may likewise have been created for the young prince or to commemorate his birth. David was given the senior court title caesar in 638, in a ceremony during which he received the kamelaukion cap previously worn by his older brother Heraclonas.\n",
            "After the death of Emperor Heraclius in February 641, when David was 10 years old, a power struggle ensued between different branches of the imperial family. As part of a compromise, David was raised to be co-emperor, ruling with his brother Heraclonas and their nephew Constans II. The Byzantine state faced serious challenges while Tiberius was co-emperor, with the ongoing Muslim conquest of Egypt and continuing religious strife over monothelitism and other Christological doctrines. All three emperors were children and the Empress Dowager Martina acted as regent. Martina was deeply unpopular due to her incestuous relationship with Heraclius, her unconventional habits, and her ambition. Her regime was deposed in a rebellion, probably by January 642. She and her sons were exiled to Rhodes and, in an early example of Byzantine political mutilation, Martina's tongue was cut out and the noses of her sons were cut off. There is no further historical record of Tiberius, and some historians speculate that he and his family lived out the rest of their lives peacefully.\n"
          ]
        }
      ],
      "source": [
        "import wikipedia\n",
        "\n",
        "context1 = wikipedia.summary(\"David (son of Heraclius)\",auto_suggest=False).strip()\n",
        "print(context1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ceB6AmCnwMPZ",
        "outputId": "dc1cc963-b36c-4ca9-d6df-7887cafde0e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;12m\u001b[1mQ: What was the regnal name of David?\u001b[0m\n",
            "\u001b[38;5;1mA: Tiberius\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "question1 = \"What was the regnal name of David?\"\n",
        "r = question_answerer(question=question1, context=context1)\n",
        "print(Fore.LIGHT_BLUE + Style.BOLD + f'Q: {question1}' + Style.RESET)\n",
        "print(Fore.RED + \"A: \" + r['answer'] + Style.RESET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn6jBWOLFbW0"
      },
      "source": [
        "We can also ask multiple questions at once by providing the pipeline with them  within a list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "Q4eS-dSrFanL",
        "outputId": "ec3327a0-d30c-4b61-a6c4-3bbb0dc92ba4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;12m\u001b[1mQ: Who was the father of David?\u001b[0m\n",
            "\u001b[38;5;1mA: Emperor Heraclius\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What does David's name reflect?\u001b[0m\n",
            "\u001b[38;5;1mA: a deliberate attempt to link the imperial family with the Biblical David\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: When did Emperor Heraclius die?\u001b[0m\n",
            "\u001b[38;5;1mA: February 641\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "questions = [\"Who was the father of David?\",\n",
        "             \"What does David's name reflect?\",\n",
        "             \"When did Emperor Heraclius die?\"]\n",
        "\n",
        "results = question_answerer(question=questions, context=context1)\n",
        "\n",
        "for q, r in zip(questions, results):\n",
        "  print(Fore.LIGHT_BLUE + Style.BOLD + f'Q: {q}' + Style.RESET)\n",
        "  print(Fore.RED + \"A: \" + r['answer'] + Style.RESET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6hYzlr_Kq2s"
      },
      "source": [
        "Although the models used in the Hugging Face pipelines generally give outstanding results, sometimes you will have particular examples where they don't perform so well. Let's use the following example with a context string about the [Golden Age of Comic Books](https://en.wikipedia.org/wiki/Golden_Age_of_Comic_Books):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mL2Kh-r5Ebal",
        "outputId": "0bc07ed9-4b3f-417c-ad7e-425102ac024f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Golden Age of Comic Books describes an era in the history of American comic books from 1938 to 1956. During this time, modern comic books were first published and rapidly increased in popularity. The superhero archetype was created and many well-known characters were introduced, including Superman, Batman, Robin, Captain Marvel, Captain America, and Wonder Woman. Between 1939 and 1941 Detective Comics and its sister company, All-American Publications, introduced popular superheroes such as Batman and Robin, Wonder Woman, the Flash, Green Lantern, Doctor Fate, the Atom, Hawkman, Green Arrow and Aquaman. Timely Comics, the 1940s predecessor of Marvel Comics, had million-selling titles featuring the Human Torch, the Sub-Mariner, and Captain America. Although DC and Timely characters are well remembered today, circulation figures suggest that the best-selling superhero title of the era was Fawcett Comics' Captain Marvel Adventures with sales of about 1.4 million copies per issue. The comic was published biweekly at one point to capitalize on its popularity. Another notable series was The Spirit by Will Eisner, which deviated from the usual publishing model of the period as a weekly multi-page supplement in the Register and Tribune Syndicate newspapers that Eisner held the copyright, a rare consideration for creators of that period. \n",
            "Patriotic heroes donning red, white, and blue were particularly popular during the time of the Second World War following the Shield's debut in 1940. Many heroes of this time period battled the Axis powers, with covers such as Captain America Comics #1 (cover-dated March 1941) showing the title character punching Nazi leader Adolf Hitler.As comic books grew in popularity, publishers began launching titles that expanded into a variety of genres. Dell Comics' non-superhero characters (particularly the licensed Walt Disney animated-character comics) outsold the superhero comics of the day. The publisher featured licensed movie and literary characters such as Mickey Mouse, Donald Duck, Roy Rogers and Tarzan. It was during this era that noted Donald Duck writer-artist Carl Barks rose to prominence. Additionally, MLJ's introduction of Archie Andrews in Pep Comics #22 (December 1941) gave rise to teen humor comics, with the Archie Andrews character remaining in print well into the 21st century.At the same time in Canada, American comic books were prohibited importation under the War Exchange Conservation Act which restricted the importation of non-essential goods. Canadian publishers responded to this lack of competition by producing titles of their own, informally called the Canadian Whites. While these titles flourished during the war, they did not survive the lifting of trade restrictions afterwards.\n",
            "\n",
            "\n",
            "=== Post-war and shift from superheroes ===\n",
            "A brief time period after the war until the mid-1950s is sometimes referred to as the Atomic Age of Comic Books. Some authors consider this an interregnum period or an era in its own right, but most regard it as still part of the Golden Age. During this time, the popularity of superhero comics waned. To retain reader interest, comic publishers diversified into other genres, such as war, Westerns, science fiction, romance, crime and horror. Many superhero titles were canceled or converted to other genres.In 1946, DC Comics' Superboy, Aquaman and Green Arrow were switched from More Fun Comics into Adventure Comics so More Fun could focus on humor. In 1948 All-American Comics, featuring Green Lantern, Johnny Thunder and Dr. Mid-Nite, was replaced with All-American Western. The following year, Flash Comics and Green Lantern were canceled. In 1951 All Star Comics, featuring the Justice Society of America, became All-Star Western. The next year Star Spangled Comics, featuring Robin, was retitled Star Spangled War Stories. Sensation Comics, featuring Wonder Woman, was canceled in 1953. The only superhero comics published continuously through the entire 1950s were Action Comics, Adventure Comics, Batman, Detective Comics, Superboy, Superman, Wonder Woman and World's Finest Comics.Plastic Man appeared in Quality Comics' Police Comics until 1950, when its focus switched to detective stories; his solo title continued bimonthly until issue 52, cover-dated February 1955. Timely Comics' The Human Torch was canceled with issue #35 (March 1949) and Marvel Mystery Comics, featuring the Human Torch, with issue #93 (Aug. 1949) became the horror comic Marvel Tales. Sub-Mariner Comics was canceled with issue #42 (June 1949) and Captain America Comics, by then Captain America's Weird Tales, with #75 (Feb. 1950). Harvey Comics' Black Cat was canceled in 1951 and rebooted as a horror comic later that yearâ€”the title would change to Black Cat Mystery, Black Cat Mystic, and eventually Black Cat Western for the final two issues, which included Black Cat stories. Lev Gleason Publications' Daredevil was edged out of his title by the Little Wise Guys in 1950. Fawcett Comics' Whiz Comics, Master Comics and Captain Marvel Adventures were canceled in 1953, and The Marvel Family was canceled the following year.Also during this period, the mass media with the advent of television were forcing media companies to put out comics that reflected the popular culture of the time period. Comic books focused on space, mystery, and suspense that television and other forms of media were turning to in the march toward scientific progress.\n",
            "According to historian Michael A. Amundson, appealing comic-book characters helped ease young readers' fear of nuclear war and neutralize anxiety about the questions posed by atomic power. It was during this period that long-running humor comics debuted, including EC Comics' series Mad and Dell's series Uncle Scrooge (both in 1952).\n",
            "\n",
            "\n",
            "=== End of the era ===\n",
            "In 1953, the comic book industry hit a setback when the United States Senate Subcommittee on Juvenile Delinquency was created in order to investigate the problem of juvenile delinquency. After the publication of Fredric Wertham's Seduction of the Innocent the following year that claimed comics sparked illegal behavior among minors, comic book publishers such as EC's William Gaines were subpoenaed to testify in public hearings. As a result, the Comics Code Authority was created by the Association of Comics Magazine Publishers to enact self-censorship by comic book publishers. At this time, EC canceled its crime and horror titles and focused primarily on Mad. The Silver Age of Comic Books is recognized by some as beginning with the debut of the first successful new superhero since the Golden Age, DC Comics' new Flash, in Showcase #4 (Oct. 1956). However, others point to either the end of World War II in 1945, or in 1948 with the first outcry of Fredric Wertham as the end of the Golden Age. \n",
            "\n",
            "\n",
            "== See also ==\n",
            "Silver Age of Comic Books\n",
            "Bronze Age of Comic Books\n",
            "Modern Age of Comic Books\n",
            "List of Golden Age comics publishers\n",
            "List of Marvel Comics Golden Age characters\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== External links ==\n",
            "Comic Book Plus (scans of presumed public domain Golden Age comics)\n",
            "Digital Comic Museum (scans of presumed public domain Golden Age comics)\n",
            "Don Markstein's Toonopedia\n",
            "International Catalogue of Superheroes\n",
            "Jess Nevins' Encyclopedia of Golden Age Superheroes\n",
            "Villain Paper Archived 2021-12-26 at the Wayback Machine a Golden Age Comics Subscription Service\n"
          ]
        }
      ],
      "source": [
        "context2 = wikipedia.summary(\"Golden Age of Comic Books\",auto_suggest=False).strip() + \" \" + \\\n",
        "           wikipedia.page(\"Golden Age of Comic Books\").content\\\n",
        "            .split(\"=== World War II ===\")[1]\\\n",
        "            .split(\"=== After the wars ===\")[0].strip()\n",
        "print(context2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "vQ4XtmFkEc_J",
        "outputId": "02f1ae38-9ebf-4f84-acb6-0d38e933dc9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;12m\u001b[1mQ: What popular superheroes were introduced between 1939 and 1941?\u001b[0m\n",
            "\u001b[38;5;1mA: DC Comics' new Flash\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\u001b[0m\n",
            "\u001b[38;5;1mA: DC Comics' new Flash\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What comic book characters were created between 1939 and 1941?\u001b[0m\n",
            "\u001b[38;5;1mA: Superman, Batman, Robin, Captain Marvel, Captain America, and Wonder Woman\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What well-known characters were created between 1939 and 1941?\u001b[0m\n",
            "\u001b[38;5;1mA: Superman, Batman, Robin, Captain Marvel, Captain America, and Wonder Woman\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\u001b[0m\n",
            "\u001b[38;5;1mA: Plastic Man\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "questions = [\"What popular superheroes were introduced between 1939 and 1941?\",\n",
        "             \"What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\",\n",
        "             \"What comic book characters were created between 1939 and 1941?\",\n",
        "             \"What well-known characters were created between 1939 and 1941?\",\n",
        "             \"What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\"]\n",
        "\n",
        "results = question_answerer(question=questions, context=context2)\n",
        "\n",
        "for q, r in zip(questions, results):\n",
        "  print(Fore.LIGHT_BLUE + Style.BOLD + f'Q: {q}' + Style.RESET)\n",
        "  print(Fore.RED + \"A: \" + r['answer'] + Style.RESET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqI-0fP8Q_GP"
      },
      "source": [
        "As you can see, our pipeline is not giving us really good results for this example. This example belongs to the[ TyDi QA dataset](https://github.com/google-research-datasets/tydiqa), a dataset from Google for question/answering in diverse languages. To achieve better results, we need to consider fine-tuning our model.\n",
        "\n",
        "But beFore entering into the fine-tuning part, let's see what is behind the ``QuestionAnswering`` pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8xlOaBhp-gE"
      },
      "source": [
        "####Â <font color='#2B4865'>*2.1.1. Behind the QA pipeline*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQcJJot8qiFM"
      },
      "source": [
        "###### **Exercise 2.2**\n",
        "Complete the following code to mimic the steps happening behind the QA pipeline above instantiated.\n",
        "\n",
        "**Note:** Make sure you use the Fast version of the checkpoint's tokenizer. You can achieve this by checking the tokenizer's attribute ``is_fast`` once you have instantiated it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xYT0MaKvqD4Y",
        "outputId": "c919ec38-afe9-4323-c279-6217bb84cae8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# <SOL>\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "## TODO: Add necessary imports\n",
        "\n",
        "tokenizer = # TODO: Create tokenizer from checkpoint_name\n",
        "model =  # TODO: Create model from checkpoint_name\n",
        "\n",
        "inputs =  #TODO: Obtain tokenizer's output\n",
        "outputs = # TODO: Obtain model's outputs\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3enWOcjfD-Nn",
        "outputId": "07587736-f83e-4212-abb9-273c93712187"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <SOL>\n",
        "## TODO: Check if you are using the Fast version of the tokenizer\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3g2x02arOFb"
      },
      "source": [
        "QA models work a little differently from what we have seen in Section 1 since they are trained on **predicting the index of the token starting the answer and the index of the token where the answer ends**. Because of this, these models **do not return one tensor of logits but two**: one for the logits corresponding to the start token of the answer, and one for the logits corresponding to the end token of the answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "GMm1GkUMrQsC",
        "outputId": "906fd0e9-e908-4fa4-b925-59f60895bd86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 403]) torch.Size([1, 403])\n"
          ]
        }
      ],
      "source": [
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "print(start_logits.shape, end_logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9qJtEDnsYXg"
      },
      "source": [
        "**To convert those logits into probabilities**, we will apply a **softmax function**. Yet, before doing so, we need to make sure we **mask the indices that are not part of the context**.\n",
        "\n",
        "One important thing to check before starting with the tokenization is **whether the model expects padding on the left or the right**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UIOAyWy6voHC",
        "outputId": "b1d963ef-2329-4d8e-870d-eb7a57e73e84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'right'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.padding_side"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbD3YjDlvoHC"
      },
      "source": [
        "Since our tokenizer expects padding on the right, we can pass to it **first the question and then the context together** (note that if ``padding_side`` were ``left``, we would switch the order of the question and the context), and it will properly insert the special tokens to form a sentence like:\n",
        "\n",
        "```\n",
        "[CLS] question [SEP] context [SEP]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3dvnde9vzZg"
      },
      "source": [
        "Knowing how our input is, we need to **mask the tokens of the question as well as the ``[SEP]`` token**. Since some models use the ``[CLS]`` token to indicate that the answer is not in the context (as it is the case for our checkpoint), we will keep the ``[CLS]`` unmasked.\n",
        "\n",
        "<br><center><img src=\"https://drive.google.com/uc?id=1aIGmJuZQ8-HCmEkbDVWDql7V8G0L1Hu7\" width=\"60%\"></center><br>\n",
        "\n",
        "Since we will apply a softmax afterward, we just need to replace the logits we want to mask with a large negative number. We can identify the logits we want to mask by means of the ``sequence_ids()`` method, which  returns:\n",
        "\n",
        "* ``None`` for the special tokens\n",
        "*  $0$ or $1$ depending on whether the corresponding token comes from the first sentence past (the question) or the second (the context):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "Fn1ETYx7nz6e",
        "outputId": "0f10c1c3-de15-4f79-88f4-b70853e80e54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
          ]
        }
      ],
      "source": [
        "sequence_ids = inputs.sequence_ids()\n",
        "print(sequence_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8tjTNQh-sarp",
        "outputId": "1c11e78e-3b11-4fc7-80c4-a288e82dbcb3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Mask everything apart from the tokens of the context\n",
        "mask = [i != 1 for i in sequence_ids]\n",
        "# Unmask the [CLS] token\n",
        "mask[0] = False\n",
        "mask = torch.tensor(mask)[None]\n",
        "\n",
        "start_logits[mask] = -10000\n",
        "end_logits[mask] = -10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDZ6h1eDsebe"
      },
      "source": [
        "Now that we have properly masked the logits corresponding to positions we donâ€™t want to predict, we can apply the softmax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ebDcuLGRsdb8",
        "outputId": "75d30983-9118-408d-92a5-d37efb2d042a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)[0]\n",
        "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpJwBYnWsisp"
      },
      "source": [
        "At this stage, we could take the argmax of the start and end probabilities. However, by doing so we might end up with a ``start_index`` that is greater than the ``end_index``. To avoid this, we will compute the probabilities of each possible ``start_index`` and ``end_index`` under the condition that ``start_index <= end_index``, and then take the tuple ``(start_index,end_index)`` with the highest probability.\n",
        "\n",
        "Assuming the events:\n",
        "*   *E1 = \"The answer starts at ``start_index``*\n",
        "*   *E2 = \"The answer ends at ``end_index``*\n",
        "\n",
        "to be independent, the probability ``P`` that the answer starts at ``start_index``and ends at ``end_index`` is:\n",
        "\n",
        "``P = start_probabilities[start_index] x end_probabilities[end_index]``\n",
        "\n",
        "So, to compute all the scores, we just need to compute all the ``P`` for ``start_index <= end_index``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lyH7R7iuslu8",
        "outputId": "9de41c41-1928-4392-b815-a0bc06998a48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scores = start_probabilities[:, None] * end_probabilities[None, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmCnitmosoOS"
      },
      "source": [
        "Then weâ€™ll mask the values where ``start_index > end_index`` by setting them to $0$ (the other probabilities are all positive numbers). The ``torch.triu()`` function returns the upper triangular part of the 2D tensor passed as an argument, so it will do that masking for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XsmRY8ADsqZn",
        "outputId": "111de240-045f-450a-d779-7becbb9ac788"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scores = torch.triu(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chWG_oqcstEM"
      },
      "source": [
        "Now we just have to get the index of the maximum. Since PyTorch will return the index in the flattened tensor, we need to use the floor division ``//`` and modulus ``%`` operations to get the ``start_index`` and ``end_index``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6Jf76P-Usuyn",
        "outputId": "897680f3-96c1-4dad-cffa-356d548c5d7c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.9917, grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "max_index = scores.argmax().item()\n",
        "start_index = max_index // scores.shape[1]\n",
        "end_index = max_index % scores.shape[1]\n",
        "print(scores[start_index, end_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWvDPHEas9PI"
      },
      "source": [
        "###### **Exercise 2.3**\n",
        "\n",
        "Compute the start and end indices for the **five** most likely answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "AAFL_86J14J7",
        "outputId": "33bf33db-329c-4f6b-8620-6ba7bf052ad6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[(57, 59), (57, 60), (53, 59), (57, 76), (12, 59)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <SOL>\n",
        "\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3P4pxtEs8XH"
      },
      "source": [
        "We have the ``start_index`` and ``end_index`` of the answer in **terms of tokens**, so now we just need to convert them to the character indices in the context. However, due to the tokenization process, less frequent words may get split into subword units (as is the case for our tokenizer). We can easily deal with this through the tokenizer option ``return_offsets_mapping``. This will add a new key in the tokenizer's output, namely the ``offset_mapping`` which, **for each sub-token returned by the tokenizer**, gives us a **tuple indicating the sub-token's start position and end position** relative to the original token it was split from. Then, if we have the character offsets in the original text, we can map them with the output of the tokenizer:\n",
        "\n",
        "*   the very first token ``([CLS])`` has ``(0, 0)`` because it doesn't correspond to any part of the question/answer\n",
        "*   the second token returned by the tokenizer is the same as the characters $0$ to $4$ of the question\n",
        "*   ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XtOy6fnjsxBT",
        "outputId": "4d55d567-06be-48f3-e567-fa1e9072fc0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 0), (0, 4), (5, 8), (9, 12), (13, 15), (15, 18), (18, 19), (20, 24), (25, 27), (28, 33)]\n"
          ]
        }
      ],
      "source": [
        "inputs_with_offsets = tokenizer(question1, context1, return_offsets_mapping=True)\n",
        "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "print(offsets[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0XQbKCXn7DS"
      },
      "source": [
        "Finally, with the offsets we can find the start and end indices in the original context and get the answer based on them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ydvW-7Io__Gu",
        "outputId": "e69e8a15-0a90-462a-f1b6-7e4f7051b1e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answer': 'Tiberius', 'start': 130, 'end': 138, 'score': tensor(0.9917, grad_fn=<SelectBackward0>)}\n"
          ]
        }
      ],
      "source": [
        "start_char, _ = offsets[start_index] # start_char is the start index in the original context1\n",
        "_, end_char = offsets[end_index] # end_char is the end index in the original context1\n",
        "answer = context1[start_char:end_char]\n",
        "\n",
        "result = {\n",
        "    \"answer\": answer,\n",
        "    \"start\": start_char,\n",
        "    \"end\": end_char,\n",
        "    \"score\": scores[start_index, end_index],\n",
        "}\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_rsBt7t1ovJ"
      },
      "source": [
        "###Â <font color='#2B4865'>*2.2. Fine-tuning*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zExYk8-Kx9EJ"
      },
      "source": [
        "Here we will be fine-tuning a pre-trained DistilBERT model on the TyDi QA dataset. In particular, we will be using the same checkpoint that we used for the inference task (``distilbert-base-cased-distilled-squad``)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD3k4awb1XXb"
      },
      "source": [
        "####Â <font color='#2B4865'>*2.2.1. Loading in the dataset*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkGnCF-MSiRf"
      },
      "source": [
        "Let's start by loading the [TyDi QA dataset from the Hub](https://huggingface.co/datasets/tydiqa). If you check the documentation, you will see that the dataset provides two types of tasks (primary and secondary). Yet, here we will only be making use of the primary task, since as the authors stated \"*these are a fuller and more robust representative of information-seeking question answering*\". Once we have the dataset, we will keep only English samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf_obd90TgfO"
      },
      "source": [
        "###### **Exercise 2.4**\n",
        "\n",
        "Download the TyDi QA dataset for the primary tasks from the Hub. Save the ``DatasetDict`` object in a variable named ``tydiqa_dataset``.\n",
        "\n",
        "**Hint:** Make use of the parameter ``task`` to specify for which tasks we are going to prepare the dataset:\n",
        "\n",
        "From the docs: [``datasets.load_dataset``](https://huggingface.co/docs/datasets/v2.15.0/en/package_reference/loading_methods#datasets.load_dataset)\n",
        "\n",
        "* **Parameters**\n",
        "  * ``path (str)`` â€” Path or name of the dataset. Depending on path, the dataset builder that is used comes from a generic dataset script (JSON, CSV, Parquet, text etc.) or from the dataset script (a python file) inside the dataset directory. -> The one we have been using until now.\n",
        "  * ``task (str)`` â€” The task to prepare the dataset for during training and evaluation. Casts the datasetâ€™s Features to standardized column names and types as detailed in datasets.tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "vQVDwKZjqjV6",
        "outputId": "adbd894c-ae6f-4e31-97d2-05f7d49f4519"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 166916\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 18670\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <SOL>\n",
        "\n",
        "# <SOL>\n",
        "\n",
        "tydiqa_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS4ZEHEhqicU"
      },
      "source": [
        "For the purpose of this example, we exclusively focus on English samples by filtering out any non-English ones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "N6M6XnkiARct",
        "outputId": "bd28febb-fa11-4b43-c366-36f84064bde2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 9211\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 1031\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We filter out non-English samples\n",
        "tydiqa_dataset = tydiqa_dataset.filter(lambda example: example['language'] == 'english')\n",
        "print()\n",
        "\n",
        "tydiqa_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xRO1yIkvpUt"
      },
      "source": [
        "As you can see, this dataset consists of:\n",
        "\n",
        "*   ``passage_answer_candidates`` for the Passage selection task, that we are not going to use\n",
        "*   questions (``question_text``)\n",
        "*   contexts (``document_plaintext``)\n",
        "*   information related to the oringal document the context comes (``document_title``, ``language``, and ``document_url``)\n",
        "*   and a dictionary accessible through the ``annotations`` key containing:\n",
        "  * the index of the passage index candidate (``passage_answer_candidate_index``)    \n",
        "  * the point to the start and end position of the answer inside the context (``minimal_answers_start_byte`` and ``minimal_answers_end_byte``). If the question is a \"yes/no\" answer or unanswerable, the former indexes will be equal to ``-1``.\n",
        "  * whether the question has a \"yes/no\" answer (``yes_no_answer``)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2puCxO90q1xG"
      },
      "source": [
        "Prior to moving forward, we eliminate the ``passage_answer_candidates`` as it won't be utilized in subsequent steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_wz_yaM0Z-4C",
        "outputId": "93478be6-ccfc-4879-ac9c-5698326c092a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tydiqa_dataset =  tydiqa_dataset.remove_columns([\"passage_answer_candidates\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwOf2UhqBBxD"
      },
      "source": [
        "###### **Exercise 2.5**\n",
        "\n",
        "\n",
        "To have easier access to each of the features in the dataset, let's transform its current nested structure of several types into separate columns using the ``Dataset.flatten()`` method.\n",
        "\n",
        "Once you have the flattened dataset, complete the code in the cell below to display an example's Question, Context, and True answer. Truncate the context to 512 words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "LpyAgWz1BWwi",
        "outputId": "4a4d98c0-672d-41a8-95dc-0f31970370d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question_text', 'document_title', 'language', 'annotations.passage_answer_candidate_index', 'annotations.minimal_answers_start_byte', 'annotations.minimal_answers_end_byte', 'annotations.yes_no_answer', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 9211\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['question_text', 'document_title', 'language', 'annotations.passage_answer_candidate_index', 'annotations.minimal_answers_start_byte', 'annotations.minimal_answers_end_byte', 'annotations.yes_no_answer', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 1031\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tydiqa_dataset = # TODO: flatten the dataset\n",
        "tydiqa_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "KNVpW6lADk92",
        "outputId": "e5e6406b-5f6a-4c16-d7db-7a26acf21a19"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;12m\u001b[1mQuestion: \u001b[0mWhat is the most used language in Europe?\n",
            "\u001b[38;5;10m\u001b[1m\n",
            "Context (truncated): \u001b[0m\n",
            "\n",
            "\n",
            "The languages of the European Union are languages used by people within the member states of the European Union (EU).\n",
            "The EU has 24 official languages, of which three (English, French and German) have the higher status of \"procedural\" languages[4] of the European Commission (whereas the European Parliament accepts all official languages as working languages[5]). One language (Irish) previously had the lower status of \"treaty language\" before being upgraded to an official and working language in 2007, alt...\n",
            "\u001b[38;5;9m\u001b[1m\n",
            "Answer: \u001b[0mEnglish\n"
          ]
        }
      ],
      "source": [
        "idx = 500\n",
        "\n",
        "start_index = # TODO: Get start index of the answer in the context\n",
        "\n",
        "end_index = # TODO: Get end index of the answer in the context\n",
        "\n",
        "question = # TODO: Get question\n",
        "\n",
        "context = # TODO: Get truncated context\n",
        "\n",
        "answer = # TODO: Get true answer\n",
        "\n",
        "print(Fore.LIGHT_BLUE + Style.BOLD + 'Question: ' + Style.RESET + question)\n",
        "print(Fore.LIGHT_GREEN + Style.BOLD + '\\nContext (truncated): ' + Style.RESET + context + '...')\n",
        "print(Fore.LIGHT_RED + Style.BOLD + '\\nAnswer: ' + Style.RESET  + answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHA0Ie6mfiLy"
      },
      "source": [
        "BeFore starting with the preprocessing, we will create a test subset from the validation one so we have one set for testing that has not been seen during the training of the model. Also, to make the training faster, we will extract a subset from each of the latter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtJQeSAuJocE"
      },
      "source": [
        "###### **Exercise 2.6**\n",
        "To generate the final dataset that we are going to use, perform the following steps:\n",
        "\n",
        "1.   Split the validation subset with an $80/20$ ratio\n",
        "2.   Select the first $3000$ entries from the original train set as the final train set.\n",
        "3.   Assign as test and validation subsets the result of splitting the original validation subset: The first $800$ samples of the resulting training subset after the train_test_split will be the final validation set, and the first $200$ of the test subset, the final test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "5tNXT_aGe4fv",
        "outputId": "bbe4b18f-bf9e-479b-9ad0-a1ad10e998d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question_text', 'document_title', 'language', 'annotations.passage_answer_candidate_index', 'annotations.minimal_answers_start_byte', 'annotations.minimal_answers_end_byte', 'annotations.yes_no_answer', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['question_text', 'document_title', 'language', 'annotations.passage_answer_candidate_index', 'annotations.minimal_answers_start_byte', 'annotations.minimal_answers_end_byte', 'annotations.yes_no_answer', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 800\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['question_text', 'document_title', 'language', 'annotations.passage_answer_candidate_index', 'annotations.minimal_answers_start_byte', 'annotations.minimal_answers_end_byte', 'annotations.yes_no_answer', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <SOL>\n",
        "\n",
        "# <SOL>\n",
        "tydiqa_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKMtFdJFi5Vs"
      },
      "source": [
        "####Â <font color='#2B4865'>*2.2.2. Dataset preprocessing*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-lZgDTEYm74"
      },
      "source": [
        "Let's first convert the text in the input into IDs the model can make sense of, using a tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LInV3b_HyAIF",
        "outputId": "27b63160-0035-460e-e37d-42b6ab8a2408"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J0s3sjkkdy2"
      },
      "source": [
        "We know from the previous subsection that our tokenizer expects **padding on the right**, so to tokenize our data we will input first the question and then the context, getting something as follows:\n",
        "\n",
        "```\n",
        "[CLS] question [SEP] context [SEP]\n",
        "```\n",
        "\n",
        "The **labels** will then be the **index of the tokens starting and ending the answer**, and the model will be tasked to predict **one start and end logit** per token in the input, with the theoretical labels being as follow:\n",
        "\n",
        "<br><center><img src=\"https://drive.google.com/uc?id=1KHPILmRPTp_i4WaksmepLsFAvg8beBL_\" width=\"60%\"></center><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zotc4WZwf_un"
      },
      "source": [
        "Below is the ``preprocess_dataset`` function for the extractive question-answering task. When calling the tokenizer, note the following:\n",
        "\n",
        "* Tokenization truncates only the context; specify this with ``truncation=\"only_first\"`` or ``truncation=\"only_second\"`` based on where padding is expected.\n",
        "* Padding is set to the model's maximum supported length.\n",
        "* Set ``return_offsets_mapping``to True so we can map each sub-token's start position and end position relative to the original token it was split from.\n",
        "\n",
        "After tokenization, we remove the text features that are in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SQ0gGQ2auBs7",
        "outputId": "18d26510-a2c2-402e-92a1-d73db6cae28e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def preprocess_dataset(examples):\n",
        "\n",
        "    # Carry out tokenization\n",
        "    questions = [q.strip() for q in examples[\"question_text\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"document_plaintext\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Extract offset mappings from the inputs\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "\n",
        "    # Lists to store start and end positions for each example\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    # Iterate over examples in the batch and their corresponding offset mappings\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "\n",
        "        # Extract the start and end character positions of the minimal answer\n",
        "        start_char = examples[\"annotations.minimal_answers_start_byte\"][i][0]\n",
        "        end_char = examples['annotations.minimal_answers_end_byte'][i][0]\n",
        "        answer = examples[\"document_plaintext\"][i][start_char:end_char]\n",
        "\n",
        "        # Get sequence_ids for the current example\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "93d9350383fa474ab8e483fcf26980af",
            "c6bf94550ed74e4ba957f5acd548fcf1",
            "c6bc14984204437989891c10dadf4a5b",
            "639dd3db877b463a81500557ed114cc4",
            "8b5055c5af7747c08b1cadc122512a3c",
            "e0c7724d189d468bbeead7401f5abf31",
            "80050567ed734572818838676f600f96",
            "7b359bd4b76b48ee9ed0bd707ac7aa27",
            "f719664f22c3489899183cae64a2fbaf",
            "4cc2fd9884354a0f94b44c27b2e185e8",
            "3d50f6814a7c4fe99a34090add1a8ec5",
            "6cb91697dac34e0ebd2249bad83e60f3",
            "d2f3abd3a9e948ac8506626685e01fd6",
            "af254ea0698a4b31a654296727e6a940",
            "877196f7bffd497697e3da96ca9df5a8",
            "ace83fd07e9a40059325650b905164c4",
            "69b8a4a548984453854bd51b688c61d7",
            "6856e67388814595810aff160eca9081",
            "bd0f14a200004cfeb3b4d71fcf6ca97e",
            "e5a19dd63b5f4d5f9bad5294534a4803",
            "c9a7fff03a8e4b6eb3887e7f20a49e95",
            "c189f465ae2140cdb876efb01e2504b4",
            "e03981e6a0ff4243b6d5d27c0da3f1c1",
            "99f14ecfbfc64378869c9fa91e4a6d1f",
            "d53ab39810734710a4d31c30c35b963b",
            "85586d6ae62f433f94b6acf101b133fe",
            "790d6266581b4db0af1ba53cd03c3bd6",
            "13517d0cb5044be799e81f183193a7bc",
            "562e1afc822f4c0d89a21ad74be2be4c",
            "865d3a9bc851455ea639959def320fe7",
            "6220dba6bc924f9ebf9e4484d2f8d6a8",
            "c63ce75de42848d6bc7a0b3f6be45887",
            "4405912bd1a542de99b43d9af053c060"
          ]
        },
        "id": "jNqbEYLCNUGX",
        "outputId": "3dff7c39-e36d-4bf5-8958-39014152bb66"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93d9350383fa474ab8e483fcf26980af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cb91697dac34e0ebd2249bad83e60f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e03981e6a0ff4243b6d5d27c0da3f1c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# <SOL>\n",
        "tokenized_tydiqa_dataset = tydiqa_dataset.map(preprocess_dataset, remove_columns=tydiqa_dataset[\"train\"].column_names, batched=True)\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "xKm4mLIxeO5q",
        "outputId": "e36e6267-53cc-465f-ee86-4971e0af80c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "        num_rows: 800\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_tydiqa_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqVCSOg6loSv"
      },
      "source": [
        "####Â <font color='#2B4865'>*2.2.3. Fine-tuning*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVUI0Z2XM42f"
      },
      "source": [
        "We will be using there the F1 score as a metric to evaluate our model's performance, as defined in the ``compute_f1_metrics`` function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Kisl-WXyM42f",
        "outputId": "2a4acff9-b3d5-4cde-f9c5-bf7872b8acfa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_f1_metrics(pred):\n",
        "    start_labels = pred.label_ids[0]\n",
        "    start_preds = pred.predictions[0].argmax(-1)\n",
        "    end_labels = pred.label_ids[1]\n",
        "    end_preds = pred.predictions[1].argmax(-1)\n",
        "\n",
        "    f1_start = f1_score(start_labels, start_preds, average='macro')\n",
        "    f1_end = f1_score(end_labels, end_preds, average='macro')\n",
        "\n",
        "    return {\n",
        "        'f1_start': f1_start,\n",
        "        'f1_end': f1_end,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQqY07uamHyX"
      },
      "source": [
        "###### **Exercise 2.7**\n",
        "Carry out the fine-tuning of the model. Do not make use of dynamic padding as we have already included padding during the tokenization.\n",
        "\n",
        "Once complete, evaluate the performance of the model with the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Mtd3SW2JNYqw",
        "outputId": "f267b4e1-fa78-4396-bd72-a9e3f1c92582"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='376' max='1880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 376/1880 04:52 < 19:37, 1.28 it/s, Epoch 2/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Start</th>\n",
              "      <th>F1 End</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.309100</td>\n",
              "      <td>1.351250</td>\n",
              "      <td>0.213547</td>\n",
              "      <td>0.144109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.907000</td>\n",
              "      <td>1.355567</td>\n",
              "      <td>0.185121</td>\n",
              "      <td>0.162478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=376, training_loss=1.1080421691245221, metrics={'train_runtime': 293.9, 'train_samples_per_second': 102.076, 'train_steps_per_second': 6.397, 'total_flos': 587938950144000.0, 'train_loss': 1.1080421691245221, 'epoch': 2.0})"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <SOL>\n",
        "\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "orKxQf5JnGY8",
        "outputId": "32641adb-a196-4021-9aef-ad999ff3e6af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.3274760246276855,\n",
              " 'eval_f1_start': 0.16458530432040366,\n",
              " 'eval_f1_end': 0.18496764151716227,\n",
              " 'eval_runtime': 2.6827,\n",
              " 'eval_samples_per_second': 74.552,\n",
              " 'eval_steps_per_second': 4.846,\n",
              " 'epoch': 2.0}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate(tokenized_tydiqa_dataset['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISrMr36mmc57"
      },
      "source": [
        "####Â <font color='#2B4865'>*2.2.4. Make predictions with the fine-tuned model*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Ykq2ipyA2v"
      },
      "source": [
        "We can now test our fine-tuned model. Let's first check how it answers the questions about the Golden Age of Comic Books:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QVP2ksJ1O9iW",
        "outputId": "a40a02bd-21d6-4f43-b946-891cadc956d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "checkpoint = 376\n",
        "checkpoint_new = f\"{path_to_folder}/{checkpoint_name}-finetuned-tydiqa/checkpoint-{checkpoint}\" ## TODO: Update this path to the last saved checkpoint in the former cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "ZYYyfuM0m_SU",
        "outputId": "272dd680-c2ac-48f4-aa69-69cc1eb87b55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;12m\u001b[1mQ: What popular superheroes were introduced between 1939 and 1941?\u001b[0m\n",
            "\u001b[38;5;1mA: Batman and Robin, Wonder Woman\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\u001b[0m\n",
            "\u001b[38;5;1mA: Batman and Robin, Wonder Woman\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What comic book characters were created between 1939 and 1941?\u001b[0m\n",
            "\u001b[38;5;1mA: Superman, Batman, Robin, Captain Marvel, Captain America, and Wonder Woman\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What well-known characters were created between 1939 and 1941?\u001b[0m\n",
            "\u001b[38;5;1mA: Superman, Batman, Robin, Captain Marvel, Captain America, and Wonder Woman\u001b[0m\n",
            "\u001b[38;5;12m\u001b[1mQ: What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\u001b[0m\n",
            "\u001b[38;5;1mA: Superman, Batman, Robin, Captain Marvel, Captain America, and Wonder Woman\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "questions = [\"What popular superheroes were introduced between 1939 and 1941?\",\n",
        "             \"What superheroes were introduced between 1939 and 1941 by Detective Comics and its sister company?\",\n",
        "             \"What comic book characters were created between 1939 and 1941?\",\n",
        "             \"What well-known characters were created between 1939 and 1941?\",\n",
        "             \"What well-known superheroes were introduced between 1939 and 1941 by Detective Comics?\"]\n",
        "\n",
        "question_answerer = pipeline(task='question-answering', model=checkpoint_new)\n",
        "\n",
        "results = question_answerer(question=questions, context=context2)\n",
        "\n",
        "for q, r in zip(questions, results):\n",
        "  print(Fore.LIGHT_BLUE + Style.BOLD + f'Q: {q}' + Style.RESET)\n",
        "  print(Fore.RED + \"A: \" + r['answer'] + Style.RESET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5PJillsyMZB"
      },
      "source": [
        "You should see an improvement in the answer in comparison to what we were obtaining before the fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2q8SA_V72c9"
      },
      "source": [
        "####Â <font color='#2B4865'>*2.2.5. Some final notes about fine-tuning a Q&A system*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_UlBv--7zFU"
      },
      "source": [
        "Though, you should note that even when we improved the performance of our Question Answering system, it still does not perform perfectly. You can test this by checking how it answers some of the questions in the test set. The main reason behind this is that we are truncating the contexts, which leads to losing the answer we are looking for on many occasions. Hugging Face does provide a better way of handling long contexts: let the long examples in our dataset give several input features, each of length shorter than the maximum length of the model. This can be achieved via the parameter ``return_overflowing_tokens=True`` and some additional configuration. If you want to know more about the topic, you can check [Hugging Face documentation about it](https://huggingface.co/course/chapter6/3b?fw=pt).\n",
        "\n",
        "You should also take into account that here we have used the F1 score as a metric to evaluate our model's performance. Yet, using this metric is just a simplification of how to deal with the evaluation, since it is based on the start and end values predicted by the model. If you want to dig deeper into other metrics that can be used for a Q&A, you can also check [this colab notebook](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb) resource from the Hugging Face team."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJKwLtujCyb"
      },
      "source": [
        "## <font color='#2B4865'>**3. Summarization**\n",
        "---\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmnIWqWDsrEz"
      },
      "source": [
        "**Summarization** is the task of producing a shorter version of a document while preserving its important information. Along with translation, it is another example of a task that can be formulated as a **sequence-to-sequence** task, i.e., we can formulate it as going from one sequence to another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5cvtkkRoMTE"
      },
      "source": [
        "##### <font color='#2B4865'>**Architecture for approaching the task**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ2etKXsEY-L"
      },
      "source": [
        "As we saw in the introductory session, there exist two types of summarization:\n",
        "* **Extractive**, when the summary consists of text extracted from the original input.\n",
        "* **Abstractive**, when the models can generate entirely new text.\n",
        "\n",
        "Accordingly, to its **sequence-to-sequence nature**, most Transformer models for summarization adopt the **encoder-decoder** architecture, although there are **some exceptions like the GPT family** of models which can also be used for summarization in few-shot settings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwi4s87QoSsN"
      },
      "source": [
        "##### <font color='#2B4865'>**Evaluation metrics**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpfShPKJmHSB"
      },
      "source": [
        "In comparison to the other tasks that we have covered in this tutorial, measuring the performance of text generation tasks such as summarization or translation is not straightforward.\n",
        "\n",
        "For instance, let's imagine that we want to generate a summary for the sentence \"*I loved watching Spiderman*\". We can find multiple valid summaries, such as \"*I loved Spiderman*\" or \"*Spiderman is a great movie\"*. Due to this, attempting to measure the performance by matching the generated summary and the label is not a good solution.\n",
        "\n",
        "For summarization, one of the most commonly used metrics is the **ROUGE score** (Recall-Oriented Understudy for Gisting Evaluation). Its basic idea is to compare a generated summary against a set of reference summaries that are typically created by humans.\n",
        "\n",
        "More precisely, suppose we want to compare the following two summaries:\n",
        "```\n",
        "generated_summary = \"I absolutely loved watching Spiderman\"\n",
        "reference_summary = \"I loved watching Spiderman\"\n",
        "```\n",
        "\n",
        "One way of comparing them would be to count the number of overlapping words ($6$ here). Since this is not really refined, ROUGE alternatively computes a metric based on the precision and recall scores for the overlap\n",
        "\n",
        "The **recall** measures how much of the reference summary is captured by the generated one. If we are just comparing words, recall can be calculated as follows:\n",
        "\n",
        "$$Recall = \\frac{\\text{Number of overlapping words}}{\\text{Total number of words in reference summary}}$$\n",
        "\n",
        "\n",
        "For the above example, the recall takes a value of $4/4=1$, i.e., a perfect recall (all the words in the reference summary have been produced by the model). Still, we could have that the generated summary was \"*I really really loved watching Spiderman all night*\" which will have also a perfect recall, even though it is a much worse summary (it is verbose).  \n",
        "\n",
        "To deal with the former scenarios, we utilize the **precision** to measure how much of the generated summary was relevant as:\n",
        "\n",
        "$$Precision = \\frac{\\text{Number of overlapping words}}{\\text{Total number of words in generated summary}}$$\n",
        "\n",
        "\n",
        "Applying this to our verbose summary gives a precision of $4/8 = 0.5$, which is considerably worse than the precision of $4/5 = 0.8$ obtained by our shorter one. In practice, both precision and recall are usually computed, and then the F1-score (the harmonic mean of precision and recall) is reported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDoZhmGj2MPc"
      },
      "source": [
        "###Â <font color='#2B4865'>*3.1. Inference*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THKmG-Wu9hjh"
      },
      "source": [
        "As we have seen in the previous sections, we can perform inference on any task by means of a pipeline. For the specific case of summarization, we just need to add the task identifier ``summarization``, in addition to the checkpoint model we want to use; when the latter is not specified, the default model will be used ([``sshleifer/distilbart-cnn-12-6``](https://huggingface.co/sshleifer/distilbart-cnn-12-6))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib_nayXs-v07"
      },
      "source": [
        "###### **Exercise 3.1**\n",
        "\n",
        "Choose a model for English summarization [from the Hub](https://huggingface.co/models?pipeline_tag=summarization) (but different from the pipeline's default) and use it to create a summarization pipeline. Extract any text from the Wikipedia of your choice through the Wikipedia API and use the pipeline to summarize it. The task identifier for the summarization task is ``summarization``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYMqpPDdHZlX"
      },
      "outputs": [],
      "source": [
        "# <SOL>\n",
        "\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "wK8ZOsigH5hJ",
        "outputId": "27679cf5-ad8f-4286-83a8-362ee0eee4fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;12m\u001b[1mText to summarize:\u001b[0m\n",
            "In statistics and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"cat\" and \"meow\" will appear in documents about cats, and \"the\" and \"is\" will appear approximately equally in both. A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. The \"topics\" produced by topic modeling techniques are clusters of similar words. A topic model captures this intuition in a mathematical framework, which allows examining a set of documents and discovering, based on the statistics of the words in each, what the topics might be and what each document's balance of topics is.\n",
            "Topic models are also referred to as probabilistic topic models, which refers to statistical algorithms for discovering the latent semantic structures of an extensive text body. In the age of information, the amount of the written material we encounter each day is simply beyond our processing capacity. Topic models can help to organize and offer insights for us to understand large collections of unstructured text bodies. Originally developed as a text-mining tool, topic models have been used to detect instructive structures in data such as genetic information, images, and networks. They also have applications in other fields such as bioinformatics and computer vision.\n",
            "\n",
            "\u001b[38;5;12m\u001b[1mSummary:\u001b[0m\n",
            "In statistics and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Originally developed as a text-mining tool, topic models have been used to detect instructive structures in data such as genetic information, images and networks.\n"
          ]
        }
      ],
      "source": [
        "# <SOL>\n",
        "import wikipedia\n",
        "\n",
        "text_to_summarize = # TODO\n",
        "summary = # TODO\n",
        "# <SOL>\n",
        "\n",
        "print(Fore.LIGHT_BLUE + Style.BOLD + 'Text to summarize:' + Style.RESET)\n",
        "print(text_to_summarize)\n",
        "print()\n",
        "print(Fore.LIGHT_BLUE + Style.BOLD + 'Summary:' + Style.RESET)\n",
        "print(summary[0]['summary_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVRmwqiqKju7"
      },
      "source": [
        "This works pretty well. However, if our objective is to generate summaries in a specific context, a fine-tuned model in such a context will be a better match. Let's see how to fine-tune a model for making summaries out of English news."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8YV7co1KhNM"
      },
      "source": [
        "###Â <font color='#2B4865'>*3.2. Fine-tuning*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7hm1WMvOCxH"
      },
      "source": [
        "####Â <font color='#2B4865'>*3.2.1. Loading in the dataset*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPiV-PRJOEgU"
      },
      "source": [
        "We will use the [CNN Dailymail Datasets](https://huggingface.co/datasets/cnn_dailymail) dataset to create our ad-hoc summarizer. It consists of English  news articles written by journalists at CNN and the Daily Mail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQFnW4CkO8MD"
      },
      "source": [
        "###### **Exercise 3.2**\n",
        "\n",
        "Download the version \"3.0.0\" from the CNN Dailymail Dataset. Save the ``DatasetDict`` object in variable named ``cnn_dataset``. To download the subset specific to the asked version, you just need to add the identifier, in this case ``3.0.0``, to the dataset loading function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "t_GuOPv7O7JZ",
        "outputId": "256acfe6-19fc-4ebf-910c-bad694ed2c76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <SOL>\n",
        "\n",
        "# </SOL>\n",
        "cnn_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rs8wRHiSV1B"
      },
      "source": [
        "As shown, we have $287,113$, $13,368$, and $501,149,000$ article-highlight pairs for the train, validation, and test sets, respectively. Given the large volume of data, we'll choose a subset of $3,000$, $800$, and $200$ samples for the train, validation, and test sets in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0t6W518y-5cI",
        "outputId": "b8c5093a-7f66-48d8-8b18-0c1e9a01b91a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cnn_dataset = DatasetDict({\n",
        "    \"train\": cnn_dataset[\"train\"].select(range(3000)),\n",
        "    \"val\": cnn_dataset[\"validation\"].select(range(800)),\n",
        "    \"test\": cnn_dataset[\"test\"].select(range(200)),\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhrynkmWumgS"
      },
      "source": [
        "Now, let's display a few samples to gain insight into their characteristics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3Pvk5-m6j7q8",
        "outputId": "3f0b86ed-a2ab-435c-f4f6-a4827fc3423a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;12m\u001b[1m\n",
            ">> Highlights:\u001b[0m Julian E. Zelizer: The Obama presidency resembles that of Lyndon B. Johnson .\n",
            "Zelizer says both aimed high and worked skillfully with congressional leaders .\n",
            "A president can shape legislation without dictating the details, professor says .\n",
            "Zelizer: Obama has gotten big results from Congress by keeping leaders on his side .\n",
            "\u001b[38;5;2m\u001b[1m>> Article:\u001b[0m Editor's note: Julian E. Zelizer is a professor of history and public affairs at Princeton University's Woodrow Wilson School. His new book, \"Arsenal of Democracy: The Politics of National Security -- From World War II to the War on Terrorism,\" will be published this fall by Basic Books. Zelizer writes widely on current events. Julian E. Zelizer says so far the Obama presidency resembles that of Lyndon B. Johnson. PRINCETON, New Jersey (CNN) -- While pundits have compared President Obama to Franklin Delano Roosevelt, John F. Kennedy, Jimmy Carter and Ronald Reagan, less attention has been paid to another, perhaps more apt parallel -- Lyndon Baines Johnson. Sometimes the similarities are striking. Both aimed high, seeking major legislation to reshape America -- Johnson with civil rights and Medicare, Obama with health care and energy legislation. Both Johnson and Obama understood that Congress was a credit-claiming institution whose members did not like to have proposals rammed down their throats. Johnson's style of political leadership was famous. A creature of the Senate, Johnson loved to lean on legislators and intimidate them into supporting his agenda. As Senate majority leader from 1955 to 1961, Johnson had been famous for subjecting colleagues to the \"Treatment\" whereby the hulking Texan cornered a legislator in the hallway, stood eye to eye and made his arguments about a bill until he received assurances of support for particular legislation. Although Johnson slightly changed his posture once he was president, he still relied on this kind of interaction to build support. As president from November 1963 until January 1969, Johnson worked closely with the Southern committee chairmen and ranking Republicans who dominated the House and Senate. Johnson sought to achieve a delicate mix of maintaining control over deliberations -- thinking of ways to obtain what he wanted without giving the appearance of it being a presidential-led idea -- all while responding to the concerns of the chairmen. The back-and-forth deliberations with House Ways and Means Chairman Wilbur Mills over the creation of Medicare in 1965 have become the classic example of how a president can work the chamber while allowing a congressional leader into the room to shape a bill in ways with which he'll be comfortable. Johnson agreed to redesign the particulars of the legislation so that the final program would protect the fiscal integrity of Social Security (under which it was included) and contain long-run costs. Thus far, Obama has taken a similar approach with the economic stimulus and, more recently, with his budget proposal. The president outlined to Congress the basic ideas he wanted in the final product but then left to lawmakers the work of designing the details. While the downside has been that Obama relinquished control over the structure of the legislation, House and Senate Democrats have felt invested and empowered to produce what Obama's team viewed as successful results. The second similarity is that Johnson, like Obama, distanced himself from the arguments of liberals who said that conservatives did not need to be feared. Johnson was consumed by his fears of a right-wing resurgence, even after trouncing Republican Barry Goldwater in the 1964 election. Johnson constantly warned advisers that the most dangerous political force in the country as far as he was concerned was not the left on college campuses but what he called the \"reactionary element\" within the GOP, and he took this into consideration when shaping legislative proposals. With domestic policy, Johnson avoided programs that could be tagged as \"socialistic,\" and on foreign policy he worked hard to demonstrate a tough stance against communism. Recently released telephone conversations have revealed that Johnson was obsessed with the 1966 midterm elections after the 1964 election was over, realizing that historically those results were not likely to be good for the White House. Obama has been reluctant to embrace liberal arguments about an end to the Age of Reagan, courting conservative journalists such as David Brooks instead of liberal pundits such as Paul Krugman. He accepted compromises on legislation in response to moderates in both parties and agreed to a financial bailout that pleased Wall Street, not Main Street. And his administration has steered clear of explicitly nationalizing banks, a step that could be called socialist. Obama has even touched on sensitive subjects such as deficit reduction and Social Security reform, which are much more appealing to the right than left. During one important conversation, Obama told the centrist Democratic Sen. Evan Bayh of Indiana that he need not worry about his administration going too far on spending since he identified himself as a New Democrat, a reference to members of the party who in the Clinton years believed that they needed to accept some of the arguments of the conservative movement. Finally, both presidents understood the strategic importance of leveraging social movements to their political advantage. During the height of the struggles over civil rights, Johnson frequently pointed to the growing power of the grass-roots civil rights movement as he tried to pressure undecided legislators to support legislation to end public segregation and then to ensure voting rights for African-Americans. Johnson made it clear that the movement had become a potent force in American life, winning the hearts and minds of citizens, and that it could cause political trouble for his opponents. Obama has shown glimmers of a similar strategy with regard to the budget. The administration recently announced that it was trying to mobilize the \"net roots\" operation from the 2008 campaign to build pressure on wavering representatives and senators to support his plans on health care and the environment. The comparisons between Johnson and Obama likewise offer reminders about what could go wrong for the current president. After all, Johnson was a politician who looked like a transformative president in 1965 but within three years found himself to be a defeated man who withdrew from the Democratic primaries. Johnson's fears of the right, moreover, pushed him and America deeper into the deadly war in Vietnam. The social movements that LBJ used to his benefit in 1964 and 1965 turned against him as the administration plunged deeper into Vietnam, a lesson worth thinking about for the current administration. Johnson's policy of respect for committee chairmen prompted him to make compromises over social policy -- such as cuts in social spending in 1968 -- that weakened his support among the very Democrats he needed to win re-election. Johnson was never fully aware of how his greatest political skills could also become the source of his downfall. Obama's challenge is to harness the best parts of this comparison -- such as how Johnson handled Congress to produce dramatic legislative results -- without repeating the destructive characteristics that shattered Johnson's White House. The opinions expressed in this commentary are solely those of Julian E. Zelizer.\n",
            "{'----------'}\n",
            "\u001b[38;5;12m\u001b[1m\n",
            ">> Highlights:\u001b[0m Chelsea Clinton steps up her role in her mother's  campaign .\n",
            "The Clintons have always shielded their daughter from the media spotlight .\n",
            "Ex-first daughter, who soon turns 28, will campaign in Hawaii for Tuesday caucuses .\n",
            "\u001b[38;5;2m\u001b[1m>> Article:\u001b[0m WASHINGTON (CNN) -- She's faced the glare of public life since she was a girl, but Chelsea Clinton must contend with renewed press scrutiny as she increasingly assumes a role in her mother's campaign for president. Chelsea Clinton accompanies her mother to the polls on Super Tuesday in Chappaqua, New York. The former first daughter always has been off-limits to the media, especially while she was growing up in the White House. But pressure to burst this protective bubble is likely to grow as the soon-to-be 28-year-old campaigns across the country for Sen. Hillary Clinton, even heading to Hawaii -- Sen. Barack Obama's home turf. Chelsea Clinton will spend three days there to strum up last-minute votes before the state's Tuesday caucuses, said a source from her mother's campaign. In the rough-and-tumble world of politics, her parents always have been protective of her -- including most recently after a TV correspondent's comment that the Clinton campaign found inappropriate.  Watch how controversy goes with the last name Â» . \"Doesn't it seem as if Chelsea is being pimped out in some weird sort of way?\" MSNBC correspondent David Shuster said this month about her reputed calls to superdelegates. Clinton communications director Howard Wolfson excoriated Shuster and called his remarks \"beneath contempt\" and disgusting. The senator from New York even sent a damning letter to NBC and demanded \"appropriate action.\" \"I am a mom first and a candidate second, and I found the remark incredibly offensive,\" she said. (Shuster was suspended indefinitely for the remark, made February 7 when he was a guest host for Tucker Carlson. MSNBC said Thursday that the suspension will end February 22.) Even a fourth-grader apparently can't get through to the press-shy Chelsea Clinton. Scholastic News \"kid reporter\" Sydney Rieckhoff was in pursuit of a story as she questioned presidential candidates last month on the campaign trail in Iowa, according to The Associated Press. Approaching Chelsea Clinton, she reportedly asked, \"Do you think your dad would be a good 'first man' in the White House?\" But Clinton wasn't talking. \"I'm sorry, I don't talk to the press and that applies to you, unfortunately. Even though I think you're cute,\" she said, according to the AP. During a campaign stop at the Luckie Food Lounge in Atlanta, Georgia, in mid-January, one supporter asked Clinton to reveal something that nobody else knew about her. She responded she would love to -- if all the cameras weren't around. Clinton has proven to be an effective campaigner for her mother, according to a campaign source, saying there's a strong correlation between her visits and improved performance. At this point, the campaign has become a fight for delegates, and even narrowing a loss has a big impact, a source said. This election cycle, Clinton campaigned for her mother in California, the first state where the senator won the youth vote. A rural congressional district in Nebraska where she campaigned reportedly outperformed others in the state. Politicians protecting their children from the spotlight is hardly new. The Bushes complained when daughters Jenna and Barbara became fodder for late-night comics and media outlets. Vice President Dick Cheney also has been reticent when it comes to his daughter Mary, who had a child with her lesbian partner. During a debate with Cheney in 2004, Democratic vice presidential candidate John Edwards broached the topic, saying, \"I think the vice president and his wife love their daughter. I think they love her very much. And you can't have anything but respect for the fact that they're willing to talk about the fact that they have a gay daughter.\" Cheney responded, \"Let me simply thank the senator for the kind words he said about my family and our daughter. I appreciate that very much. ... That's it.\" But the vice president later slammed Sen. John Kerry for his remarks about Mary Cheney when asked about homosexuality during a debate with President Bush. The vice president said Kerry was \"out of line;\" wife Lynne Cheney called him \"not a good man.\" These exchanges show that as Chelsea Clinton's public persona rises, so too will questions about why she doesn't make herself available to reporters. The Clinton campaign said Chelsea Clinton is trying to reach as many people as possible and has \"appeared in dozens of venues in more than 20 states.\" But she's still not granting interviews. E-mail to a friend . CNN's Trisha Henry, Frank Sesno, Rebecca Sinderbrand and Jessica Yellin contributed to this report. Copyright 2008 CNN. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed. Associated Press contributed to this report.\n",
            "{'----------'}\n",
            "\u001b[38;5;12m\u001b[1m\n",
            ">> Highlights:\u001b[0m Incest dad twice holidayed in Thailand while daughter remained in cellar .\n",
            "Austrian family terrorized by decades of incest meet for the first time .\n",
            "Josef Fritzl kept daughter imprisoned under home for 24 years, police say .\n",
            "Fritzl, who appeared in court Tuesday, has admitted guilt and faces 15 years| .\n",
            "\u001b[38;5;2m\u001b[1m>> Article:\u001b[0m AMSTETTEN, Austria (CNN)  -- Josef Fritzl, who Austrian police say has confessed to imprisoning his daughter for 24 years and fathering seven of her children, twice holidayed in Thailand while she remained trapped in a cellar below his house, according to German media reports. Josef Fritzl appeared in court after admitting raping his daughter and fathering her seven children. Germany's Bild newspaper quoted a holiday companion, identified only as Paul H, who said he and 73-year-old Fritzl traveled to Thailand together twice and spent time in each other's homes. \"He went [to Thailand] without his wife; apparently she had to look after the children. ... Once he had a very long massage from a young Thai girl at the beach. He really loved that,\" Paul H told the newspaper, which featured video of Fritzl laughing and receiving a massage in Thailand on its Web site. \"Once I saw how Josef bought an evening dress and racy lingerie for a very slim woman in Pattaya [Thailand] on the beach. He got really angry when he realized I saw him. Then he told me that he has a girlfriend on the side. The items were meant for her. He told me not to tell his wife.\"  Watch footage of Fritzl on vacation at a Thai beach resort Â» . The pair had also ventured to Oktoberfest. Paul H said he had visited Fritzl's house three times, the last in 2005. \"We sat out on the terrace and had a really nice evening. ... The kids were well-behaved, however; they had a great respect for their father. They were never allowed downstairs into the cellar, but we never thought anything of it,\" he told Bild. \"Now that I think of the dungeon down there, I feel really sick in the stomach.\" Paul H said Fritzl was a DIY \"genius,\" constantly extending and building on to the house. Meanwhile, family members at the center of the incest and imprisonment case have held an \"astonishing\" reunion, medical officials said. \"They met each other on Sunday morning,\" clinic director Berthold Kepplinger said Tuesday. \"And it is astonishing how easy it worked, that the children came together, and also it was astonishing how easy it happened that the grandmother and the mother came together.\" Investigators say Fritzl held his daughter, Elisabeth, captive in a cellar for 24 years. He raped her repeatedly, they say, and eventually fathered seven of her children. Elisabeth and two of her children were reunited Sunday with three of her other children and her mother, Kepplinger said Tuesday. The three children and her mother lived in the home above the cellar. Elisabeth's eldest child, 19-year-old Kerstin Fritzl, remains in hospital. A seventh child died years ago, shortly after birth. Fritzl told police he burned the infant's body in a furnace. The story of the family's imprisonment began to unravel a week ago, when Kerstin fell seriously ill with convulsions and was hospitalized. Austrian police Wednesday denied reports that they were investigating possible links between Fritzl and the unsolved murder of a woman. Franz Polzer, director of the Lower Austrian Bureau of Criminal Affairs, said Fritzl had owned an Austrian hotel near where a woman was found murdered decades ago. However, they were not investigating the incident at this stage. Meanwhile, an Austrian girl who was held prisoner in a basement for eight years said the family faced a long period of adjustment.  See how Austrians are troubled by the case Â» . Natascha Kampusch was 10 years old when she was kidnapped on her way to school in March 1998. She escaped from a bunker below the house of Wolfgang Priklopil in a suburb of Vienna in August 2007. Priklopil killed himself by throwing himself under a train only hours later. \"Although they are now in a secret location, I believe it might have been even better to leave them where they were, but that was probably impossible,\" she said of the Fritzl family Tuesday. \"Yes, because that was of course the environment they were used to, and now they're somewhere else. Pulling them abruptly out of this situation, without transition, to hold them and isolating them to some extent, it can't be good for them.\" Officials said Tuesday that DNA testing had confirmed Fritzl fathered the children. His DNA also was found on a letter sent to the Fritzl family that was made to look like it was from his daughter, Elisabeth, Polzer said.  See inside the 'House of horrors' Â» . Authorities said Fritzl sent other letters over the years, leading the family to believe that Elisabeth was a runaway who had abandoned three of her children on their doorstep. He dictated at least one of the letters to his daughter, they said. Authorities said it did not appear that Fritzl's wife, Rosemarie, knew about her husband's activities. Reports have surfaced in The Times of London and Austria's Presse that Fritzl was convicted of sexual assault in the 1960s, but there is nothing in his record to confirm this, said District Governor Hans Heinz Lenze. He added, however, that records were expunged after a certain number of years. Prosecutors were checking archives to find the information, said Gerhard Sedlacek, prosecutor for the state of Poelten. The Times of London quoted a 50-year-old neighbor who said that when he was 10, he remembered \"how we children were afraid to play near Mr. Fritzl's house because of the rumors that he had raped a woman and spent some time in jail for it.\"  Watch a report of how the case unfolded. Â» . Fritzl led police to the cellar Sunday. A day later, he confessed to raping his daughter, now 42, and keeping her and their children in captivity, police said. Fritzl was able to convince social service workers, friends and family that Elisabeth had run away in 1984, when she was about 18. The father, who police described as an authoritarian figure, forbade anyone from entering the cellar. In the cellar with Elisabeth were Kerstin and two sons, aged 5 and 18. E-mail to a friend . CNN's Phil Black, Nadine Schmidt and Eileen Hsieh contributed to this story.\n",
            "{'----------'}\n",
            "\u001b[38;5;12m\u001b[1m\n",
            ">> Highlights:\u001b[0m Sens. Clinton and Obama hold a unity rally in Unity, New Hampshire .\n",
            "Crowley: A \"day of togetherness that Barack Obama had wanted\"\n",
            "\"It was not entirely believable, but politics is the art of pragmatism,\" Crowley adds .\n",
            "\u001b[38;5;2m\u001b[1m>> Article:\u001b[0m UNITY, New Hampshire (CNN) -- The day began with a kiss. Sen. Hillary Clinton and Sen. Barack Obama leave Washington on Friday for a rally in New Hampshire. Sen. Barack Obama, on the tarmac at Reagan Washington National Airport, reached out to shake Sen. Hillary Clinton's hand and leaned down to kiss her cheek. It went on from there. Wearing a tie that matched her suit, he put his hand on her back, guiding the way up the plane steps. They sat side-by-side for the flight up to Manchester, New Hampshire, chatting amiably. One overheard conversation was about the plane. Clinton had used it during the primary season. They hopped on a souped-up bus for the 1Â½-hour ride to Unity, New Hampshire. The honorary mayor of Unity introduced the pair, admitting that he was a Republican who voted for John McCain in the primary. He didn't seem so sure about the general election. They walked onstage to the tune of \"Beautiful Day.\" Arms around each other's waists, they smiled and waved at the crowd. Every camera angle had UNITY signs, big and little, in the backdrop. She said she wants to help elect him president. He gave an ode to Hillary: \"She rocks.\"  Watch more from Unity Â» . One woman stood at the back, periodically yelling, \"Hillary for VP!\" A few others, older women, stubbornly held up tattered Hillary For President placards. But the vast majority cheered her, \"Thank you, Hillary!\" and him, \"Yes, we can!\" They held new signs for the new times: \"UNITY FOR CHANGE.\" As the dynamic duo glowed onstage, a Clinton staffer circulated through the press corps with word that Hillary and Bill Clinton had gone online to give the maximum contribution allowed by law to the Obama for President campaign. It was the picture-perfect day of togetherness that Barack Obama had wanted. It was not entirely believable, but politics is the art of pragmatism.\n",
            "{'----------'}\n",
            "\u001b[38;5;12m\u001b[1m\n",
            ">> Highlights:\u001b[0m NEW: Test pilot David Cooley, 49, of Palmdale, California, dies in crash .\n",
            "F-22A fighter jet crashes 35 miles northeast of Edwards AFB around 10:30 a.m.\n",
            "The one-seater jet was on a test mission when it crashed .\n",
            "At $150 million apiece, the F-22A is the most expensive Air Force fighter .\n",
            "\u001b[38;5;2m\u001b[1m>> Article:\u001b[0m WASHINGTON (CNN) -- An Air Force F-22A fighter jet crashed Wednesday near Edwards Air Force Base in California, killing the test pilot, the Air Force said. An F-22A fighter jet similar to this one crashed Wednesday during a test mission in California. The single-seater crashed about 10:30 a.m. (1:30 p.m. ET) for unknown reasons, Air Force officials said. Lockheed Martin said the test pilot, David Cooley, 49, of Palmdale, California, joined the company in 2003 and was a 21-year veteran of the U.S. Air Force. The fighter was on a test mission when it crashed about 35 miles northeast of  Edwards AFB, where it was stationed, the Air Force said in a news release. At $150 million apiece, the F-22A is the most expensive Air Force fighter. In 2004, an F-22 Raptor crashed on a training mission in the Nevada desert. The pilot ejected and was not hurt, though the jet was destroyed. The plane was designed in the 1980s to provide a stealthy method to enter Soviet air space and strike Soviet bombers if the USSR attempted a nuclear strike. Once the Cold War ended, the Air Force found a new mission for the F-22 as a long-range fighter with a sophisticated stealth design and state-of-the-art equipment that no other plane could rival. However, the rising cost of the plane and numerous design and software problems threatened the program, which was almost eliminated by Congress. In the end, the aircraft survived, and most of the problems were fixed -- except for the price tag, which forced the Air Force to buy fewer aircraft.\n",
            "{'----------'}\n"
          ]
        }
      ],
      "source": [
        "def show_samples(dataset, num_samples=2, seed=42):\n",
        "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
        "    for example in sample:\n",
        "        print(Fore.LIGHT_BLUE + Style.BOLD + '\\n>> Highlights:' + Style.RESET, example['highlights'])\n",
        "        print(Fore.GREEN + Style.BOLD + '>> Article:' + Style.RESET, example['article'])\n",
        "        print({\"-\" * 10})\n",
        "\n",
        "show_samples(cnn_dataset, num_samples=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZPEuStZ3kLM"
      },
      "source": [
        "Now that we have a training corpus, one final thing to check is the distribution of words in the articles-hightlights pairs. This is especially important for summarization tasks, where short reference summaries in the data can bias the model to only output one or two words in the generated summaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slCLv4qO35VF"
      },
      "source": [
        "###### **Exercise 3.3**\n",
        "\n",
        "Plot two histograms: one for the word distribution in the reviews and another one for those in the titles (summaries) in the **train** subset. Also, calculate the average number of tokens per review and summary. For easiness, convert the training dataset into a Pandas DataFrame.\n",
        "\n",
        "You can convert a ``DatasetDict`` object into a ``pandas.DataFrame`` by applying ``DatasetDict.set_format(\"pandas\")``.\n",
        "\n",
        "Once you are finished with the exercise, do not forget to restore the dataset to its original format with the ``reset_format()`` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QvQEAEvo5NO6",
        "outputId": "248a1d90-5c50-4640-d8ce-f7f47e5e7157"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# <SOL>\n",
        "# TODO: Transform cnn_dataset into pandas DataFrame and take train subset\n",
        "\n",
        "# TODO: Tokenize train subset's documents and summaries\n",
        "\n",
        "# TODO: Save tokenized subsets in dataframe\n",
        "\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "-I1OJQFZAAD4",
        "outputId": "c543bf78-ab8f-4697-b5c1-9a2fe0a148ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average number of tokens per review: 605.7106666666666\n",
            "Average number of tokens per summary: 43.471333333333334\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 388,
              "width": 1190
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# <SOL>\n",
        "# TODO: Plot histograms\n",
        "\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5WFGfg109ibc",
        "outputId": "9933b40b-c0e5-4781-8b58-47d159ac88b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# <SOL>\n",
        "# TODO: Reset format of cnn_dataset\n",
        "\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7ZSFro8Q_k"
      },
      "source": [
        "The distribution of both articles and highlights is generally well-balanced, requiring no additional processing at this stage. It's worth noting, however, that if, for instance, the highlights were heavily skewed towards 0 words, filtering out examples with very short titles may be necessary to ensure our model generates more meaningful summaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYW2CgKBIqN8"
      },
      "source": [
        "Now that we have our dataset ready, it is time to look for the model. In this case, we are going to use the small version of the **T5** model.\n",
        "\n",
        "As we saw in class, in T5, every NLP task is defined in terms of a prompt prefix, such as summarise, which causes the model to adjust the output text to the prompt, thus making T5 quite versatile in the sense that solves many tasks within a single model:\n",
        "\n",
        "<br><center><img src=\"https://drive.google.com/uc?id=1OFzqv_1NCqoc_sRzwsK154XOCOIcZHG6\" width=\"60%\"></center><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYWH57OcE3E3"
      },
      "source": [
        "####Â <font color='#2B4865'>*3.2.2. Dataset preprocessing*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF_Yx3B6E8Q-"
      },
      "source": [
        "Our next task is to **tokenize and encode** our document-summary pairs. We will be using ``t5-small`` as our model checkpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqNExvHzQvPB"
      },
      "source": [
        "###### **Exercise 3.4**\n",
        "\n",
        "Load the tokenizer associated with the pretrained model checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BK1KuP6GE-dW",
        "outputId": "9b4d9df1-56ab-4482-bfa3-c74bbcb39602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# <SOL>\n",
        "model_checkpoint = \"t5-small\"\n",
        "tokenizer = # TODO\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juynYNmPGFwW"
      },
      "source": [
        "Letâ€™s start by testing out the T5 tokenizer on a small example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "knlVef_1GIK0",
        "outputId": "e0992583-148e-4313-f6c0-3c1d2b2f7870"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    input_ids:\n",
            "        [27, 1858, 3355, 18617, 348, 55, 1]\n",
            "    attention_mask:\n",
            "        [1, 1, 1, 1, 1, 1, 1]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(\"I loved watching Spiderman!\")\n",
        "print_encoding(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP1cIIv3GKsA"
      },
      "source": [
        "As usual, we see the ``input_ids`` and ``attention_mask`` we have been dealing with until now. Letâ€™s decode these input IDs to see the kind of tokenizer weâ€™re utilzing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iOxzljCDGRPD",
        "outputId": "b8bda491-d1b4-45a2-f424-e072edb386b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "['â–I', 'â–loved', 'â–watching', 'â–Spider', 'man', '!', '</s>']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ajv2N62GVav"
      },
      "source": [
        "The special Unicode character â– and end-of-sequence token </s> indicate that weâ€™re dealing with the **SentencePiece tokenizer**.\n",
        "\n",
        "> **Unigram:** Subword tokenization algorithm introduced [here](https://arxiv.org/pdf/1804.10959.pdf). Instead of starting with a group of base symbols and learning merges with some rule, like BPE, it starts from a large vocabulary (for instance, all pretokenized words and the most common substrings) that it will trim down progressively.\n",
        "\n",
        "> **SentencePiece:** Tokenization algorithm that is agnostic about accents, punctuation, and the fact that many languages, like Japanese, do not have whitespace characters. It achieves this by treating the input as a raw stream, including the space in the set of characters to use and then using the unigram tokenization to construct the appropriate vocabulary. The â€˜â–â€™ characters represent here spaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gppLbBEG2Jz"
      },
      "source": [
        "To tokenize our corpus, we must contend with a summarization-related complication: because our labels are also text, they may exceed the model's maximum context size. To avoid passing extremely long inputs to our model, we must apply truncation to both the articles and their highlights. Transformers' tokenizers allow us to do this via the ``text_target`` argument, thanks to which we can tokenize the labels in parallel to the inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwvPbp6DmB2H"
      },
      "source": [
        "###### **Exercise 3.5**\n",
        "\n",
        "Implement the function ``preprocess_dataset`` that carries out the preprocessing of the inputs and targets for T5. Note that the variables ```max_input_length``` and ```max_target_length``` define the upper limits for how long the documents and summaries are going to be.\n",
        "\n",
        "Take into account the following for the implementation of the ``preprocess_dataset`` function:\n",
        "\n",
        "*  You need to call the tokenizer twice: once for carrying out the preprocessing of the articles (``article``) and once for that of the summaries (``highlights``).\n",
        "*  For the tokenization of the reviews:\n",
        "  * Prefix the inputs with ``\"summarize:\"``\n",
        "  * Use the options ``max_length=max_input_length`` and ``truncation=True``.\n",
        "*  For the tokenization of the summaries:\n",
        "  * Use the options ``max_length=max_target_length`` and ``truncation=True``.\n",
        "\n",
        "\n",
        "Once the preprocessing function is defined, use the ``map()`` function to apply it to the whole dataset. For doing so, use the following parameters:\n",
        "*   ```batched=True``` to operate with batches of example (of default batch size $1,000$)\n",
        "*   ```remove_columns``` to get rid of the string columns that we do not need anymore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ae2001c5bec24d55a78ebe8c524e8454",
            "8f747039ca084a529080974dffdc5d97",
            "674a8bdc92934e9bbcac12a1059be395",
            "cddf6c483b844ae0b249ddead8767eab",
            "702de1c00d434936b589bc9377212d97",
            "1bfa793ced1045e1aab4f39a015340bf",
            "79b1468b6a234c61b232ca9234e34dff",
            "6145d797ecc24708941f4eb46b4879b6",
            "d9e76c404df84dcf9736c34432ef7e66",
            "91399a6445214a9c901dcd2137dff976",
            "e0351ce4d87b499191bc6d0101d252f1"
          ]
        },
        "id": "YEluOj5xG0l0",
        "outputId": "d5215a1f-175f-42cc-8d58-22af2ebef2ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae2001c5bec24d55a78ebe8c524e8454",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "max_input_length = 1024\n",
        "max_target_length = 128\n",
        "\n",
        "def preprocess_dataset(examples):\n",
        "    # <SOL>\n",
        "    # TODO: Implement body\n",
        "\n",
        "    # </SOL>\n",
        "    return model_inputs\n",
        "\n",
        "# <SOL>\n",
        "# TODO: Tokenize dataset\n",
        "tokenized_cnn_dataset = cnn_dataset.map(preprocess_dataset, batched=True, remove_columns=cnn_dataset[\"train\"].column_names)\n",
        "# <SOL>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "TCzau7gU4dyC",
        "outputId": "6d53dee9-0321-4440-d656-baff16b6dc32"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 800\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woSGGbh7kNW_"
      },
      "source": [
        "####Â <font color='#2B4865'>*3.2.3. Fine-tuning*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSv0RD43oAAZ"
      },
      "source": [
        "As evaluation metrics, we are going to use the ROUGE score explained in the Summarization introduction, which is available within the ```rouge_score``` package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Aph58zFLoOEQ",
        "outputId": "d8d63640-b4a7-4534-d6a2-e7910a71ac96"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "rouge_score = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1iJBwJfIoRGY",
        "outputId": "4456a736-be7d-4798-c1a6-df77905c6e40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generated_summary = \"I absolutely loved watching Spiderman\"\n",
        "reference_summary = \"I loved watching Spiderman\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "puBJz8xooT1I",
        "outputId": "78689c71-c5b5-4f87-e933-f73dadf5742a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'rouge1': 0.888888888888889,\n",
              " 'rouge2': 0.5714285714285715,\n",
              " 'rougeL': 0.888888888888889,\n",
              " 'rougeLsum': 0.888888888888889}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = rouge_score.compute(\n",
        "    predictions=[generated_summary], references=[reference_summary]\n",
        ")\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiP6D4jdo8jP"
      },
      "source": [
        "We can see that the output is a dictionary with a variety of ROUGE scores which are based on different types of text granularity when comparing the generated and reference summaries. From these, the ```rouge1``` variant is the metric we have discussed in the introduction. ```rouge2``` measures the overlap between bigrams (pairs of words), while ```rougeL``` and ```rougeLsum``` measure the longest matching sequences of words by looking for the longest common substrings in the generated and reference summaries. The difference between the latter two comes from the fact that ```rougeLsum``` is computed over a whole summary, while ```rougeL```is the average over individual sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTFnxBKsoYs5"
      },
      "source": [
        "We are going to use these ROUGE scores to track the performance of our model, but first, we must define a strong baseline. For text summarization, it is pretty common to attain this baseline by taking the first three sentences of a baseline (the lead-3 baseline). To track the sentence boundaries, we could use full stops, but this will fail on acronyms such as U.S.A. Hence, we will use nltk's sentence tokenizer instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgNAMKPepmVn"
      },
      "source": [
        "###### **Exercise 3.6**\n",
        "\n",
        "Implement the body of the function ```three_sentence_summary``` which given an example in our dataset, it returns the first three sentences in its document. Return the three found sentences joined with a  newline (```\"\\n\"```). Test it on a training example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "k2XlTg8WpsMX",
        "outputId": "5f5e7fcd-0adc-4388-e570-e653802fe653"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
            "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
            "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n"
          ]
        }
      ],
      "source": [
        "# <SOL>\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def three_sentence_summary(text):\n",
        "    # TODO: Implement body\n",
        "    return summary\n",
        "\n",
        "print(three_sentence_summary(cnn_dataset[\"train\"][1][\"article\"]))\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vujk07gdqu2P"
      },
      "source": [
        "###### **Exercise 3.7**\n",
        "\n",
        "Implement the body of the function ```evaluate_lead3_baseline```, which given a dataset and an instance of the metric class, computes the given metric for the three sentence summaries extracted from the dataset. Then use this function to compute the ROUGE scores over the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "mtZbGtFjp4ES",
        "outputId": "3fec0d7c-3e30-43cd-cba9-5ac991f19a6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'rouge1': 27.587462923326456,\n",
              " 'rouge2': 10.356732932817884,\n",
              " 'rougeL': 18.638068385674504,\n",
              " 'rougeLsum': 24.66859712196244}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <SOL>\n",
        "def evaluate_lead3_baseline(dataset, metric):\n",
        "    # TODO: Implement body\n",
        "    return score\n",
        "# </SOL>\n",
        "\n",
        "score_dict = evaluate_lead3_baseline(cnn_dataset[\"val\"], rouge_score)\n",
        "score_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjpsjo576vmd"
      },
      "source": [
        "Now that we have baseline scores to compare with, we can start with the fine-tuning of our model. Let's start by loading the pretrained model from the t5-small checkpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2U8R4gucLsZ"
      },
      "source": [
        "###### **Exercise 3.8**\n",
        "\n",
        "Load the pretrained model in a variable named ``model``. For doing so, take into account that Summarization is a **sequence-to-sequence** task when you create your AutoModel instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iuLXX1xoqUxh",
        "outputId": "4773ea6a-0caf-4c1f-bbae-5c158d5abee8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# <SOL>\n",
        "\n",
        "# </SOL>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7WE4ttucsf0"
      },
      "source": [
        "If youâ€™re wondering why you donâ€™t see any warnings about fine-tuning the model on a downstream task, thatâ€™s because **for sequence-to-sequence tasks we keep all the weights of the network**; this is different from what we have encountered until now, where the head of the pretrained model was replaced with a randomly initialized network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_73I6Ubb-E0"
      },
      "source": [
        "Fine-tuning a model for summarization is very similar to what have been doing until now for other tasks, but with a few exceptions:\n",
        "\n",
        "1. To compute the ROUGE scores, we need to generate summaries. ðŸ¤— Transformers makes this automatically for us through two dedicated classes ``Seq2SeqTrainingArguments`` and ``Seq2SeqTrainer``. Hence, instead of instantiating objects from the classes ``TrainingArguments`` and ``Trainer``, we will use the Seq2Seq-specific ones.\n",
        "  * When using the ``Seq2SeqTrainingArguments`` class, we need to care of the following arguments:\n",
        "      * ``predict_with_generate=True`` to generate summaries during evaluation so that we can compute ROUGE scores for each epoch. The Transformer's decoder performs inference by predicting tokens one by one, and this is implemented by the modelâ€™s ``generate()`` method. Setting ``predict_with_generate=True`` tells the Seq2SeqTrainer to use that method for evaluation.\n",
        "      *   ``save_total_limit`` to limit the number of checkpoints saved during training. This is necessary since even the \"small\" version of T5 uses around a GB of hard drive space, and we can save a bit of room by limiting the number of copies we save.\n",
        "  * The usage of the ``Seq2SeqTrainer`` class is equivalent to that of the ``Trainer`` class.\n",
        "2. Since T5 is an **encoder-decoder Transformer model**, during decoding, we need to shift the labels to the right by one when preparing our batches. This is necessary to ensure that the decoder only sees the previous ground truth labels and not the current or future ones, which would be easy for the model to memorize. ðŸ¤— Transformers provides a ``DataCollatorForSeq2Seq`` collator that will dynamically pad the inputs and the labels for us. The way we instantiate this collator is by providing the tokenizer and model. From this dynamic padding, there are two main things that we need to take into account:\n",
        "  * ``input_ids`` and ``attention_mask`` of shorter sentences get padded on the right with a [PAD] token (whose ID is 0)\n",
        "  * its associated labels are padded with $-100$s, to make sure the padding tokens are ignored by the loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRFZ3E47D_wW"
      },
      "source": [
        "Having this in mind, proceed with the following exercises to complete the fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6962Z05r7LBt"
      },
      "source": [
        "###### **Exercise 3.9**\n",
        "\n",
        "Implement the body of the ``compute_metrics`` function by following the provided guidelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "X0xdRqB1q1yh",
        "outputId": "a0968cc5-e2b8-406f-cc7d-6c19fa23f7a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    # <SOL>\n",
        "\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    decoded_preds = # TODO: Decode generated summaries of a whole batch at once into text. Skip special_tokens\n",
        "\n",
        "    labels = # TODO: Replace -100 in the labels by the \"pad_token_id\"\n",
        "\n",
        "    decoded_labels = # TODO: Decode reference summaries into text of a whole batch at once into text. Skip special_tokens\n",
        "\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    score = # TODO: Compute ROUGE scores\n",
        "\n",
        "    score = {key: value * 100 for key, value in score.items()}\n",
        "\n",
        "    # <SOL>\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq6um4g_Xzhq"
      },
      "source": [
        "###### **Exercise 3.10**\n",
        "\n",
        "Carry out the fine-tuning. For doing so:\n",
        "\n",
        "1. Define your training arguments by creating an instance of the ``Seq2SeqTrainingArguments`` class. Utilize, **at least**, the following configuration:\n",
        "  * ``save_total_limit=3``\n",
        "  * ``predict_with_generate=True``\n",
        "  \n",
        "  Try fine-tuning other parameters (e.g., learning_rate, weight_decay, eval_steps, nr epochs etc.)\n",
        "2. Create a ``DataCollatorForSeq2Seq`` object.\n",
        "3. Create a ``Seq2SeqTrainer`` object by passing all the objects until now created (model, training_args, tokenizer, etc.) Use the compute_metrics function we defined in Exercise 3.10 for evaluating the model during training.\n",
        "4. Train and evaluate the model.\n",
        "\n",
        "Save the fine-tuned model.\n",
        "\n",
        "How are the evaluation scores of our fine-tuned model? Does it outperform our lead-3 baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "W77d2UP5qmlF",
        "outputId": "bb212048-9d6e-4d7e-c9a5-3f897b7693b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# <SOL>\n",
        "\n",
        "# TODO: Add imports\n",
        "\n",
        "training_args = # TODO\n",
        "\n",
        "trainer = # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "urPCHAZBrgrS",
        "outputId": "23a305b0-7563-416f-ab76-48e805574bdd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2250' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2250/6000 17:53 < 29:50, 2.09 it/s, Epoch 3/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.032100</td>\n",
              "      <td>2.002954</td>\n",
              "      <td>24.485941</td>\n",
              "      <td>9.088702</td>\n",
              "      <td>19.785590</td>\n",
              "      <td>22.241066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.895400</td>\n",
              "      <td>2.005943</td>\n",
              "      <td>23.814575</td>\n",
              "      <td>8.921603</td>\n",
              "      <td>19.346105</td>\n",
              "      <td>21.766360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.863200</td>\n",
              "      <td>2.017755</td>\n",
              "      <td>24.131540</td>\n",
              "      <td>8.991544</td>\n",
              "      <td>19.556298</td>\n",
              "      <td>21.938851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2250, training_loss=1.9319733208550347, metrics={'train_runtime': 1074.5493, 'train_samples_per_second': 22.335, 'train_steps_per_second': 5.584, 'total_flos': 2352957398188032.0, 'train_loss': 1.9319733208550347, 'epoch': 3.0})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "SAxOT5IVpr8G",
        "outputId": "dbc7b711-327b-463b-ebd8-a789ab727676"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 01:27]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 2.0029544830322266,\n",
              " 'eval_rouge1': 24.485941480924698,\n",
              " 'eval_rouge2': 9.08870153531135,\n",
              " 'eval_rougeL': 19.7855897173772,\n",
              " 'eval_rougeLsum': 22.241065951663842,\n",
              " 'eval_runtime': 89.7221,\n",
              " 'eval_samples_per_second': 8.916,\n",
              " 'eval_steps_per_second': 2.229,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NudEDJuUqt0h"
      },
      "source": [
        "####Â <font color='#2B4865'>*3.2.4. Make predictions with the fine-tuned model*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oB2nmcLrsMw"
      },
      "source": [
        "We can no play with our saved model either via the inference widget or with a pipeline object, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qSgyrCforC1w",
        "outputId": "a7caa85c-eec2-48ad-b866-bd6704868c27"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load trained model\n",
        "from transformers import pipeline\n",
        "checkpoint = 2250\n",
        "model_path = f\"{path_to_folder}/{model_checkpoint}-finetuned-cnn/checkpoint-{checkpoint}\" ## TODO: Update this path to the last saved checkpoint in the former cell\n",
        "summarizer = pipeline(\"summarization\", model=model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt5celbJrwoH"
      },
      "source": [
        "Let's feed some examples from the test set (which the model has not seen) to our pipeline to get a feel for the quality of the summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Q06DbOV4iE_B",
        "outputId": "22c90fb6-f919-422a-eb1f-1315471a4968"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def print_summary(dataset, num_samples=2, seed=42):\n",
        "    sample = dataset[\"test\"].shuffle(seed=seed).select(range(num_samples))\n",
        "    for example in sample:\n",
        "      review = example[\"article\"]\n",
        "      title = example[\"highlights\"]\n",
        "      summary = summarizer(review)[0][\"summary_text\"]\n",
        "\n",
        "      print(Fore.GREEN + Style.BOLD + '\\n>> Article:' + Style.RESET, review)\n",
        "      print(Fore.LIGHT_BLUE + Style.BOLD + '>> Highlights:' + Style.RESET, title)\n",
        "      print(Fore.RED + Style.BOLD + '>> Summary:' + Style.RESET, summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n80nQaUhryUK",
        "outputId": "d0075ae6-6e98-481e-9b2e-d707919878d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <Style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </Style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m\u001b[1m\n",
            ">> Article:\u001b[0m (CNN)Gastrointestinal illness has gripped 100 people on the cruise ship Celebrity Infinity, according to a report from the Centers for Disease Control. Of the ship's 2,117 passengers, 95 have suffered from vomiting, diarrhea and other symptoms, the CDC said. The illness has also affected five members of the 964-person crew. The CDC has yet to determine what's causing the ailments. Two staffers from the agency are scheduled to meet the West Coast-based ship in San Diego on Monday. The Infinity left San Diego on March 29. It made its last stop in Puerto Vallarta, Mexico, on April 10, according to MarineTraffic.com. Celebrity Cruises has been taking action since the outbreak began, including increasing cleaning and disinfection procedures, keeping passengers informed and taking specimens from the afflicted for testing by the CDC, the agency says. According to the Maritime Executive, this is the third time the Celebrity Infinity has suffered an outbreak of gastrointestinal illness, with others occurring in 2006 and 2013. The ship was built in 2001 and refurbished in 2011.\n",
            "\u001b[38;5;12m\u001b[1m>> Highlights:\u001b[0m 100 passengers and crew members have been sickened on Celebrity Infinity .\n",
            "The ship, which is based on the West Coast, left San Diego in late March .\n",
            "The CDC is scheduled to board the ship Monday .\n",
            "\u001b[38;5;1m\u001b[1m>> Summary:\u001b[0m 95 of cruise ship's 2,117 passengers have suffered from vomiting, diarrhea and other symptoms . The illness has also affected five members of the 964-person crew . Celebrity Cruises has been taking action since outbreak began .\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m\u001b[1m\n",
            ">> Article:\u001b[0m (CNN)When singer Avril Lavigne went missing from the music scene, there was tons of speculation. Was she pregnant? In rehab? Going through a split from her husband, Nickelback front man Chad Kroeger? Focus on the mystery intensified in December after a fan Twitter account posted a direct message from Lavigne when she solicited prayers, saying she was \"having some health issues.\" Now the Canadian singer has revealed to People magazine that she was bedridden for five months after contracting Lyme disease. \"I felt like I couldn't breathe, I couldn't talk, and I couldn't move,\" she told the magazine. \"I thought I was dying.\" Lyme disease: What you should know . Lavigne believes that she was bitten by a tick last spring. What followed was months of lightheadedness and lethargy that doctors were initially unable to diagnose. The 30-year-old performer said she recuperated in her Ontario home, where her husband would use tour breaks to care for her and her mother moved in to assist. \"There were definitely times I couldn't shower for a full week because I could barely stand,\" she told People. \"It felt like having all your life sucked out of you.\" Opinion: Why you should be afraid of Lyme disease . After her direct message about her health went viral, Lavigne was inundated with concern from fans. \"The get-well messages and videos they sent touched me so deeply,\" she said. Now declaring herself \"80 percent better,\" Lavigne is releasing a new single this month to support the 2015 Special Olympics and says that being ill was a \"wake-up call\" that has given her a new perspective. \"I really just want to enjoy life from here on out,\" she said.\n",
            "\u001b[38;5;12m\u001b[1m>> Highlights:\u001b[0m The singer had been off the scene for a while .\n",
            "She says she was bedridden for months .\n",
            "Lavigne was sometimes too weak to shower .\n",
            "\u001b[38;5;1m\u001b[1m>> Summary:\u001b[0m Avril Lavigne says she was bedridden for five months after contracting Lyme disease . The singer has released a new single to support the 2015 Special Olympics . Fans say she was bitten by a tick last spring .\n",
            "\u001b[38;5;2m\u001b[1m\n",
            ">> Article:\u001b[0m New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York. A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.  Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other. In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage. Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the 2010 marriage license application, according to court documents. Prosecutors said the marriages were part of an immigration scam. On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further. After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.  All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say. Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.  Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted. The case was referred to the Bronx District Attorney's Office by Immigration and Customs Enforcement and the Department of Homeland Security's Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali. Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force. If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
            "\u001b[38;5;12m\u001b[1m>> Highlights:\u001b[0m Liana Barrientos, 39, re-arrested after court appearance for alleged fare beating .\n",
            "She has married 10 times as part of an immigration scam, prosecutors say .\n",
            "Barrientos pleaded not guilty Friday to misdemeanor charges .\n",
            "\u001b[38;5;1m\u001b[1m>> Summary:\u001b[0m Liana Barrientos, now 39, is facing two criminal counts of \"offering a false instrument\" Prosecutors say marriages were part of an immigration scam . In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002 .\n",
            "\u001b[38;5;2m\u001b[1m\n",
            ">> Article:\u001b[0m (CNN)Imprisoned soldier Chelsea Manning can now communicate with the world  -- in 140 characters or less. Manning, who is serving a 35-year prison sentence for leaking thousands of classified documents, appears to have joined Twitter this week. In a series of tweets, the prisoner formerly known as Bradley Manning said she will be using a voice phone to dictate her tweets to  communications firm Fitzgibbon Media, which will post them on her behalf. She is not allowed Internet access in prison, according to The Guardian. \"It will be hard, but I don't want this Twitter feed to be a one-way street/conversation,\" Manning posted to her nearly 26,000-plus followers. Manning was sentenced in 2013, and in August of that year, she said she wanted to transition to a female. The Fort Leavenworth Disciplinary Barracks in Kansas, where she is serving her sentence, has authorized hormone therapy for her treatment. Manning said she suffers from gender dysphoria. Her  lawyers describe it as \"the medical diagnosis given to individuals whose gender identity -- their innate sense of being male or female -- differs from the sex they were assigned at birth, causing clinically significant distress.\" Last year, a Kansas judge granted her request to be formally known as Chelsea Elizabeth Manning. The former Army intelligence analyst was convicted of stealing and disseminating 750,000 pages of documents and videos to WikiLeaks in what has been described as the largest leak of classified material in U.S. history. She was found guilty of 20 of the 22 charges, including violations of the U.S. Espionage Act. Manning has written opinion pieces for The New York Times and The Guardian from prison.\n",
            "\u001b[38;5;12m\u001b[1m>> Highlights:\u001b[0m Manning is serving a 35-year sentence for leaking thousands of classified documents .\n",
            "She says she will be using a voice phone to dictate her tweets .\n",
            "\u001b[38;5;1m\u001b[1m>> Summary:\u001b[0m Chelsea Manning is serving a 35-year prison sentence for leaking classified documents . In a series of tweets, Manning said she will be using a voice phone to dictate her tweets . She is not allowed Internet access in prison, according to The Guardian .\n",
            "\u001b[38;5;2m\u001b[1m\n",
            ">> Article:\u001b[0m (CNN)A Connecticut teen who has been forced to have chemotherapy to treat Hodgkin lymphoma will remain in temporary custody of the state for the time being, according to her attorney, Josh Michtom. A Connecticut juvenile court judge issued a written decision Wednesday denying a motion to let the teen, identified in court documents as \"Cassandra C.,\" go home. The judge also denied a motion for visitation. The 17-year-old is in remission after nearly six months of forced chemo treatments. On March 16, Michtom tried to convince the court that she should be able to return to her mother's home because she was no longer at imminent risk of harm from her illness. Michtom and attorney Michael Taylor, who represents Cassandra's mother, Jackie Fortin, released a written statement after receiving the judge's decision Wednesday: \"We are disappointed in this ruling, not least of all because it draws a factual conclusion that is directly contradicted by the weight of the evidence. We're conferring with our clients now about next steps, including whether to take another appeal.\" Cassandra was diagnosed with Hodgkin lymphoma in September and medical experts gave her an 85% chance of survival if treated with chemotherapy. Without it, doctors said at the time, she was likely to die within two years. She started chemotherapy in November but ran away after two days, according to court documents, when she decided she did not want to put the poison of the treatment into her body. In December, a judge ordered the young woman to be under the custody of the Connecticut Department of Children and Families. At that time, she was admitted to Connecticut Children's Medical Center in Hartford and has remained there since then.  Doctors surgically implanted a port in Cassandra's chest to administer chemotherapy medications, which began in spite of legal maneuvers to halt them. Cassandra is feeling well and is in good shape as far as her health is concerned, according to Michtom. \"She's seen in her case the side effects weren't bad, and she's been well-treated by the nurses and doctors and does want to complete the treatment,\" he said. Her treatment is scheduled to wrap up this month. Michtom and Taylor failed in their effort before the Connecticut Supreme Court to make the case that Cassandra was mature enough to make her own medical decisions. Joette Katz, the commissioner of the Department of Children and Families, told CNN in March the agency is \"very pleased with Cassandra's progress toward a complete recovery. We understand how difficult this has been for Cassandra and her family, but we have had full confidence throughout that the medical professionals involved in her treatment would be successful in saving her life.\" The agency has denied CNN's request to speak with Cassandra or her physicians. According to Michtom, the Department of Children and Families could have withdrawn its position for an order of custody but hasn't. He said the department sees Cassandra as a flight risk because she has run away before. Representatives for the department have said in court and in conversations with Michtom and Taylor that they will withdraw their pending neglect petition once Cassandra completes her last round of chemo -- expected around the end of April -- and that she'll be allowed to return home. So for now, Cassandra is said to spend her days reading, watching TV and drawing. \"The hospital is effectively jail,\" Michtom said.\n",
            "\u001b[38;5;12m\u001b[1m>> Highlights:\u001b[0m Judge won't allow teen leave hospital before her last chemotherapy treatment .\n",
            "Attorneys for the teen are deciding whether to appeal .\n",
            "Cassandra C. is now in remission and is no longer opposed to the chemotherapy treatments .\n",
            "\u001b[38;5;1m\u001b[1m>> Summary:\u001b[0m Connecticut teen forced to have chemotherapy to treat Hodgkin lymphoma will remain in temporary custody . Judge denies motion to let the 17-year-old go home . Cassandra is in remission after nearly six months of forced chemo treatments .\n"
          ]
        }
      ],
      "source": [
        "print_summary(cnn_dataset, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqpDKlZWeNBt"
      },
      "source": [
        "## <font color='#2B4865'>Summary</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7mtT_KGNc5A"
      },
      "source": [
        "In this second tutorial, we have covered the tasks of Question Answering and Summarization. The most important things you should have learned are:\n",
        "\n",
        "* How to perform extractive question answering without the pipeline\n",
        "* How to preprocess different datasets according to the task we are trying to solve\n",
        "* How the training of Sequence-to-Sequence models differs from all the others"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjxNX8zGQaLT"
      },
      "source": [
        "### <font color='#2B4865'>Extension exercise</font>\n",
        "\n",
        "**Translation** is another sequence-to-sequence task that is pretty close to summarization, and you could adapt what we have seen here to solve it. If you want to try it out:\n",
        "\n",
        "1. Select which kind of translation model you want to create, e.g. one that translates French to German.\n",
        "2. Choose a dataset from the Hub valid for machine translation on those languages\n",
        "3. Choose a model suitable for the translation task\n",
        "\n",
        "Some things you need to take into account when carrying out the fine-tuning:\n",
        "* **During preprocessing:**\n",
        "  * You need to carry out the tokenization of both the **inputs** and the **targets** (to obtain the labels). As we did with the summarization task, you should define a ``max_input_length`` and a ``max_target_length``. You do not need to save the ``labels_mask``.\n",
        "  * Remember that if you are using a T5 model (one of the t5-xxx checkpoints), the model will expect the text inputs to have a prefix indicating the task at hand, such as ``translate: French to German:``.\n",
        "* **During fine-tuning:**\n",
        "  * As evaluation metric, try out **\"sacrebleu\"**, which, after installing the SacreBLEU library (``!pip install sacrebleu``), you can load via ``evaluate.load()``. This metric takes texts as inputs and targets and is designed to accept several acceptable targets (often multiple acceptable translations of the same sentence). So, the predictions should be a list of sentences (where sentences are strings), but the references should be a list of lists of sentences. This metric will return a dictionary, from which we are interested in the value associated with the key ``score``.\n",
        "  * You can define the ``comput_metrics`` function based on the \"sacrebleu\" in a similar way as we did with summarization. Just note that SacreBLEU does not expect the text to be tokenized."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13517d0cb5044be799e81f183193a7bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfa793ced1045e1aab4f39a015340bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d50f6814a7c4fe99a34090add1a8ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4405912bd1a542de99b43d9af053c060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc2fd9884354a0f94b44c27b2e185e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562e1afc822f4c0d89a21ad74be2be4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6145d797ecc24708941f4eb46b4879b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6220dba6bc924f9ebf9e4484d2f8d6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "639dd3db877b463a81500557ed114cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc2fd9884354a0f94b44c27b2e185e8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3d50f6814a7c4fe99a34090add1a8ec5",
            "value": " 3000/3000 [01:12&lt;00:00, 41.90 examples/s]"
          }
        },
        "674a8bdc92934e9bbcac12a1059be395": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6145d797ecc24708941f4eb46b4879b6",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9e76c404df84dcf9736c34432ef7e66",
            "value": 800
          }
        },
        "6856e67388814595810aff160eca9081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69b8a4a548984453854bd51b688c61d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb91697dac34e0ebd2249bad83e60f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2f3abd3a9e948ac8506626685e01fd6",
              "IPY_MODEL_af254ea0698a4b31a654296727e6a940",
              "IPY_MODEL_877196f7bffd497697e3da96ca9df5a8"
            ],
            "layout": "IPY_MODEL_ace83fd07e9a40059325650b905164c4"
          }
        },
        "702de1c00d434936b589bc9377212d97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "790d6266581b4db0af1ba53cd03c3bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b1468b6a234c61b232ca9234e34dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b359bd4b76b48ee9ed0bd707ac7aa27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80050567ed734572818838676f600f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85586d6ae62f433f94b6acf101b133fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c63ce75de42848d6bc7a0b3f6be45887",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4405912bd1a542de99b43d9af053c060",
            "value": " 200/200 [00:04&lt;00:00, 49.86 examples/s]"
          }
        },
        "865d3a9bc851455ea639959def320fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "877196f7bffd497697e3da96ca9df5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9a7fff03a8e4b6eb3887e7f20a49e95",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c189f465ae2140cdb876efb01e2504b4",
            "value": " 800/800 [00:19&lt;00:00, 40.16 examples/s]"
          }
        },
        "8b5055c5af7747c08b1cadc122512a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f747039ca084a529080974dffdc5d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bfa793ced1045e1aab4f39a015340bf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_79b1468b6a234c61b232ca9234e34dff",
            "value": "Map: 100%"
          }
        },
        "91399a6445214a9c901dcd2137dff976": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d9350383fa474ab8e483fcf26980af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6bf94550ed74e4ba957f5acd548fcf1",
              "IPY_MODEL_c6bc14984204437989891c10dadf4a5b",
              "IPY_MODEL_639dd3db877b463a81500557ed114cc4"
            ],
            "layout": "IPY_MODEL_8b5055c5af7747c08b1cadc122512a3c"
          }
        },
        "99f14ecfbfc64378869c9fa91e4a6d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13517d0cb5044be799e81f183193a7bc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_562e1afc822f4c0d89a21ad74be2be4c",
            "value": "Map: 100%"
          }
        },
        "ace83fd07e9a40059325650b905164c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2001c5bec24d55a78ebe8c524e8454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f747039ca084a529080974dffdc5d97",
              "IPY_MODEL_674a8bdc92934e9bbcac12a1059be395",
              "IPY_MODEL_cddf6c483b844ae0b249ddead8767eab"
            ],
            "layout": "IPY_MODEL_702de1c00d434936b589bc9377212d97"
          }
        },
        "af254ea0698a4b31a654296727e6a940": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0f14a200004cfeb3b4d71fcf6ca97e",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5a19dd63b5f4d5f9bad5294534a4803",
            "value": 800
          }
        },
        "bd0f14a200004cfeb3b4d71fcf6ca97e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c189f465ae2140cdb876efb01e2504b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c63ce75de42848d6bc7a0b3f6be45887": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6bc14984204437989891c10dadf4a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b359bd4b76b48ee9ed0bd707ac7aa27",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f719664f22c3489899183cae64a2fbaf",
            "value": 3000
          }
        },
        "c6bf94550ed74e4ba957f5acd548fcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c7724d189d468bbeead7401f5abf31",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_80050567ed734572818838676f600f96",
            "value": "Map: 100%"
          }
        },
        "c9a7fff03a8e4b6eb3887e7f20a49e95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cddf6c483b844ae0b249ddead8767eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91399a6445214a9c901dcd2137dff976",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e0351ce4d87b499191bc6d0101d252f1",
            "value": " 800/800 [00:02&lt;00:00, 352.58 examples/s]"
          }
        },
        "d2f3abd3a9e948ac8506626685e01fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b8a4a548984453854bd51b688c61d7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6856e67388814595810aff160eca9081",
            "value": "Map: 100%"
          }
        },
        "d53ab39810734710a4d31c30c35b963b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865d3a9bc851455ea639959def320fe7",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6220dba6bc924f9ebf9e4484d2f8d6a8",
            "value": 200
          }
        },
        "d9e76c404df84dcf9736c34432ef7e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0351ce4d87b499191bc6d0101d252f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e03981e6a0ff4243b6d5d27c0da3f1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99f14ecfbfc64378869c9fa91e4a6d1f",
              "IPY_MODEL_d53ab39810734710a4d31c30c35b963b",
              "IPY_MODEL_85586d6ae62f433f94b6acf101b133fe"
            ],
            "layout": "IPY_MODEL_790d6266581b4db0af1ba53cd03c3bd6"
          }
        },
        "e0c7724d189d468bbeead7401f5abf31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a19dd63b5f4d5f9bad5294534a4803": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f719664f22c3489899183cae64a2fbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
